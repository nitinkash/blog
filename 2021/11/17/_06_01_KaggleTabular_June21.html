<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Title | Nitin Kashyap</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Title" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="My Data Science Blog" />
<meta property="og:description" content="My Data Science Blog" />
<link rel="canonical" href="https://nitinkash.github.io/blog/2021/11/17/_06_01_KaggleTabular_June21.html" />
<meta property="og:url" content="https://nitinkash.github.io/blog/2021/11/17/_06_01_KaggleTabular_June21.html" />
<meta property="og:site_name" content="Nitin Kashyap" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-11-17T00:00:00-06:00" />
<script type="application/ld+json">
{"description":"My Data Science Blog","url":"https://nitinkash.github.io/blog/2021/11/17/_06_01_KaggleTabular_June21.html","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://nitinkash.github.io/blog/2021/11/17/_06_01_KaggleTabular_June21.html"},"headline":"Title","dateModified":"2021-11-17T00:00:00-06:00","datePublished":"2021-11-17T00:00:00-06:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://nitinkash.github.io/blog/feed.xml" title="Nitin Kashyap" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" /><script src="https://hypothes.is/embed.js" async></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Nitin Kashyap</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/">Home</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Title</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-11-17T00:00:00-06:00" itemprop="datePublished">
        Nov 17, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      52 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/nitinkash/blog/tree/master/_notebooks/2020_06_01_KaggleTabular_June21.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/nitinkash/blog/master?filepath=_notebooks%2F2020_06_01_KaggleTabular_June21.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/nitinkash/blog/blob/master/_notebooks/2020_06_01_KaggleTabular_June21.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020_06_01_KaggleTabular_June21.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">log_loss</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;train.csv.zip&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;test.csv.zip&#39;</span><span class="p">)</span> 
<span class="n">sample_submission</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;sample_submission.csv.zip&#39;</span><span class="p">)</span>

<span class="n">train</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">codes</span>

<span class="n">indep_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;feature_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">75</span><span class="p">)]</span>
<span class="n">dep_var</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">optuna</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">catboost</span>

<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">shap</span>

<span class="kn">from</span> <span class="nn">catboost</span> <span class="kn">import</span> <span class="n">Pool</span><span class="p">,</span> <span class="n">CatBoostClassifier</span>

<span class="kn">import</span> <span class="nn">catboost</span>
<span class="kn">import</span> <span class="nn">optuna</span>
<span class="kn">import</span> <span class="nn">shap</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting optuna
  Downloading https://files.pythonhosted.org/packages/1a/18/b49ca91cf592747e19f2d333c2a86cd7c81895b922a5a09adf6335471576/optuna-2.8.0-py3-none-any.whl (301kB)
     |████████████████████████████████| 307kB 7.3MB/s 
Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.41.1)
Requirement already satisfied: sqlalchemy&gt;=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.18)
Collecting colorlog
  Downloading https://files.pythonhosted.org/packages/32/e6/e9ddc6fa1104fda718338b341e4b3dc31cd8039ab29e52fc73b508515361/colorlog-5.0.1-py2.py3-none-any.whl
Collecting cliff
  Downloading https://files.pythonhosted.org/packages/87/11/aea1cacbd4cf8262809c4d6f95dcb3f2802594de1f51c5bd454d69bf15c5/cliff-3.8.0-py3-none-any.whl (80kB)
     |████████████████████████████████| 81kB 9.9MB/s 
Collecting alembic
  Downloading https://files.pythonhosted.org/packages/d5/80/ef186e599a57d0e4cb78fc76e0bfc2e6953fa9716b2a5cf2de0117ed8eb5/alembic-1.6.5-py2.py3-none-any.whl (164kB)
     |████████████████████████████████| 174kB 21.2MB/s 
Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)
Collecting cmaes&gt;=0.8.2
  Downloading https://files.pythonhosted.org/packages/01/1f/43b01223a0366171f474320c6e966c39a11587287f098a5f09809b45e05f/cmaes-0.8.2-py3-none-any.whl
Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (20.9)
Requirement already satisfied: greenlet!=0.4.17; python_version &gt;= &#34;3&#34; in /usr/local/lib/python3.7/dist-packages (from sqlalchemy&gt;=1.1.0-&gt;optuna) (1.1.0)
Requirement already satisfied: importlib-metadata; python_version &lt; &#34;3.8&#34; in /usr/local/lib/python3.7/dist-packages (from sqlalchemy&gt;=1.1.0-&gt;optuna) (4.5.0)
Collecting cmd2&gt;=1.0.0
  Downloading https://files.pythonhosted.org/packages/e3/6a/e929ec70ca05c5962f6541ef29fb9c207dd41f0f2333680fa39f44fa4357/cmd2-2.1.1-py3-none-any.whl (140kB)
     |████████████████████████████████| 143kB 25.9MB/s 
Requirement already satisfied: PrettyTable&gt;=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff-&gt;optuna) (2.1.0)
Collecting stevedore&gt;=2.0.1
  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)
     |████████████████████████████████| 51kB 8.7MB/s 
Requirement already satisfied: PyYAML&gt;=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff-&gt;optuna) (3.13)
Collecting pbr!=2.1.0,&gt;=2.0.0
  Downloading https://files.pythonhosted.org/packages/18/e0/1d4702dd81121d04a477c272d47ee5b6bc970d1a0990b11befa275c55cf2/pbr-5.6.0-py2.py3-none-any.whl (111kB)
     |████████████████████████████████| 112kB 27.4MB/s 
Requirement already satisfied: pyparsing&gt;=2.1.0 in /usr/local/lib/python3.7/dist-packages (from cliff-&gt;optuna) (2.4.7)
Collecting Mako
  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)
     |████████████████████████████████| 81kB 10.3MB/s 
Collecting python-editor&gt;=0.3
  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl
Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic-&gt;optuna) (2.8.1)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version &lt; &#34;3.8&#34;-&gt;sqlalchemy&gt;=1.1.0-&gt;optuna) (3.4.1)
Requirement already satisfied: typing-extensions&gt;=3.6.4; python_version &lt; &#34;3.8&#34; in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version &lt; &#34;3.8&#34;-&gt;sqlalchemy&gt;=1.1.0-&gt;optuna) (3.7.4.3)
Requirement already satisfied: wcwidth&gt;=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2&gt;=1.0.0-&gt;cliff-&gt;optuna) (0.2.5)
Requirement already satisfied: attrs&gt;=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2&gt;=1.0.0-&gt;cliff-&gt;optuna) (21.2.0)
Collecting colorama&gt;=0.3.7
  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl
Collecting pyperclip&gt;=1.6
  Downloading https://files.pythonhosted.org/packages/a7/2c/4c64579f847bd5d539803c8b909e54ba087a79d01bb3aba433a95879a6c5/pyperclip-1.8.2.tar.gz
Requirement already satisfied: MarkupSafe&gt;=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako-&gt;alembic-&gt;optuna) (2.0.1)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil-&gt;alembic-&gt;optuna) (1.15.0)
Building wheels for collected packages: pyperclip
  Building wheel for pyperclip (setup.py) ... done
  Created wheel for pyperclip: filename=pyperclip-1.8.2-cp37-none-any.whl size=11136 sha256=25736bd654d36a09e93fd30cb6c095cfb875f32371c32cd94952e9f6e71de56e
  Stored in directory: /root/.cache/pip/wheels/25/af/b8/3407109267803f4015e1ee2ff23be0c8c19ce4008665931ee1
Successfully built pyperclip
Installing collected packages: colorlog, colorama, pyperclip, cmd2, pbr, stevedore, cliff, Mako, python-editor, alembic, cmaes, optuna
Successfully installed Mako-1.1.4 alembic-1.6.5 cliff-3.8.0 cmaes-0.8.2 cmd2-2.1.1 colorama-0.4.4 colorlog-5.0.1 optuna-2.8.0 pbr-5.6.0 pyperclip-1.8.2 python-editor-1.0.4 stevedore-3.3.0
Collecting catboost
  Downloading https://files.pythonhosted.org/packages/5a/41/24e14322b9986cf72a8763e0a0a69cc256cf963cf9502c8f0044a62c1ae8/catboost-0.26-cp37-none-manylinux1_x86_64.whl (69.2MB)
     |████████████████████████████████| 69.2MB 38kB/s 
Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)
Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)
Requirement already satisfied: pandas&gt;=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)
Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)
Requirement already satisfied: numpy&gt;=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)
Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.24.0-&gt;catboost) (2.8.1)
Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.24.0-&gt;catboost) (2018.9)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;catboost) (2.4.7)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;catboost) (1.3.1)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;catboost) (0.10.0)
Requirement already satisfied: retrying&gt;=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly-&gt;catboost) (1.3.3)
Installing collected packages: catboost
Successfully installed catboost-0.26
Collecting shap
  Downloading https://files.pythonhosted.org/packages/b9/f4/c5b95cddae15be80f8e58b25edceca105aa83c0b8c86a1edad24a6af80d3/shap-0.39.0.tar.gz (356kB)
     |████████████████████████████████| 358kB 8.1MB/s 
Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)
Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (0.22.2.post1)
Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.1.5)
Requirement already satisfied: tqdm&gt;4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.41.1)
Collecting slicer==0.0.7
  Downloading https://files.pythonhosted.org/packages/78/c2/b3f55dfdb8af9812fdb9baf70cacf3b9e82e505b2bd4324d588888b81202/slicer-0.0.7-py3-none-any.whl
Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)
Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;shap) (1.0.1)
Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;shap) (2018.9)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;shap) (2.8.1)
Requirement already satisfied: llvmlite&lt;0.35,&gt;=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba-&gt;shap) (0.34.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba-&gt;shap) (57.0.0)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;shap) (1.15.0)
Building wheels for collected packages: shap
  Building wheel for shap (setup.py) ... done
  Created wheel for shap: filename=shap-0.39.0-cp37-cp37m-linux_x86_64.whl size=491624 sha256=8a08a0f333a477e798fadfceb652d10f8a38b8849b9354c5125b5ed004b99867
  Stored in directory: /root/.cache/pip/wheels/15/27/f5/a8ab9da52fd159aae6477b5ede6eaaec69fd130fa0fa59f283
Successfully built shap
Installing collected packages: slicer, shap
Successfully installed shap-0.39.0 slicer-0.0.7
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((200000, 77), (100000, 76))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f040cd56390&gt;</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">train_models</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">cat_features</span><span class="p">,</span> <span class="n">random_state</span><span class="p">,</span> <span class="n">n_splits</span><span class="p">):</span>

    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">folds</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>  <span class="c1"># create folds</span>
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">n_fold</span><span class="p">,</span> <span class="p">(</span><span class="n">train_idx</span><span class="p">,</span> <span class="n">valid_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">folds</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span>  <span class="n">y_train</span><span class="p">)):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Fold </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_fold</span><span class="p">,</span> <span class="n">n_splits</span><span class="p">))</span>
        <span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">y_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
        <span class="n">valid_X</span><span class="p">,</span> <span class="n">valid_y</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">],</span> <span class="n">y_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">]</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">Pool</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">cat_features</span><span class="p">)</span>
        <span class="n">evalset</span> <span class="o">=</span> <span class="n">Pool</span><span class="p">(</span><span class="n">valid_X</span><span class="p">,</span> <span class="n">valid_y</span><span class="p">,</span> <span class="n">cat_features</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">CatBoostClassifier</span><span class="p">(</span>
            <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;GPU&quot;</span><span class="p">,</span>
            <span class="n">depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
            <span class="n">max_ctr_complexity</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
            <span class="c1"># border_count=1024,</span>
            <span class="n">iterations</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span>
            <span class="n">od_wait</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">od_type</span><span class="o">=</span><span class="s1">&#39;Iter&#39;</span><span class="p">,</span>
            <span class="c1"># l2_leaf_reg=0.01,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
            <span class="n">min_data_in_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">use_best_model</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">loss_function</span><span class="o">=</span><span class="s1">&#39;MultiClass&#39;</span>

        <span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="n">evalset</span><span class="p">)</span>        
        <span class="n">_record</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;model&#39;</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_record</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">models</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">10</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>20000.0</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="n">train_models</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">indep_vars</span><span class="p">,</span> <span class="n">cat_features</span><span class="o">=</span><span class="n">indep_vars</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">43</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;target&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="o">/</span><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>target
Class_1     4.5590
Class_2    12.2155
Class_3     7.3990
Class_4     2.3520
Class_5     1.5320
Class_6    25.9055
Class_7     7.3845
Class_8    25.8815
Class_9    12.7710
Name: id, dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">X_test</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="n">indep_vars</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">submissionFile</span><span class="p">(</span><span class="n">modelZ</span><span class="p">,</span> <span class="n">generate_csv</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>   
    <span class="n">probabilities</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">modelZ</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Class_1&#39;</span><span class="p">,</span><span class="s1">&#39;Class_2&#39;</span><span class="p">,</span><span class="s1">&#39;Class_3&#39;</span><span class="p">,</span><span class="s1">&#39;Class_4&#39;</span><span class="p">,</span> <span class="s1">&#39;Class_5&#39;</span><span class="p">,</span> <span class="s1">&#39;Class_6&#39;</span><span class="p">,</span> <span class="s1">&#39;Class_7&#39;</span><span class="p">,</span> <span class="s1">&#39;Class_8&#39;</span><span class="p">,</span> <span class="s1">&#39;Class_9&#39;</span><span class="p">])</span>
    <span class="n">mySubmission</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="n">mySubmission</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span>
    <span class="n">mySubmission</span><span class="p">[</span><span class="s1">&#39;Class_1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">probabilities</span><span class="p">[</span><span class="s1">&#39;Class_1&#39;</span><span class="p">]</span>
    <span class="n">mySubmission</span><span class="p">[</span><span class="s1">&#39;Class_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">probabilities</span><span class="p">[</span><span class="s1">&#39;Class_2&#39;</span><span class="p">]</span>
    <span class="n">mySubmission</span><span class="p">[</span><span class="s1">&#39;Class_3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">probabilities</span><span class="p">[</span><span class="s1">&#39;Class_3&#39;</span><span class="p">]</span>
    <span class="n">mySubmission</span><span class="p">[</span><span class="s1">&#39;Class_4&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">probabilities</span><span class="p">[</span><span class="s1">&#39;Class_4&#39;</span><span class="p">]</span>
    <span class="n">mySubmission</span><span class="p">[</span><span class="s1">&#39;Class_5&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">probabilities</span><span class="p">[</span><span class="s1">&#39;Class_5&#39;</span><span class="p">]</span>
    <span class="n">mySubmission</span><span class="p">[</span><span class="s1">&#39;Class_6&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">probabilities</span><span class="p">[</span><span class="s1">&#39;Class_6&#39;</span><span class="p">]</span>
    <span class="n">mySubmission</span><span class="p">[</span><span class="s1">&#39;Class_7&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">probabilities</span><span class="p">[</span><span class="s1">&#39;Class_7&#39;</span><span class="p">]</span>
    <span class="n">mySubmission</span><span class="p">[</span><span class="s1">&#39;Class_8&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">probabilities</span><span class="p">[</span><span class="s1">&#39;Class_8&#39;</span><span class="p">]</span>
    <span class="n">mySubmission</span><span class="p">[</span><span class="s1">&#39;Class_9&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">probabilities</span><span class="p">[</span><span class="s1">&#39;Class_9&#39;</span><span class="p">]</span>
    
    <span class="k">if</span> <span class="n">generate_csv</span><span class="p">:</span>
        <span class="n">mySubmission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;submission.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mySubmission</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">submissionFile</span><span class="p">(</span><span class="n">models</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="s1">&#39;model&#39;</span><span class="p">])</span>
<span class="err">!</span><span class="n">kaggle</span> <span class="n">competitions</span> <span class="n">submit</span> <span class="o">-</span><span class="n">c</span> <span class="n">tabular</span><span class="o">-</span><span class="n">playground</span><span class="o">-</span><span class="n">series</span><span class="o">-</span><span class="n">jun</span><span class="o">-</span><span class="mi">2021</span> <span class="o">-</span><span class="n">f</span> <span class="n">submission</span><span class="o">.</span><span class="n">csv</span> <span class="o">-</span><span class="n">m</span> <span class="s2">&quot;Sample-May-Pipeline&quot;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Warning: Looks like you&#39;re using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)
100% 17.9M/17.9M [00:00&lt;00:00, 36.3MB/s]
Successfully submitted to Tabular Playground Series - Jun 2021</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Hyper-parameter-tuning-using-Optuna">Hyper parameter tuning using Optuna<a class="anchor-link" href="#Hyper-parameter-tuning-using-Optuna"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train</span><span class="o">.</span><span class="n">columns</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Index([&#39;id&#39;, &#39;feature_0&#39;, &#39;feature_1&#39;, &#39;feature_2&#39;, &#39;feature_3&#39;, &#39;feature_4&#39;,
       &#39;feature_5&#39;, &#39;feature_6&#39;, &#39;feature_7&#39;, &#39;feature_8&#39;, &#39;feature_9&#39;,
       &#39;feature_10&#39;, &#39;feature_11&#39;, &#39;feature_12&#39;, &#39;feature_13&#39;, &#39;feature_14&#39;,
       &#39;feature_15&#39;, &#39;feature_16&#39;, &#39;feature_17&#39;, &#39;feature_18&#39;, &#39;feature_19&#39;,
       &#39;feature_20&#39;, &#39;feature_21&#39;, &#39;feature_22&#39;, &#39;feature_23&#39;, &#39;feature_24&#39;,
       &#39;feature_25&#39;, &#39;feature_26&#39;, &#39;feature_27&#39;, &#39;feature_28&#39;, &#39;feature_29&#39;,
       &#39;feature_30&#39;, &#39;feature_31&#39;, &#39;feature_32&#39;, &#39;feature_33&#39;, &#39;feature_34&#39;,
       &#39;feature_35&#39;, &#39;feature_36&#39;, &#39;feature_37&#39;, &#39;feature_38&#39;, &#39;feature_39&#39;,
       &#39;feature_40&#39;, &#39;feature_41&#39;, &#39;feature_42&#39;, &#39;feature_43&#39;, &#39;feature_44&#39;,
       &#39;feature_45&#39;, &#39;feature_46&#39;, &#39;feature_47&#39;, &#39;feature_48&#39;, &#39;feature_49&#39;,
       &#39;feature_50&#39;, &#39;feature_51&#39;, &#39;feature_52&#39;, &#39;feature_53&#39;, &#39;feature_54&#39;,
       &#39;feature_55&#39;, &#39;feature_56&#39;, &#39;feature_57&#39;, &#39;feature_58&#39;, &#39;feature_59&#39;,
       &#39;feature_60&#39;, &#39;feature_61&#39;, &#39;feature_62&#39;, &#39;feature_63&#39;, &#39;feature_64&#39;,
       &#39;feature_65&#39;, &#39;feature_66&#39;, &#39;feature_67&#39;, &#39;feature_68&#39;, &#39;feature_69&#39;,
       &#39;feature_70&#39;, &#39;feature_71&#39;, &#39;feature_72&#39;, &#39;feature_73&#39;, &#39;feature_74&#39;,
       &#39;target&#39;],
      dtype=&#39;object&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">train</span>
<span class="c1">#Y=train[&#39;target&#39;]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">y</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">X</span><span class="p">,</span><span class="n">target</span><span class="o">=</span><span class="n">Y</span><span class="p">):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;iterations&#39;</span><span class="p">:</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;iterations&quot;</span><span class="p">,</span> <span class="mi">7000</span><span class="p">,</span> <span class="mi">25000</span><span class="p">),</span>
            <span class="s1">&#39;od_wait&#39;</span><span class="p">:</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">&#39;od_wait&#39;</span><span class="p">,</span> <span class="mi">1500</span><span class="p">,</span> <span class="mi">3000</span><span class="p">),</span>
            <span class="s1">&#39;loss_function&#39;</span><span class="p">:</span><span class="s1">&#39;MultiClass&#39;</span><span class="p">,</span>
            <span class="s1">&#39;task_type&#39;</span><span class="p">:</span><span class="s2">&quot;GPU&quot;</span><span class="p">,</span>
            <span class="s1">&#39;eval_metric&#39;</span><span class="p">:</span><span class="s1">&#39;MultiClass&#39;</span><span class="p">,</span>
            <span class="s1">&#39;leaf_estimation_method&#39;</span><span class="p">:</span><span class="s1">&#39;Newton&#39;</span><span class="p">,</span>
            <span class="s1">&#39;bootstrap_type&#39;</span><span class="p">:</span> <span class="s1">&#39;Bernoulli&#39;</span><span class="p">,</span>
            <span class="s1">&#39;learning_rate&#39;</span> <span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_uniform</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span><span class="mf">0.001</span><span class="p">,</span><span class="mf">0.1</span><span class="p">),</span>
            <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_uniform</span><span class="p">(</span><span class="s1">&#39;reg_lambda&#39;</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">),</span>
            <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_uniform</span><span class="p">(</span><span class="s1">&#39;subsample&#39;</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span>
            <span class="s1">&#39;random_strength&#39;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_uniform</span><span class="p">(</span><span class="s1">&#39;random_strength&#39;</span><span class="p">,</span><span class="mi">18</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span>
            <span class="s1">&#39;depth&#39;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">&#39;depth&#39;</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span>
            <span class="s1">&#39;min_data_in_leaf&#39;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">&#39;min_data_in_leaf&#39;</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span>
            <span class="s1">&#39;leaf_estimation_iterations&#39;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">&#39;leaf_estimation_iterations&#39;</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span>
                <span class="p">}</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">CatBoostClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>  
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)],</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
    <span class="n">y_preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>


    <span class="n">log_loss_multi</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">log_loss_multi</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">OPTUNA_OPTIMIZATION</span> <span class="o">=</span> <span class="kc">True</span>


<span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s1">&#39;minimize&#39;</span><span class="p">)</span>
<span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of finished trials:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">study</span><span class="o">.</span><span class="n">trials</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best trial: score </span><span class="si">{}</span><span class="s1">, params </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">study</span><span class="o">.</span><span class="n">best_trial</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">study</span><span class="o">.</span><span class="n">best_trial</span><span class="o">.</span><span class="n">params</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre><span class="ansi-green-fg">[I 2021-06-24 11:31:52,715]</span> A new study created in memory with name: no-name-51ea7dd7-c8d2-4705-942e-90c8d8c2297b
Custom logger is already specified. Specify more than one logger at same time is not thread safe.<span class="ansi-green-fg">[I 2021-06-24 11:32:06,212]</span> Trial 0 finished with value: 1.7475517290197657 and parameters: {&#39;iterations&#39;: 22081, &#39;od_wait&#39;: 2890, &#39;learning_rate&#39;: 0.0523585535392492, &#39;reg_lambda&#39;: 53.30046637750339, &#39;subsample&#39;: 0.8322426285324465, &#39;random_strength&#39;: 25.383248292425595, &#39;depth&#39;: 3, &#39;min_data_in_leaf&#39;: 17, &#39;leaf_estimation_iterations&#39;: 4}. Best is trial 0 with value: 1.7475517290197657.
<span class="ansi-green-fg">[I 2021-06-24 11:32:32,838]</span> Trial 1 finished with value: 1.746530009869069 and parameters: {&#39;iterations&#39;: 16107, &#39;od_wait&#39;: 1934, &#39;learning_rate&#39;: 0.020694951401143857, &#39;reg_lambda&#39;: 76.40295318744504, &#39;subsample&#39;: 0.5779226659582111, &#39;random_strength&#39;: 18.674100622696255, &#39;depth&#39;: 4, &#39;min_data_in_leaf&#39;: 17, &#39;leaf_estimation_iterations&#39;: 3}. Best is trial 1 with value: 1.746530009869069.
<span class="ansi-green-fg">[I 2021-06-24 11:33:11,831]</span> Trial 2 finished with value: 1.746400371649169 and parameters: {&#39;iterations&#39;: 23051, &#39;od_wait&#39;: 2708, &#39;learning_rate&#39;: 0.013266322205507153, &#39;reg_lambda&#39;: 68.80768412391788, &#39;subsample&#39;: 0.5917359474274496, &#39;random_strength&#39;: 25.9671120082771, &#39;depth&#39;: 4, &#39;min_data_in_leaf&#39;: 20, &#39;leaf_estimation_iterations&#39;: 3}. Best is trial 2 with value: 1.746400371649169.
<span class="ansi-green-fg">[I 2021-06-24 11:33:20,339]</span> Trial 3 finished with value: 1.748109944775364 and parameters: {&#39;iterations&#39;: 7837, &#39;od_wait&#39;: 2024, &#39;learning_rate&#39;: 0.08940487435096595, &#39;reg_lambda&#39;: 94.49408043431762, &#39;subsample&#39;: 0.033697771735656246, &#39;random_strength&#39;: 21.96373022691814, &#39;depth&#39;: 5, &#39;min_data_in_leaf&#39;: 10, &#39;leaf_estimation_iterations&#39;: 5}. Best is trial 2 with value: 1.746400371649169.
<span class="ansi-green-fg">[I 2021-06-24 11:33:31,814]</span> Trial 4 finished with value: 1.7465947826600974 and parameters: {&#39;iterations&#39;: 8561, &#39;od_wait&#39;: 2482, &#39;learning_rate&#39;: 0.051847639930613254, &#39;reg_lambda&#39;: 88.8265560299443, &#39;subsample&#39;: 0.8561444452479751, &#39;random_strength&#39;: 27.327853362663912, &#39;depth&#39;: 5, &#39;min_data_in_leaf&#39;: 28, &#39;leaf_estimation_iterations&#39;: 3}. Best is trial 2 with value: 1.746400371649169.
<span class="ansi-green-fg">[I 2021-06-24 11:33:50,273]</span> Trial 5 finished with value: 1.7474099656786515 and parameters: {&#39;iterations&#39;: 10633, &#39;od_wait&#39;: 2781, &#39;learning_rate&#39;: 0.03558483877482585, &#39;reg_lambda&#39;: 98.29738704750187, &#39;subsample&#39;: 0.0016725576626520633, &#39;random_strength&#39;: 25.28373658367917, &#39;depth&#39;: 5, &#39;min_data_in_leaf&#39;: 30, &#39;leaf_estimation_iterations&#39;: 6}. Best is trial 2 with value: 1.746400371649169.
<span class="ansi-green-fg">[I 2021-06-24 11:34:55,381]</span> Trial 6 finished with value: 1.7458479262869728 and parameters: {&#39;iterations&#39;: 21137, &#39;od_wait&#39;: 1612, &#39;learning_rate&#39;: 0.009700927493295129, &#39;reg_lambda&#39;: 75.30243026925147, &#39;subsample&#39;: 0.6106777045552494, &#39;random_strength&#39;: 21.22381681406639, &#39;depth&#39;: 5, &#39;min_data_in_leaf&#39;: 27, &#39;leaf_estimation_iterations&#39;: 6}. Best is trial 6 with value: 1.7458479262869728.
<span class="ansi-green-fg">[I 2021-06-24 11:35:06,131]</span> Trial 7 finished with value: 1.7473726389629178 and parameters: {&#39;iterations&#39;: 12020, &#39;od_wait&#39;: 1538, &#39;learning_rate&#39;: 0.05846745451734049, &#39;reg_lambda&#39;: 66.74096285230748, &#39;subsample&#39;: 0.5152141740529858, &#39;random_strength&#39;: 18.086700126519453, &#39;depth&#39;: 3, &#39;min_data_in_leaf&#39;: 13, &#39;leaf_estimation_iterations&#39;: 2}. Best is trial 6 with value: 1.7458479262869728.
<span class="ansi-green-fg">[I 2021-06-24 11:35:13,600]</span> Trial 8 finished with value: 1.7473827678729799 and parameters: {&#39;iterations&#39;: 12637, &#39;od_wait&#39;: 2891, &#39;learning_rate&#39;: 0.08608747207630392, &#39;reg_lambda&#39;: 52.33175708629835, &#39;subsample&#39;: 0.8333242356914867, &#39;random_strength&#39;: 25.501737215394584, &#39;depth&#39;: 4, &#39;min_data_in_leaf&#39;: 28, &#39;leaf_estimation_iterations&#39;: 4}. Best is trial 6 with value: 1.7458479262869728.
<span class="ansi-green-fg">[I 2021-06-24 11:35:55,916]</span> Trial 9 finished with value: 1.7452546603418322 and parameters: {&#39;iterations&#39;: 17673, &#39;od_wait&#39;: 2363, &#39;learning_rate&#39;: 0.014174736490140817, &#39;reg_lambda&#39;: 63.91819499977507, &#39;subsample&#39;: 0.15103934369387173, &#39;random_strength&#39;: 20.629442387538404, &#39;depth&#39;: 6, &#39;min_data_in_leaf&#39;: 20, &#39;leaf_estimation_iterations&#39;: 2}. Best is trial 9 with value: 1.7452546603418322.
<span class="ansi-green-fg">[I 2021-06-24 11:39:28,423]</span> Trial 10 finished with value: 1.7454383570512968 and parameters: {&#39;iterations&#39;: 17665, &#39;od_wait&#39;: 2344, &#39;learning_rate&#39;: 0.0016874297825336618, &#39;reg_lambda&#39;: 61.262675395241985, &#39;subsample&#39;: 0.22562898282554636, &#39;random_strength&#39;: 29.61502819684977, &#39;depth&#39;: 6, &#39;min_data_in_leaf&#39;: 23, &#39;leaf_estimation_iterations&#39;: 2}. Best is trial 9 with value: 1.7452546603418322.
<span class="ansi-green-fg">[I 2021-06-24 11:42:54,192]</span> Trial 11 finished with value: 1.7462246417016778 and parameters: {&#39;iterations&#39;: 17865, &#39;od_wait&#39;: 2324, &#39;learning_rate&#39;: 0.001201978817991051, &#39;reg_lambda&#39;: 60.981201516164674, &#39;subsample&#39;: 0.2182601017873742, &#39;random_strength&#39;: 28.885486735161823, &#39;depth&#39;: 6, &#39;min_data_in_leaf&#39;: 22, &#39;leaf_estimation_iterations&#39;: 2}. Best is trial 9 with value: 1.7452546603418322.
<span class="ansi-green-fg">[I 2021-06-24 11:43:12,604]</span> Trial 12 finished with value: 1.7458295896690477 and parameters: {&#39;iterations&#39;: 18732, &#39;od_wait&#39;: 2465, &#39;learning_rate&#39;: 0.03347786451108715, &#39;reg_lambda&#39;: 59.97450248914125, &#39;subsample&#39;: 0.25423345497514366, &#39;random_strength&#39;: 21.59810311874977, &#39;depth&#39;: 6, &#39;min_data_in_leaf&#39;: 23, &#39;leaf_estimation_iterations&#39;: 2}. Best is trial 9 with value: 1.7452546603418322.
<span class="ansi-green-fg">[I 2021-06-24 11:46:13,476]</span> Trial 13 finished with value: 1.7451314700338245 and parameters: {&#39;iterations&#39;: 15303, &#39;od_wait&#39;: 2091, &#39;learning_rate&#39;: 0.0025553641829274155, &#39;reg_lambda&#39;: 58.90581768346291, &#39;subsample&#39;: 0.2803752477508894, &#39;random_strength&#39;: 29.811834598299864, &#39;depth&#39;: 6, &#39;min_data_in_leaf&#39;: 24, &#39;leaf_estimation_iterations&#39;: 2}. Best is trial 13 with value: 1.7451314700338245.
<span class="ansi-green-fg">[I 2021-06-24 11:46:35,473]</span> Trial 14 finished with value: 1.745619726766246 and parameters: {&#39;iterations&#39;: 14608, &#39;od_wait&#39;: 1988, &#39;learning_rate&#39;: 0.024430072222760557, &#39;reg_lambda&#39;: 83.54033041422643, &#39;subsample&#39;: 0.33529647924209044, &#39;random_strength&#39;: 19.85206927527221, &#39;depth&#39;: 6, &#39;min_data_in_leaf&#39;: 25, &#39;leaf_estimation_iterations&#39;: 3}. Best is trial 13 with value: 1.7451314700338245.
<span class="ansi-green-fg">[I 2021-06-24 11:46:43,946]</span> Trial 15 finished with value: 1.7469002864780332 and parameters: {&#39;iterations&#39;: 14612, &#39;od_wait&#39;: 2112, &#39;learning_rate&#39;: 0.07113034816909905, &#39;reg_lambda&#39;: 50.64443897027989, &#39;subsample&#39;: 0.09743289130986188, &#39;random_strength&#39;: 23.235789931897173, &#39;depth&#39;: 6, &#39;min_data_in_leaf&#39;: 17, &#39;leaf_estimation_iterations&#39;: 2}. Best is trial 13 with value: 1.7451314700338245.
<span class="ansi-green-fg">[I 2021-06-24 11:46:59,410]</span> Trial 16 finished with value: 1.746074161484668 and parameters: {&#39;iterations&#39;: 24879, &#39;od_wait&#39;: 1795, &#39;learning_rate&#39;: 0.03823712498063181, &#39;reg_lambda&#39;: 68.81591565015204, &#39;subsample&#39;: 0.39378640203502946, &#39;random_strength&#39;: 22.900672433164914, &#39;depth&#39;: 6, &#39;min_data_in_leaf&#39;: 20, &#39;leaf_estimation_iterations&#39;: 3}. Best is trial 13 with value: 1.7451314700338245.
<span class="ansi-green-fg">[I 2021-06-24 11:49:59,929]</span> Trial 17 finished with value: 1.7461189704019306 and parameters: {&#39;iterations&#39;: 20820, &#39;od_wait&#39;: 2192, &#39;learning_rate&#39;: 0.0030749668653478617, &#39;reg_lambda&#39;: 56.90191741891942, &#39;subsample&#39;: 0.1319154631507808, &#39;random_strength&#39;: 20.345579982546628, &#39;depth&#39;: 5, &#39;min_data_in_leaf&#39;: 14, &#39;leaf_estimation_iterations&#39;: 5}. Best is trial 13 with value: 1.7451314700338245.
<span class="ansi-green-fg">[I 2021-06-24 11:50:35,601]</span> Trial 18 finished with value: 1.7453019832535064 and parameters: {&#39;iterations&#39;: 19400, &#39;od_wait&#39;: 2588, &#39;learning_rate&#39;: 0.015569833679796617, &#39;reg_lambda&#39;: 64.9867731346661, &#39;subsample&#39;: 0.4119976109071702, &#39;random_strength&#39;: 27.670942758083612, &#39;depth&#39;: 6, &#39;min_data_in_leaf&#39;: 25, &#39;leaf_estimation_iterations&#39;: 2}. Best is trial 13 with value: 1.7451314700338245.
<span class="ansi-green-fg">[I 2021-06-24 11:50:56,732]</span> Trial 19 finished with value: 1.7462970137394513 and parameters: {&#39;iterations&#39;: 16079, &#39;od_wait&#39;: 1740, &#39;learning_rate&#39;: 0.025921600027612537, &#39;reg_lambda&#39;: 79.94197587917978, &#39;subsample&#39;: 0.11726613064624752, &#39;random_strength&#39;: 19.33862638199317, &#39;depth&#39;: 5, &#39;min_data_in_leaf&#39;: 19, &#39;leaf_estimation_iterations&#39;: 4}. Best is trial 13 with value: 1.7451314700338245.
<span class="ansi-green-fg">[I 2021-06-24 11:54:20,731]</span> Trial 20 finished with value: 1.745902916234771 and parameters: {&#39;iterations&#39;: 14047, &#39;od_wait&#39;: 2176, &#39;learning_rate&#39;: 0.0014635190053216935, &#39;reg_lambda&#39;: 56.304435706979824, &#39;subsample&#39;: 0.7050889136259979, &#39;random_strength&#39;: 24.269567100494108, &#39;depth&#39;: 6, &#39;min_data_in_leaf&#39;: 25, &#39;leaf_estimation_iterations&#39;: 3}. Best is trial 13 with value: 1.7451314700338245.
<span class="ansi-green-fg">[I 2021-06-24 11:54:58,325]</span> Trial 21 finished with value: 1.7452692941624655 and parameters: {&#39;iterations&#39;: 19379, &#39;od_wait&#39;: 2501, &#39;learning_rate&#39;: 0.01731967973088596, &#39;reg_lambda&#39;: 67.02388276657074, &#39;subsample&#39;: 0.41017468074284225, &#39;random_strength&#39;: 28.425587015156562, &#39;depth&#39;: 6, &#39;min_data_in_leaf&#39;: 26, &#39;leaf_estimation_iterations&#39;: 2}. Best is trial 13 with value: 1.7451314700338245.
<span class="ansi-green-fg">[I 2021-06-24 11:55:53,988]</span> Trial 22 finished with value: 1.7451029696916622 and parameters: {&#39;iterations&#39;: 19581, &#39;od_wait&#39;: 2429, &#39;learning_rate&#39;: 0.009876655991126419, &#39;reg_lambda&#39;: 71.53117835425219, &#39;subsample&#39;: 0.33074164017922814, &#39;random_strength&#39;: 29.442332429053916, &#39;depth&#39;: 6, &#39;min_data_in_leaf&#39;: 22, &#39;leaf_estimation_iterations&#39;: 2}. Best is trial 22 with value: 1.7451029696916622.
<span class="ansi-green-fg">[I 2021-06-24 11:56:56,652]</span> Trial 23 finished with value: 1.7451228273737278 and parameters: {&#39;iterations&#39;: 17343, &#39;od_wait&#39;: 2333, &#39;learning_rate&#39;: 0.007933666929867488, &#39;reg_lambda&#39;: 72.32861753721613, &#39;subsample&#39;: 0.33426802877805567, &#39;random_strength&#39;: 29.827205971007093, &#39;depth&#39;: 6, &#39;min_data_in_leaf&#39;: 22, &#39;leaf_estimation_iterations&#39;: 2}. Best is trial 22 with value: 1.7451029696916622.
<span class="ansi-green-fg">[I 2021-06-24 11:58:10,102]</span> Trial 24 finished with value: 1.7458064565335587 and parameters: {&#39;iterations&#39;: 16625, &#39;od_wait&#39;: 2283, &#39;learning_rate&#39;: 0.007837776980504339, &#39;reg_lambda&#39;: 72.71900246937989, &#39;subsample&#39;: 0.31289940592330956, &#39;random_strength&#39;: 29.965419880406152, &#39;depth&#39;: 5, &#39;min_data_in_leaf&#39;: 22, &#39;leaf_estimation_iterations&#39;: 3}. Best is trial 22 with value: 1.7451029696916622.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Number of finished trials: 25
Best trial: score 1.7451029696916622, params {&#39;iterations&#39;: 19581, &#39;od_wait&#39;: 2429, &#39;learning_rate&#39;: 0.009876655991126419, &#39;reg_lambda&#39;: 71.53117835425219, &#39;subsample&#39;: 0.33074164017922814, &#39;random_strength&#39;: 29.442332429053916, &#39;depth&#39;: 6, &#39;min_data_in_leaf&#39;: 22, &#39;leaf_estimation_iterations&#39;: 2}
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">if</span> <span class="n">OPTUNA_OPTIMIZATION</span><span class="p">:</span>
    <span class="n">display</span><span class="p">(</span><span class="n">optuna</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">plot_optimization_history</span><span class="p">(</span><span class="n">study</span><span class="p">))</span>
    <span class="n">display</span><span class="p">(</span><span class="n">optuna</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">plot_slice</span><span class="p">(</span><span class="n">study</span><span class="p">))</span>
    <span class="n">display</span><span class="p">(</span><span class="n">optuna</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">plot_parallel_coordinate</span><span class="p">(</span><span class="n">study</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<html>
<head><meta charset="utf-8" /></head>
<body>
    <div>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>
                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>    
            <div id="d20d0706-f9ed-422d-9c77-63dc405ba616" class="plotly-graph-div" style="height:525px; width:100%;"></div>
            <script type="text/javascript">
                
                    window.PLOTLYENV=window.PLOTLYENV || {};
                    
                if (document.getElementById("d20d0706-f9ed-422d-9c77-63dc405ba616")) {
                    Plotly.newPlot(
                        'd20d0706-f9ed-422d-9c77-63dc405ba616',
                        [{"mode": "markers", "name": "Objective Value", "type": "scatter", "x": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "y": [1.7475517290197657, 1.746530009869069, 1.746400371649169, 1.748109944775364, 1.7465947826600974, 1.7474099656786515, 1.7458479262869728, 1.7473726389629178, 1.7473827678729799, 1.7452546603418322, 1.7454383570512968, 1.7462246417016778, 1.7458295896690477, 1.7451314700338245, 1.745619726766246, 1.7469002864780332, 1.746074161484668, 1.7461189704019306, 1.7453019832535064, 1.7462970137394513, 1.745902916234771, 1.7452692941624655, 1.7451029696916622, 1.7451228273737278, 1.7458064565335587]}, {"name": "Best Value", "type": "scatter", "x": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "y": [1.7475517290197657, 1.746530009869069, 1.746400371649169, 1.746400371649169, 1.746400371649169, 1.746400371649169, 1.7458479262869728, 1.7458479262869728, 1.7458479262869728, 1.7452546603418322, 1.7452546603418322, 1.7452546603418322, 1.7452546603418322, 1.7451314700338245, 1.7451314700338245, 1.7451314700338245, 1.7451314700338245, 1.7451314700338245, 1.7451314700338245, 1.7451314700338245, 1.7451314700338245, 1.7451314700338245, 1.7451029696916622, 1.7451029696916622, 1.7451029696916622]}],
                        {"template": {"data": {"bar": [{"error_x": {"color": "#2a3f5f"}, "error_y": {"color": "#2a3f5f"}, "marker": {"line": {"color": "#E5ECF6", "width": 0.5}}, "type": "bar"}], "barpolar": [{"marker": {"line": {"color": "#E5ECF6", "width": 0.5}}, "type": "barpolar"}], "carpet": [{"aaxis": {"endlinecolor": "#2a3f5f", "gridcolor": "white", "linecolor": "white", "minorgridcolor": "white", "startlinecolor": "#2a3f5f"}, "baxis": {"endlinecolor": "#2a3f5f", "gridcolor": "white", "linecolor": "white", "minorgridcolor": "white", "startlinecolor": "#2a3f5f"}, "type": "carpet"}], "choropleth": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "type": "choropleth"}], "contour": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "contour"}], "contourcarpet": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "type": "contourcarpet"}], "heatmap": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "heatmap"}], "heatmapgl": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "heatmapgl"}], "histogram": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "histogram"}], "histogram2d": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "histogram2d"}], "histogram2dcontour": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "histogram2dcontour"}], "mesh3d": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "type": "mesh3d"}], "parcoords": [{"line": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "parcoords"}], "pie": [{"automargin": true, "type": "pie"}], "scatter": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scatter"}], "scatter3d": [{"line": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scatter3d"}], "scattercarpet": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scattercarpet"}], "scattergeo": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scattergeo"}], "scattergl": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scattergl"}], "scattermapbox": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scattermapbox"}], "scatterpolar": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scatterpolar"}], "scatterpolargl": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scatterpolargl"}], "scatterternary": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scatterternary"}], "surface": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "surface"}], "table": [{"cells": {"fill": {"color": "#EBF0F8"}, "line": {"color": "white"}}, "header": {"fill": {"color": "#C8D4E3"}, "line": {"color": "white"}}, "type": "table"}]}, "layout": {"annotationdefaults": {"arrowcolor": "#2a3f5f", "arrowhead": 0, "arrowwidth": 1}, "coloraxis": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "colorscale": {"diverging": [[0, "#8e0152"], [0.1, "#c51b7d"], [0.2, "#de77ae"], [0.3, "#f1b6da"], [0.4, "#fde0ef"], [0.5, "#f7f7f7"], [0.6, "#e6f5d0"], [0.7, "#b8e186"], [0.8, "#7fbc41"], [0.9, "#4d9221"], [1, "#276419"]], "sequential": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "sequentialminus": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]]}, "colorway": ["#636efa", "#EF553B", "#00cc96", "#ab63fa", "#FFA15A", "#19d3f3", "#FF6692", "#B6E880", "#FF97FF", "#FECB52"], "font": {"color": "#2a3f5f"}, "geo": {"bgcolor": "white", "lakecolor": "white", "landcolor": "#E5ECF6", "showlakes": true, "showland": true, "subunitcolor": "white"}, "hoverlabel": {"align": "left"}, "hovermode": "closest", "mapbox": {"style": "light"}, "paper_bgcolor": "white", "plot_bgcolor": "#E5ECF6", "polar": {"angularaxis": {"gridcolor": "white", "linecolor": "white", "ticks": ""}, "bgcolor": "#E5ECF6", "radialaxis": {"gridcolor": "white", "linecolor": "white", "ticks": ""}}, "scene": {"xaxis": {"backgroundcolor": "#E5ECF6", "gridcolor": "white", "gridwidth": 2, "linecolor": "white", "showbackground": true, "ticks": "", "zerolinecolor": "white"}, "yaxis": {"backgroundcolor": "#E5ECF6", "gridcolor": "white", "gridwidth": 2, "linecolor": "white", "showbackground": true, "ticks": "", "zerolinecolor": "white"}, "zaxis": {"backgroundcolor": "#E5ECF6", "gridcolor": "white", "gridwidth": 2, "linecolor": "white", "showbackground": true, "ticks": "", "zerolinecolor": "white"}}, "shapedefaults": {"line": {"color": "#2a3f5f"}}, "ternary": {"aaxis": {"gridcolor": "white", "linecolor": "white", "ticks": ""}, "baxis": {"gridcolor": "white", "linecolor": "white", "ticks": ""}, "bgcolor": "#E5ECF6", "caxis": {"gridcolor": "white", "linecolor": "white", "ticks": ""}}, "title": {"x": 0.05}, "xaxis": {"automargin": true, "gridcolor": "white", "linecolor": "white", "ticks": "", "title": {"standoff": 15}, "zerolinecolor": "white", "zerolinewidth": 2}, "yaxis": {"automargin": true, "gridcolor": "white", "linecolor": "white", "ticks": "", "title": {"standoff": 15}, "zerolinecolor": "white", "zerolinewidth": 2}}}, "title": {"text": "Optimization History Plot"}, "xaxis": {"title": {"text": "#Trials"}}, "yaxis": {"title": {"text": "Objective Value"}}},
                        {"responsive": true}
                    ).then(function(){
                            
var gd = document.getElementById('d20d0706-f9ed-422d-9c77-63dc405ba616');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })
                };
                
            </script>
        </div>
</body>
</html>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<html>
<head><meta charset="utf-8" /></head>
<body>
    <div>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>
                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>    
            <div id="c22053e8-4e13-4c09-a846-bf312d813ae5" class="plotly-graph-div" style="height:525px; width:2700px;"></div>
            <script type="text/javascript">
                
                    window.PLOTLYENV=window.PLOTLYENV || {};
                    
                if (document.getElementById("c22053e8-4e13-4c09-a846-bf312d813ae5")) {
                    Plotly.newPlot(
                        'c22053e8-4e13-4c09-a846-bf312d813ae5',
                        [{"marker": {"color": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "colorbar": {"title": {"text": "#Trials"}, "x": 1.0, "xpad": 40}, "colorscale": [[0.0, "rgb(247,251,255)"], [0.125, "rgb(222,235,247)"], [0.25, "rgb(198,219,239)"], [0.375, "rgb(158,202,225)"], [0.5, "rgb(107,174,214)"], [0.625, "rgb(66,146,198)"], [0.75, "rgb(33,113,181)"], [0.875, "rgb(8,81,156)"], [1.0, "rgb(8,48,107)"]], "line": {"color": "Grey", "width": 0.5}, "showscale": true}, "mode": "markers", "showlegend": false, "type": "scatter", "x": [3, 4, 4, 5, 5, 5, 5, 3, 4, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 6, 6, 5], "xaxis": "x", "y": [1.7475517290197657, 1.746530009869069, 1.746400371649169, 1.748109944775364, 1.7465947826600974, 1.7474099656786515, 1.7458479262869728, 1.7473726389629178, 1.7473827678729799, 1.7452546603418322, 1.7454383570512968, 1.7462246417016778, 1.7458295896690477, 1.7451314700338245, 1.745619726766246, 1.7469002864780332, 1.746074161484668, 1.7461189704019306, 1.7453019832535064, 1.7462970137394513, 1.745902916234771, 1.7452692941624655, 1.7451029696916622, 1.7451228273737278, 1.7458064565335587], "yaxis": "y"}, {"marker": {"color": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "colorbar": {"title": {"text": "#Trials"}, "x": 1.0, "xpad": 40}, "colorscale": [[0.0, "rgb(247,251,255)"], [0.125, "rgb(222,235,247)"], [0.25, "rgb(198,219,239)"], [0.375, "rgb(158,202,225)"], [0.5, "rgb(107,174,214)"], [0.625, "rgb(66,146,198)"], [0.75, "rgb(33,113,181)"], [0.875, "rgb(8,81,156)"], [1.0, "rgb(8,48,107)"]], "line": {"color": "Grey", "width": 0.5}, "showscale": false}, "mode": "markers", "showlegend": false, "type": "scatter", "x": [22081, 16107, 23051, 7837, 8561, 10633, 21137, 12020, 12637, 17673, 17665, 17865, 18732, 15303, 14608, 14612, 24879, 20820, 19400, 16079, 14047, 19379, 19581, 17343, 16625], "xaxis": "x2", "y": [1.7475517290197657, 1.746530009869069, 1.746400371649169, 1.748109944775364, 1.7465947826600974, 1.7474099656786515, 1.7458479262869728, 1.7473726389629178, 1.7473827678729799, 1.7452546603418322, 1.7454383570512968, 1.7462246417016778, 1.7458295896690477, 1.7451314700338245, 1.745619726766246, 1.7469002864780332, 1.746074161484668, 1.7461189704019306, 1.7453019832535064, 1.7462970137394513, 1.745902916234771, 1.7452692941624655, 1.7451029696916622, 1.7451228273737278, 1.7458064565335587], "yaxis": "y2"}, {"marker": {"color": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "colorbar": {"title": {"text": "#Trials"}, "x": 1.0, "xpad": 40}, "colorscale": [[0.0, "rgb(247,251,255)"], [0.125, "rgb(222,235,247)"], [0.25, "rgb(198,219,239)"], [0.375, "rgb(158,202,225)"], [0.5, "rgb(107,174,214)"], [0.625, "rgb(66,146,198)"], [0.75, "rgb(33,113,181)"], [0.875, "rgb(8,81,156)"], [1.0, "rgb(8,48,107)"]], "line": {"color": "Grey", "width": 0.5}, "showscale": false}, "mode": "markers", "showlegend": false, "type": "scatter", "x": [4, 3, 3, 5, 3, 6, 6, 2, 4, 2, 2, 2, 2, 2, 3, 2, 3, 5, 2, 4, 3, 2, 2, 2, 3], "xaxis": "x3", "y": [1.7475517290197657, 1.746530009869069, 1.746400371649169, 1.748109944775364, 1.7465947826600974, 1.7474099656786515, 1.7458479262869728, 1.7473726389629178, 1.7473827678729799, 1.7452546603418322, 1.7454383570512968, 1.7462246417016778, 1.7458295896690477, 1.7451314700338245, 1.745619726766246, 1.7469002864780332, 1.746074161484668, 1.7461189704019306, 1.7453019832535064, 1.7462970137394513, 1.745902916234771, 1.7452692941624655, 1.7451029696916622, 1.7451228273737278, 1.7458064565335587], "yaxis": "y3"}, {"marker": {"color": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "colorbar": {"title": {"text": "#Trials"}, "x": 1.0, "xpad": 40}, "colorscale": [[0.0, "rgb(247,251,255)"], [0.125, "rgb(222,235,247)"], [0.25, "rgb(198,219,239)"], [0.375, "rgb(158,202,225)"], [0.5, "rgb(107,174,214)"], [0.625, "rgb(66,146,198)"], [0.75, "rgb(33,113,181)"], [0.875, "rgb(8,81,156)"], [1.0, "rgb(8,48,107)"]], "line": {"color": "Grey", "width": 0.5}, "showscale": false}, "mode": "markers", "showlegend": false, "type": "scatter", "x": [0.0523585535392492, 0.020694951401143857, 0.013266322205507153, 0.08940487435096595, 0.051847639930613254, 0.03558483877482585, 0.009700927493295129, 0.05846745451734049, 0.08608747207630392, 0.014174736490140817, 0.0016874297825336618, 0.001201978817991051, 0.03347786451108715, 0.0025553641829274155, 0.024430072222760557, 0.07113034816909905, 0.03823712498063181, 0.0030749668653478617, 0.015569833679796617, 0.025921600027612537, 0.0014635190053216935, 0.01731967973088596, 0.009876655991126419, 0.007933666929867488, 0.007837776980504339], "xaxis": "x4", "y": [1.7475517290197657, 1.746530009869069, 1.746400371649169, 1.748109944775364, 1.7465947826600974, 1.7474099656786515, 1.7458479262869728, 1.7473726389629178, 1.7473827678729799, 1.7452546603418322, 1.7454383570512968, 1.7462246417016778, 1.7458295896690477, 1.7451314700338245, 1.745619726766246, 1.7469002864780332, 1.746074161484668, 1.7461189704019306, 1.7453019832535064, 1.7462970137394513, 1.745902916234771, 1.7452692941624655, 1.7451029696916622, 1.7451228273737278, 1.7458064565335587], "yaxis": "y4"}, {"marker": {"color": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "colorbar": {"title": {"text": "#Trials"}, "x": 1.0, "xpad": 40}, "colorscale": [[0.0, "rgb(247,251,255)"], [0.125, "rgb(222,235,247)"], [0.25, "rgb(198,219,239)"], [0.375, "rgb(158,202,225)"], [0.5, "rgb(107,174,214)"], [0.625, "rgb(66,146,198)"], [0.75, "rgb(33,113,181)"], [0.875, "rgb(8,81,156)"], [1.0, "rgb(8,48,107)"]], "line": {"color": "Grey", "width": 0.5}, "showscale": false}, "mode": "markers", "showlegend": false, "type": "scatter", "x": [17, 17, 20, 10, 28, 30, 27, 13, 28, 20, 23, 22, 23, 24, 25, 17, 20, 14, 25, 19, 25, 26, 22, 22, 22], "xaxis": "x5", "y": [1.7475517290197657, 1.746530009869069, 1.746400371649169, 1.748109944775364, 1.7465947826600974, 1.7474099656786515, 1.7458479262869728, 1.7473726389629178, 1.7473827678729799, 1.7452546603418322, 1.7454383570512968, 1.7462246417016778, 1.7458295896690477, 1.7451314700338245, 1.745619726766246, 1.7469002864780332, 1.746074161484668, 1.7461189704019306, 1.7453019832535064, 1.7462970137394513, 1.745902916234771, 1.7452692941624655, 1.7451029696916622, 1.7451228273737278, 1.7458064565335587], "yaxis": "y5"}, {"marker": {"color": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "colorbar": {"title": {"text": "#Trials"}, "x": 1.0, "xpad": 40}, "colorscale": [[0.0, "rgb(247,251,255)"], [0.125, "rgb(222,235,247)"], [0.25, "rgb(198,219,239)"], [0.375, "rgb(158,202,225)"], [0.5, "rgb(107,174,214)"], [0.625, "rgb(66,146,198)"], [0.75, "rgb(33,113,181)"], [0.875, "rgb(8,81,156)"], [1.0, "rgb(8,48,107)"]], "line": {"color": "Grey", "width": 0.5}, "showscale": false}, "mode": "markers", "showlegend": false, "type": "scatter", "x": [2890, 1934, 2708, 2024, 2482, 2781, 1612, 1538, 2891, 2363, 2344, 2324, 2465, 2091, 1988, 2112, 1795, 2192, 2588, 1740, 2176, 2501, 2429, 2333, 2283], "xaxis": "x6", "y": [1.7475517290197657, 1.746530009869069, 1.746400371649169, 1.748109944775364, 1.7465947826600974, 1.7474099656786515, 1.7458479262869728, 1.7473726389629178, 1.7473827678729799, 1.7452546603418322, 1.7454383570512968, 1.7462246417016778, 1.7458295896690477, 1.7451314700338245, 1.745619726766246, 1.7469002864780332, 1.746074161484668, 1.7461189704019306, 1.7453019832535064, 1.7462970137394513, 1.745902916234771, 1.7452692941624655, 1.7451029696916622, 1.7451228273737278, 1.7458064565335587], "yaxis": "y6"}, {"marker": {"color": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "colorbar": {"title": {"text": "#Trials"}, "x": 1.0, "xpad": 40}, "colorscale": [[0.0, "rgb(247,251,255)"], [0.125, "rgb(222,235,247)"], [0.25, "rgb(198,219,239)"], [0.375, "rgb(158,202,225)"], [0.5, "rgb(107,174,214)"], [0.625, "rgb(66,146,198)"], [0.75, "rgb(33,113,181)"], [0.875, "rgb(8,81,156)"], [1.0, "rgb(8,48,107)"]], "line": {"color": "Grey", "width": 0.5}, "showscale": false}, "mode": "markers", "showlegend": false, "type": "scatter", "x": [25.383248292425595, 18.674100622696255, 25.9671120082771, 21.96373022691814, 27.327853362663912, 25.28373658367917, 21.22381681406639, 18.086700126519453, 25.501737215394584, 20.629442387538404, 29.61502819684977, 28.885486735161823, 21.59810311874977, 29.811834598299864, 19.85206927527221, 23.235789931897173, 22.900672433164914, 20.345579982546628, 27.670942758083612, 19.33862638199317, 24.269567100494108, 28.425587015156562, 29.442332429053916, 29.827205971007093, 29.965419880406152], "xaxis": "x7", "y": [1.7475517290197657, 1.746530009869069, 1.746400371649169, 1.748109944775364, 1.7465947826600974, 1.7474099656786515, 1.7458479262869728, 1.7473726389629178, 1.7473827678729799, 1.7452546603418322, 1.7454383570512968, 1.7462246417016778, 1.7458295896690477, 1.7451314700338245, 1.745619726766246, 1.7469002864780332, 1.746074161484668, 1.7461189704019306, 1.7453019832535064, 1.7462970137394513, 1.745902916234771, 1.7452692941624655, 1.7451029696916622, 1.7451228273737278, 1.7458064565335587], "yaxis": "y7"}, {"marker": {"color": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "colorbar": {"title": {"text": "#Trials"}, "x": 1.0, "xpad": 40}, "colorscale": [[0.0, "rgb(247,251,255)"], [0.125, "rgb(222,235,247)"], [0.25, "rgb(198,219,239)"], [0.375, "rgb(158,202,225)"], [0.5, "rgb(107,174,214)"], [0.625, "rgb(66,146,198)"], [0.75, "rgb(33,113,181)"], [0.875, "rgb(8,81,156)"], [1.0, "rgb(8,48,107)"]], "line": {"color": "Grey", "width": 0.5}, "showscale": false}, "mode": "markers", "showlegend": false, "type": "scatter", "x": [53.30046637750339, 76.40295318744504, 68.80768412391788, 94.49408043431762, 88.8265560299443, 98.29738704750187, 75.30243026925147, 66.74096285230748, 52.33175708629835, 63.91819499977507, 61.262675395241985, 60.981201516164674, 59.97450248914125, 58.90581768346291, 83.54033041422643, 50.64443897027989, 68.81591565015204, 56.90191741891942, 64.9867731346661, 79.94197587917978, 56.304435706979824, 67.02388276657074, 71.53117835425219, 72.32861753721613, 72.71900246937989], "xaxis": "x8", "y": [1.7475517290197657, 1.746530009869069, 1.746400371649169, 1.748109944775364, 1.7465947826600974, 1.7474099656786515, 1.7458479262869728, 1.7473726389629178, 1.7473827678729799, 1.7452546603418322, 1.7454383570512968, 1.7462246417016778, 1.7458295896690477, 1.7451314700338245, 1.745619726766246, 1.7469002864780332, 1.746074161484668, 1.7461189704019306, 1.7453019832535064, 1.7462970137394513, 1.745902916234771, 1.7452692941624655, 1.7451029696916622, 1.7451228273737278, 1.7458064565335587], "yaxis": "y8"}, {"marker": {"color": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "colorbar": {"title": {"text": "#Trials"}, "x": 1.0, "xpad": 40}, "colorscale": [[0.0, "rgb(247,251,255)"], [0.125, "rgb(222,235,247)"], [0.25, "rgb(198,219,239)"], [0.375, "rgb(158,202,225)"], [0.5, "rgb(107,174,214)"], [0.625, "rgb(66,146,198)"], [0.75, "rgb(33,113,181)"], [0.875, "rgb(8,81,156)"], [1.0, "rgb(8,48,107)"]], "line": {"color": "Grey", "width": 0.5}, "showscale": false}, "mode": "markers", "showlegend": false, "type": "scatter", "x": [0.8322426285324465, 0.5779226659582111, 0.5917359474274496, 0.033697771735656246, 0.8561444452479751, 0.0016725576626520633, 0.6106777045552494, 0.5152141740529858, 0.8333242356914867, 0.15103934369387173, 0.22562898282554636, 0.2182601017873742, 0.25423345497514366, 0.2803752477508894, 0.33529647924209044, 0.09743289130986188, 0.39378640203502946, 0.1319154631507808, 0.4119976109071702, 0.11726613064624752, 0.7050889136259979, 0.41017468074284225, 0.33074164017922814, 0.33426802877805567, 0.31289940592330956], "xaxis": "x9", "y": [1.7475517290197657, 1.746530009869069, 1.746400371649169, 1.748109944775364, 1.7465947826600974, 1.7474099656786515, 1.7458479262869728, 1.7473726389629178, 1.7473827678729799, 1.7452546603418322, 1.7454383570512968, 1.7462246417016778, 1.7458295896690477, 1.7451314700338245, 1.745619726766246, 1.7469002864780332, 1.746074161484668, 1.7461189704019306, 1.7453019832535064, 1.7462970137394513, 1.745902916234771, 1.7452692941624655, 1.7451029696916622, 1.7451228273737278, 1.7458064565335587], "yaxis": "y9"}],
                        {"template": {"data": {"bar": [{"error_x": {"color": "#2a3f5f"}, "error_y": {"color": "#2a3f5f"}, "marker": {"line": {"color": "#E5ECF6", "width": 0.5}}, "type": "bar"}], "barpolar": [{"marker": {"line": {"color": "#E5ECF6", "width": 0.5}}, "type": "barpolar"}], "carpet": [{"aaxis": {"endlinecolor": "#2a3f5f", "gridcolor": "white", "linecolor": "white", "minorgridcolor": "white", "startlinecolor": "#2a3f5f"}, "baxis": {"endlinecolor": "#2a3f5f", "gridcolor": "white", "linecolor": "white", "minorgridcolor": "white", "startlinecolor": "#2a3f5f"}, "type": "carpet"}], "choropleth": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "type": "choropleth"}], "contour": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "contour"}], "contourcarpet": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "type": "contourcarpet"}], "heatmap": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "heatmap"}], "heatmapgl": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "heatmapgl"}], "histogram": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "histogram"}], "histogram2d": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "histogram2d"}], "histogram2dcontour": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "histogram2dcontour"}], "mesh3d": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "type": "mesh3d"}], "parcoords": [{"line": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "parcoords"}], "pie": [{"automargin": true, "type": "pie"}], "scatter": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scatter"}], "scatter3d": [{"line": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scatter3d"}], "scattercarpet": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scattercarpet"}], "scattergeo": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scattergeo"}], "scattergl": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scattergl"}], "scattermapbox": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scattermapbox"}], "scatterpolar": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scatterpolar"}], "scatterpolargl": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scatterpolargl"}], "scatterternary": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scatterternary"}], "surface": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "surface"}], "table": [{"cells": {"fill": {"color": "#EBF0F8"}, "line": {"color": "white"}}, "header": {"fill": {"color": "#C8D4E3"}, "line": {"color": "white"}}, "type": "table"}]}, "layout": {"annotationdefaults": {"arrowcolor": "#2a3f5f", "arrowhead": 0, "arrowwidth": 1}, "coloraxis": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "colorscale": {"diverging": [[0, "#8e0152"], [0.1, "#c51b7d"], [0.2, "#de77ae"], [0.3, "#f1b6da"], [0.4, "#fde0ef"], [0.5, "#f7f7f7"], [0.6, "#e6f5d0"], [0.7, "#b8e186"], [0.8, "#7fbc41"], [0.9, "#4d9221"], [1, "#276419"]], "sequential": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "sequentialminus": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]]}, "colorway": ["#636efa", "#EF553B", "#00cc96", "#ab63fa", "#FFA15A", "#19d3f3", "#FF6692", "#B6E880", "#FF97FF", "#FECB52"], "font": {"color": "#2a3f5f"}, "geo": {"bgcolor": "white", "lakecolor": "white", "landcolor": "#E5ECF6", "showlakes": true, "showland": true, "subunitcolor": "white"}, "hoverlabel": {"align": "left"}, "hovermode": "closest", "mapbox": {"style": "light"}, "paper_bgcolor": "white", "plot_bgcolor": "#E5ECF6", "polar": {"angularaxis": {"gridcolor": "white", "linecolor": "white", "ticks": ""}, "bgcolor": "#E5ECF6", "radialaxis": {"gridcolor": "white", "linecolor": "white", "ticks": ""}}, "scene": {"xaxis": {"backgroundcolor": "#E5ECF6", "gridcolor": "white", "gridwidth": 2, "linecolor": "white", "showbackground": true, "ticks": "", "zerolinecolor": "white"}, "yaxis": {"backgroundcolor": "#E5ECF6", "gridcolor": "white", "gridwidth": 2, "linecolor": "white", "showbackground": true, "ticks": "", "zerolinecolor": "white"}, "zaxis": {"backgroundcolor": "#E5ECF6", "gridcolor": "white", "gridwidth": 2, "linecolor": "white", "showbackground": true, "ticks": "", "zerolinecolor": "white"}}, "shapedefaults": {"line": {"color": "#2a3f5f"}}, "ternary": {"aaxis": {"gridcolor": "white", "linecolor": "white", "ticks": ""}, "baxis": {"gridcolor": "white", "linecolor": "white", "ticks": ""}, "bgcolor": "#E5ECF6", "caxis": {"gridcolor": "white", "linecolor": "white", "ticks": ""}}, "title": {"x": 0.05}, "xaxis": {"automargin": true, "gridcolor": "white", "linecolor": "white", "ticks": "", "title": {"standoff": 15}, "zerolinecolor": "white", "zerolinewidth": 2}, "yaxis": {"automargin": true, "gridcolor": "white", "linecolor": "white", "ticks": "", "title": {"standoff": 15}, "zerolinecolor": "white", "zerolinewidth": 2}}}, "title": {"text": "Slice Plot"}, "width": 2700, "xaxis": {"anchor": "y", "domain": [0.0, 0.09135802469135802], "title": {"text": "depth"}}, "xaxis2": {"anchor": "y2", "domain": [0.11358024691358025, 0.20493827160493827], "title": {"text": "iterations"}}, "xaxis3": {"anchor": "y3", "domain": [0.2271604938271605, 0.31851851851851853], "title": {"text": "leaf_estimation_iterations"}}, "xaxis4": {"anchor": "y4", "domain": [0.34074074074074073, 0.43209876543209874], "title": {"text": "learning_rate"}}, "xaxis5": {"anchor": "y5", "domain": [0.454320987654321, 0.5456790123456791], "title": {"text": "min_data_in_leaf"}}, "xaxis6": {"anchor": "y6", "domain": [0.5679012345679012, 0.6592592592592592], "title": {"text": "od_wait"}}, "xaxis7": {"anchor": "y7", "domain": [0.6814814814814815, 0.7728395061728395], "title": {"text": "random_strength"}}, "xaxis8": {"anchor": "y8", "domain": [0.7950617283950617, 0.8864197530864197], "title": {"text": "reg_lambda"}}, "xaxis9": {"anchor": "y9", "domain": [0.908641975308642, 1.0], "title": {"text": "subsample"}}, "yaxis": {"anchor": "x", "domain": [0.0, 1.0], "title": {"text": "Objective Value"}}, "yaxis2": {"anchor": "x2", "domain": [0.0, 1.0], "matches": "y", "showticklabels": false}, "yaxis3": {"anchor": "x3", "domain": [0.0, 1.0], "matches": "y", "showticklabels": false}, "yaxis4": {"anchor": "x4", "domain": [0.0, 1.0], "matches": "y", "showticklabels": false}, "yaxis5": {"anchor": "x5", "domain": [0.0, 1.0], "matches": "y", "showticklabels": false}, "yaxis6": {"anchor": "x6", "domain": [0.0, 1.0], "matches": "y", "showticklabels": false}, "yaxis7": {"anchor": "x7", "domain": [0.0, 1.0], "matches": "y", "showticklabels": false}, "yaxis8": {"anchor": "x8", "domain": [0.0, 1.0], "matches": "y", "showticklabels": false}, "yaxis9": {"anchor": "x9", "domain": [0.0, 1.0], "matches": "y", "showticklabels": false}},
                        {"responsive": true}
                    ).then(function(){
                            
var gd = document.getElementById('c22053e8-4e13-4c09-a846-bf312d813ae5');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })
                };
                
            </script>
        </div>
</body>
</html>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<html>
<head><meta charset="utf-8" /></head>
<body>
    <div>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>
                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>    
            <div id="0995cb3d-e950-40c5-a515-aa3eab7ad653" class="plotly-graph-div" style="height:525px; width:100%;"></div>
            <script type="text/javascript">
                
                    window.PLOTLYENV=window.PLOTLYENV || {};
                    
                if (document.getElementById("0995cb3d-e950-40c5-a515-aa3eab7ad653")) {
                    Plotly.newPlot(
                        '0995cb3d-e950-40c5-a515-aa3eab7ad653',
                        [{"dimensions": [{"label": "Objective Value", "range": [1.7451029696916622, 1.748109944775364], "values": [1.7475517290197657, 1.746530009869069, 1.746400371649169, 1.748109944775364, 1.7465947826600974, 1.7474099656786515, 1.7458479262869728, 1.7473726389629178, 1.7473827678729799, 1.7452546603418322, 1.7454383570512968, 1.7462246417016778, 1.7458295896690477, 1.7451314700338245, 1.745619726766246, 1.7469002864780332, 1.746074161484668, 1.7461189704019306, 1.7453019832535064, 1.7462970137394513, 1.745902916234771, 1.7452692941624655, 1.7451029696916622, 1.7451228273737278, 1.7458064565335587]}, {"label": "depth", "range": [3, 6], "values": [3, 4, 4, 5, 5, 5, 5, 3, 4, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 6, 6, 5]}, {"label": "iterations", "range": [7837, 24879], "values": [22081, 16107, 23051, 7837, 8561, 10633, 21137, 12020, 12637, 17673, 17665, 17865, 18732, 15303, 14608, 14612, 24879, 20820, 19400, 16079, 14047, 19379, 19581, 17343, 16625]}, {"label": "leaf_estimation_i...", "range": [2, 6], "values": [4, 3, 3, 5, 3, 6, 6, 2, 4, 2, 2, 2, 2, 2, 3, 2, 3, 5, 2, 4, 3, 2, 2, 2, 3]}, {"label": "learning_rate", "range": [0.001201978817991051, 0.08940487435096595], "values": [0.0523585535392492, 0.020694951401143857, 0.013266322205507153, 0.08940487435096595, 0.051847639930613254, 0.03558483877482585, 0.009700927493295129, 0.05846745451734049, 0.08608747207630392, 0.014174736490140817, 0.0016874297825336618, 0.001201978817991051, 0.03347786451108715, 0.0025553641829274155, 0.024430072222760557, 0.07113034816909905, 0.03823712498063181, 0.0030749668653478617, 0.015569833679796617, 0.025921600027612537, 0.0014635190053216935, 0.01731967973088596, 0.009876655991126419, 0.007933666929867488, 0.007837776980504339]}, {"label": "min_data_in_leaf", "range": [10, 30], "values": [17, 17, 20, 10, 28, 30, 27, 13, 28, 20, 23, 22, 23, 24, 25, 17, 20, 14, 25, 19, 25, 26, 22, 22, 22]}, {"label": "od_wait", "range": [1538, 2891], "values": [2890, 1934, 2708, 2024, 2482, 2781, 1612, 1538, 2891, 2363, 2344, 2324, 2465, 2091, 1988, 2112, 1795, 2192, 2588, 1740, 2176, 2501, 2429, 2333, 2283]}, {"label": "random_strength", "range": [18.086700126519453, 29.965419880406152], "values": [25.383248292425595, 18.674100622696255, 25.9671120082771, 21.96373022691814, 27.327853362663912, 25.28373658367917, 21.22381681406639, 18.086700126519453, 25.501737215394584, 20.629442387538404, 29.61502819684977, 28.885486735161823, 21.59810311874977, 29.811834598299864, 19.85206927527221, 23.235789931897173, 22.900672433164914, 20.345579982546628, 27.670942758083612, 19.33862638199317, 24.269567100494108, 28.425587015156562, 29.442332429053916, 29.827205971007093, 29.965419880406152]}, {"label": "reg_lambda", "range": [50.64443897027989, 98.29738704750187], "values": [53.30046637750339, 76.40295318744504, 68.80768412391788, 94.49408043431762, 88.8265560299443, 98.29738704750187, 75.30243026925147, 66.74096285230748, 52.33175708629835, 63.91819499977507, 61.262675395241985, 60.981201516164674, 59.97450248914125, 58.90581768346291, 83.54033041422643, 50.64443897027989, 68.81591565015204, 56.90191741891942, 64.9867731346661, 79.94197587917978, 56.304435706979824, 67.02388276657074, 71.53117835425219, 72.32861753721613, 72.71900246937989]}, {"label": "subsample", "range": [0.0016725576626520633, 0.8561444452479751], "values": [0.8322426285324465, 0.5779226659582111, 0.5917359474274496, 0.033697771735656246, 0.8561444452479751, 0.0016725576626520633, 0.6106777045552494, 0.5152141740529858, 0.8333242356914867, 0.15103934369387173, 0.22562898282554636, 0.2182601017873742, 0.25423345497514366, 0.2803752477508894, 0.33529647924209044, 0.09743289130986188, 0.39378640203502946, 0.1319154631507808, 0.4119976109071702, 0.11726613064624752, 0.7050889136259979, 0.41017468074284225, 0.33074164017922814, 0.33426802877805567, 0.31289940592330956]}], "labelangle": 30, "labelside": "bottom", "line": {"color": [1.7475517290197657, 1.746530009869069, 1.746400371649169, 1.748109944775364, 1.7465947826600974, 1.7474099656786515, 1.7458479262869728, 1.7473726389629178, 1.7473827678729799, 1.7452546603418322, 1.7454383570512968, 1.7462246417016778, 1.7458295896690477, 1.7451314700338245, 1.745619726766246, 1.7469002864780332, 1.746074161484668, 1.7461189704019306, 1.7453019832535064, 1.7462970137394513, 1.745902916234771, 1.7452692941624655, 1.7451029696916622, 1.7451228273737278, 1.7458064565335587], "colorbar": {"title": {"text": "Objective Value"}}, "colorscale": [[0.0, "rgb(247,251,255)"], [0.125, "rgb(222,235,247)"], [0.25, "rgb(198,219,239)"], [0.375, "rgb(158,202,225)"], [0.5, "rgb(107,174,214)"], [0.625, "rgb(66,146,198)"], [0.75, "rgb(33,113,181)"], [0.875, "rgb(8,81,156)"], [1.0, "rgb(8,48,107)"]], "reversescale": true, "showscale": true}, "type": "parcoords"}],
                        {"template": {"data": {"bar": [{"error_x": {"color": "#2a3f5f"}, "error_y": {"color": "#2a3f5f"}, "marker": {"line": {"color": "#E5ECF6", "width": 0.5}}, "type": "bar"}], "barpolar": [{"marker": {"line": {"color": "#E5ECF6", "width": 0.5}}, "type": "barpolar"}], "carpet": [{"aaxis": {"endlinecolor": "#2a3f5f", "gridcolor": "white", "linecolor": "white", "minorgridcolor": "white", "startlinecolor": "#2a3f5f"}, "baxis": {"endlinecolor": "#2a3f5f", "gridcolor": "white", "linecolor": "white", "minorgridcolor": "white", "startlinecolor": "#2a3f5f"}, "type": "carpet"}], "choropleth": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "type": "choropleth"}], "contour": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "contour"}], "contourcarpet": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "type": "contourcarpet"}], "heatmap": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "heatmap"}], "heatmapgl": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "heatmapgl"}], "histogram": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "histogram"}], "histogram2d": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "histogram2d"}], "histogram2dcontour": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "histogram2dcontour"}], "mesh3d": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "type": "mesh3d"}], "parcoords": [{"line": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "parcoords"}], "pie": [{"automargin": true, "type": "pie"}], "scatter": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scatter"}], "scatter3d": [{"line": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scatter3d"}], "scattercarpet": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scattercarpet"}], "scattergeo": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scattergeo"}], "scattergl": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scattergl"}], "scattermapbox": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scattermapbox"}], "scatterpolar": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scatterpolar"}], "scatterpolargl": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scatterpolargl"}], "scatterternary": [{"marker": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "type": "scatterternary"}], "surface": [{"colorbar": {"outlinewidth": 0, "ticks": ""}, "colorscale": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "type": "surface"}], "table": [{"cells": {"fill": {"color": "#EBF0F8"}, "line": {"color": "white"}}, "header": {"fill": {"color": "#C8D4E3"}, "line": {"color": "white"}}, "type": "table"}]}, "layout": {"annotationdefaults": {"arrowcolor": "#2a3f5f", "arrowhead": 0, "arrowwidth": 1}, "coloraxis": {"colorbar": {"outlinewidth": 0, "ticks": ""}}, "colorscale": {"diverging": [[0, "#8e0152"], [0.1, "#c51b7d"], [0.2, "#de77ae"], [0.3, "#f1b6da"], [0.4, "#fde0ef"], [0.5, "#f7f7f7"], [0.6, "#e6f5d0"], [0.7, "#b8e186"], [0.8, "#7fbc41"], [0.9, "#4d9221"], [1, "#276419"]], "sequential": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]], "sequentialminus": [[0.0, "#0d0887"], [0.1111111111111111, "#46039f"], [0.2222222222222222, "#7201a8"], [0.3333333333333333, "#9c179e"], [0.4444444444444444, "#bd3786"], [0.5555555555555556, "#d8576b"], [0.6666666666666666, "#ed7953"], [0.7777777777777778, "#fb9f3a"], [0.8888888888888888, "#fdca26"], [1.0, "#f0f921"]]}, "colorway": ["#636efa", "#EF553B", "#00cc96", "#ab63fa", "#FFA15A", "#19d3f3", "#FF6692", "#B6E880", "#FF97FF", "#FECB52"], "font": {"color": "#2a3f5f"}, "geo": {"bgcolor": "white", "lakecolor": "white", "landcolor": "#E5ECF6", "showlakes": true, "showland": true, "subunitcolor": "white"}, "hoverlabel": {"align": "left"}, "hovermode": "closest", "mapbox": {"style": "light"}, "paper_bgcolor": "white", "plot_bgcolor": "#E5ECF6", "polar": {"angularaxis": {"gridcolor": "white", "linecolor": "white", "ticks": ""}, "bgcolor": "#E5ECF6", "radialaxis": {"gridcolor": "white", "linecolor": "white", "ticks": ""}}, "scene": {"xaxis": {"backgroundcolor": "#E5ECF6", "gridcolor": "white", "gridwidth": 2, "linecolor": "white", "showbackground": true, "ticks": "", "zerolinecolor": "white"}, "yaxis": {"backgroundcolor": "#E5ECF6", "gridcolor": "white", "gridwidth": 2, "linecolor": "white", "showbackground": true, "ticks": "", "zerolinecolor": "white"}, "zaxis": {"backgroundcolor": "#E5ECF6", "gridcolor": "white", "gridwidth": 2, "linecolor": "white", "showbackground": true, "ticks": "", "zerolinecolor": "white"}}, "shapedefaults": {"line": {"color": "#2a3f5f"}}, "ternary": {"aaxis": {"gridcolor": "white", "linecolor": "white", "ticks": ""}, "baxis": {"gridcolor": "white", "linecolor": "white", "ticks": ""}, "bgcolor": "#E5ECF6", "caxis": {"gridcolor": "white", "linecolor": "white", "ticks": ""}}, "title": {"x": 0.05}, "xaxis": {"automargin": true, "gridcolor": "white", "linecolor": "white", "ticks": "", "title": {"standoff": 15}, "zerolinecolor": "white", "zerolinewidth": 2}, "yaxis": {"automargin": true, "gridcolor": "white", "linecolor": "white", "ticks": "", "title": {"standoff": 15}, "zerolinecolor": "white", "zerolinewidth": 2}}}, "title": {"text": "Parallel Coordinate Plot"}},
                        {"responsive": true}
                    ).then(function(){
                            
var gd = document.getElementById('0995cb3d-e950-40c5-a515-aa3eab7ad653');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })
                };
                
            </script>
        </div>
</body>
</html>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>

<span class="n">cat_params</span> <span class="o">=</span> <span class="n">study</span><span class="o">.</span><span class="n">best_trial</span><span class="o">.</span><span class="n">params</span>
<span class="n">cat_params</span><span class="p">[</span><span class="s1">&#39;loss_function&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;MultiClass&#39;</span>
<span class="n">cat_params</span><span class="p">[</span><span class="s1">&#39;eval_metric&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;MultiClass&#39;</span>
<span class="n">cat_params</span><span class="p">[</span><span class="s1">&#39;bootstrap_type&#39;</span><span class="p">]</span><span class="o">=</span> <span class="s1">&#39;Bernoulli&#39;</span>
<span class="n">cat_params</span><span class="p">[</span><span class="s1">&#39;leaf_estimation_method&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;Newton&#39;</span>
<span class="n">cat_params</span><span class="p">[</span><span class="s1">&#39;random_state&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">cat_params</span><span class="p">[</span><span class="s1">&#39;task_type&#39;</span><span class="p">]</span><span class="o">=</span><span class="s1">&#39;GPU&#39;</span>
<span class="n">test_preds</span><span class="o">=</span> <span class="kc">None</span>

<span class="n">splits_num</span> <span class="o">=</span> <span class="mi">25</span>

<span class="n">kf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span> <span class="o">=</span> <span class="n">splits_num</span> <span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span> <span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
<span class="k">for</span> <span class="n">fold</span><span class="p">,</span> <span class="p">(</span><span class="n">tr_index</span> <span class="p">,</span> <span class="n">val_index</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span> <span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">values</span><span class="p">)):</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fold </span><span class="si">{</span><span class="n">fold</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="n">x_train</span><span class="p">,</span><span class="n">x_val</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">tr_index</span><span class="p">]</span> <span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">val_index</span><span class="p">]</span>
    <span class="n">y_train</span><span class="p">,</span><span class="n">y_val</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">tr_index</span><span class="p">]</span> <span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">val_index</span><span class="p">]</span>
        
    <span class="n">eval_set</span> <span class="o">=</span> <span class="p">[(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)]</span>
    
    <span class="n">model</span> <span class="o">=</span><span class="n">CatBoostClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">cat_params</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">eval_set</span> <span class="o">=</span> <span class="n">eval_set</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
    
    <span class="n">train_preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>    
    <span class="n">val_preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x_val</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="n">log_loss</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">val_preds</span><span class="p">))</span>
    
    <span class="k">if</span> <span class="n">test_preds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">test_preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">indep_vars</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">test_preds</span> <span class="o">+=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">indep_vars</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">test_preds</span> <span class="o">/=</span> <span class="n">splits_num</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------------------------------------
Fold 1
1.749131290962051
--------------------------------------------------
Fold 2
1.7529425231280356
--------------------------------------------------
Fold 3
1.7441613430391134
--------------------------------------------------
Fold 4
1.7507247405855506
--------------------------------------------------
Fold 5
1.749730703947867
--------------------------------------------------
Fold 6
1.7416265027557527
--------------------------------------------------
Fold 7
1.7389727740147918
--------------------------------------------------
Fold 8
1.7461709330254438
--------------------------------------------------
Fold 9
1.7471508960803261
--------------------------------------------------
Fold 10
1.7329933410159393
--------------------------------------------------
Fold 11
1.744993746290057
--------------------------------------------------
Fold 12
1.7385173930583442
--------------------------------------------------
Fold 13
1.7469541940063509
--------------------------------------------------
Fold 14
1.7417066228071663
--------------------------------------------------
Fold 15
1.7476072977082582
--------------------------------------------------
Fold 16
1.7391476840534388
--------------------------------------------------
Fold 17
1.743906119554551
--------------------------------------------------
Fold 18
1.7485591143782357
--------------------------------------------------
Fold 19
1.744438403016501
--------------------------------------------------
Fold 20
1.7519072645447469
--------------------------------------------------
Fold 21
1.7449992198432482
--------------------------------------------------
Fold 22
1.7426330478083867
--------------------------------------------------
Fold 23
1.743329307101937
--------------------------------------------------
Fold 24
1.7427386418620936
--------------------------------------------------
Fold 25
1.748528083535207
--------------------------------------------------
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">y_train</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;Class_6&#39;, &#39;Class_6&#39;, &#39;Class_2&#39;, &#39;Class_8&#39;, &#39;Class_2&#39;, ..., &#39;Class_6&#39;, &#39;Class_6&#39;, &#39;Class_8&#39;, &#39;Class_7&#39;, &#39;Class_8&#39;]
Length: 199600
Categories (9, object): [&#39;Class_1&#39;, &#39;Class_2&#39;, &#39;Class_3&#39;, &#39;Class_4&#39;, ..., &#39;Class_6&#39;, &#39;Class_7&#39;,
                         &#39;Class_8&#39;, &#39;Class_9&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;sample_submission.csv.zip&quot;</span><span class="p">)</span>
<span class="n">submission</span><span class="p">[</span><span class="s1">&#39;Class_1&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">test_preds</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">submission</span><span class="p">[</span><span class="s1">&#39;Class_2&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">test_preds</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">submission</span><span class="p">[</span><span class="s1">&#39;Class_3&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">test_preds</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span>
<span class="n">submission</span><span class="p">[</span><span class="s1">&#39;Class_4&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">test_preds</span><span class="p">[:,</span><span class="mi">3</span><span class="p">]</span>
<span class="n">submission</span><span class="p">[</span><span class="s1">&#39;Class_5&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">test_preds</span><span class="p">[:,</span><span class="mi">4</span><span class="p">]</span>
<span class="n">submission</span><span class="p">[</span><span class="s1">&#39;Class_6&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">test_preds</span><span class="p">[:,</span><span class="mi">5</span><span class="p">]</span>
<span class="n">submission</span><span class="p">[</span><span class="s1">&#39;Class_7&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">test_preds</span><span class="p">[:,</span><span class="mi">6</span><span class="p">]</span>
<span class="n">submission</span><span class="p">[</span><span class="s1">&#39;Class_8&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">test_preds</span><span class="p">[:,</span><span class="mi">7</span><span class="p">]</span>
<span class="n">submission</span><span class="p">[</span><span class="s1">&#39;Class_9&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">test_preds</span><span class="p">[:,</span><span class="mi">8</span><span class="p">]</span>


<span class="n">submission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;submission.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="err">!</span><span class="n">kaggle</span> <span class="n">competitions</span> <span class="n">submit</span> <span class="o">-</span><span class="n">c</span> <span class="n">tabular</span><span class="o">-</span><span class="n">playground</span><span class="o">-</span><span class="n">series</span><span class="o">-</span><span class="n">jun</span><span class="o">-</span><span class="mi">2021</span> <span class="o">-</span><span class="n">f</span> <span class="n">submission</span><span class="o">.</span><span class="n">csv</span> <span class="o">-</span><span class="n">m</span> <span class="s2">&quot;Optimizing the hyperparameters using optuna -v2&quot;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Warning: Looks like you&#39;re using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)
100% 17.9M/17.9M [00:03&lt;00:00, 5.83MB/s]
Successfully submitted to Tabular Playground Series - Jun 2021</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s1">&#39;Catboost_optuna.model&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That helped reduce the error a bit, but I think I need to do quite a bit more to end up doing better than May</p>
<p><img src="data:image/png;base64,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" alt="image.png" /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Was able to crank up the model and reduce the error again.</p>
<p><img src="data:image/png;base64,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" alt="image.png" /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Rerun-the-model-and-look-at-feature-importances">Rerun the model and look at feature importances<a class="anchor-link" href="#Rerun-the-model-and-look-at-feature-importances"> </a></h2><p>I am now planning to rerun a simpler model using catboost for some iteratiosn and get a sense of the features that are most important for our model. And then rerun the optuna with the reduced number of features to get the final result</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">indep_vars</span><span class="p">],</span> <span class="n">train</span><span class="p">[</span><span class="n">dep_var</span><span class="p">],</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_validation</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validation</span> <span class="o">=</span> <span class="n">data</span>

<span class="n">train_pool</span> <span class="o">=</span> <span class="n">Pool</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> 
    <span class="n">label</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> 
    <span class="n">cat_features</span><span class="o">=</span><span class="n">indep_vars</span>
<span class="p">)</span>

<span class="n">validation_pool</span> <span class="o">=</span> <span class="n">Pool</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">X_validation</span><span class="p">,</span> 
    <span class="n">label</span><span class="o">=</span><span class="n">y_validation</span><span class="p">,</span> 
    <span class="n">cat_features</span><span class="o">=</span><span class="n">indep_vars</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_prev</span> <span class="o">=</span> <span class="n">CatBoostClassifier</span><span class="p">()</span>
<span class="n">model_prev</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;/content/Catboost_optuna_Jun21.model&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">CatBoostError</span>                             Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-8-719e78ae1a88&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> model_prev <span class="ansi-blue-fg">=</span> CatBoostClassifier<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span>model_prev<span class="ansi-blue-fg">.</span>load_model<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;/content/Catboost_optuna_Jun21.model&#34;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/catboost/core.py</span> in <span class="ansi-cyan-fg">load_model</span><span class="ansi-blue-fg">(self, fname, format, stream, blob)</span>
<span class="ansi-green-intense-fg ansi-bold">   2971</span> 
<span class="ansi-green-intense-fg ansi-bold">   2972</span>         <span class="ansi-green-fg">if</span> fname <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 2973</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>_load_model<span class="ansi-blue-fg">(</span>fname<span class="ansi-blue-fg">,</span> format<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   2974</span>         <span class="ansi-green-fg">elif</span> stream <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   2975</span>             self<span class="ansi-blue-fg">.</span>_load_from_stream<span class="ansi-blue-fg">(</span>stream<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/catboost/core.py</span> in <span class="ansi-cyan-fg">_load_model</span><span class="ansi-blue-fg">(self, model_file, format)</span>
<span class="ansi-green-intense-fg ansi-bold">   1519</span>             <span class="ansi-green-fg">raise</span> CatBoostError<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;Invalid fname type={}: must be str() or pathlib.Path().&#34;</span><span class="ansi-blue-fg">.</span>format<span class="ansi-blue-fg">(</span>type<span class="ansi-blue-fg">(</span>model_file<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1520</span> 
<span class="ansi-green-fg">-&gt; 1521</span><span class="ansi-red-fg">         </span>self<span class="ansi-blue-fg">.</span>_object<span class="ansi-blue-fg">.</span>_load_model<span class="ansi-blue-fg">(</span>model_file<span class="ansi-blue-fg">,</span> format<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1522</span>         self<span class="ansi-blue-fg">.</span>_set_trained_model_attributes<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1523</span>         <span class="ansi-green-fg">for</span> key<span class="ansi-blue-fg">,</span> value <span class="ansi-green-fg">in</span> iteritems<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_get_params<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">_catboost.pyx</span> in <span class="ansi-cyan-fg">_catboost._CatBoost._load_model</span><span class="ansi-blue-fg">()</span>

<span class="ansi-green-fg">_catboost.pyx</span> in <span class="ansi-cyan-fg">_catboost._CatBoost._load_model</span><span class="ansi-blue-fg">()</span>

<span class="ansi-red-fg">CatBoostError</span>: catboost/libs/model/model_import_interface.h:19: Model file doesn&#39;t exist: /content/Catboost_optuna_Jun21.model</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">prev_params</span> <span class="o">=</span> <span class="n">model_prev</span><span class="o">.</span><span class="n">get_all_params</span><span class="p">()</span>
<span class="n">model_feature</span> <span class="o">=</span> <span class="n">CatBoostClassifier</span><span class="p">()</span>

<span class="n">model_feature</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">prev_params</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;catboost.core.CatBoostClassifier at 0x7f7c16e0ff50&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_feature</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="p">,</span>  <span class="n">eval_set</span><span class="o">=</span><span class="n">validation_pool</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">CatBoostError</span>                             Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-56-57581050d03d&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> model_feature.fit(train_pool,
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg">     eval_set=validation_pool)
</span>
<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/catboost/core.py</span> in <span class="ansi-cyan-fg">fit</span><span class="ansi-blue-fg">(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)</span>
<span class="ansi-green-intense-fg ansi-bold">   4673</span>         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,
<span class="ansi-green-intense-fg ansi-bold">   4674</span>                   eval_set<span class="ansi-blue-fg">,</span> verbose<span class="ansi-blue-fg">,</span> logging_level<span class="ansi-blue-fg">,</span> plot<span class="ansi-blue-fg">,</span> column_description<span class="ansi-blue-fg">,</span> verbose_eval<span class="ansi-blue-fg">,</span> metric_period<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">-&gt; 4675</span><span class="ansi-red-fg">                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)
</span><span class="ansi-green-intense-fg ansi-bold">   4676</span>         <span class="ansi-green-fg">return</span> self
<span class="ansi-green-intense-fg ansi-bold">   4677</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/catboost/core.py</span> in <span class="ansi-cyan-fg">_fit</span><span class="ansi-blue-fg">(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)</span>
<span class="ansi-green-intense-fg ansi-bold">   1984</span>             silent<span class="ansi-blue-fg">=</span>silent<span class="ansi-blue-fg">,</span> early_stopping_rounds<span class="ansi-blue-fg">=</span>early_stopping_rounds<span class="ansi-blue-fg">,</span> save_snapshot<span class="ansi-blue-fg">=</span>save_snapshot<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1985</span>             snapshot_file<span class="ansi-blue-fg">=</span>snapshot_file<span class="ansi-blue-fg">,</span> snapshot_interval<span class="ansi-blue-fg">=</span>snapshot_interval<span class="ansi-blue-fg">,</span> init_model<span class="ansi-blue-fg">=</span>init_model<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">-&gt; 1986</span><span class="ansi-red-fg">             </span>callbacks<span class="ansi-blue-fg">=</span>callbacks
<span class="ansi-green-intense-fg ansi-bold">   1987</span>         )
<span class="ansi-green-intense-fg ansi-bold">   1988</span>         params <span class="ansi-blue-fg">=</span> train_params<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#34;params&#34;</span><span class="ansi-blue-fg">]</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/catboost/core.py</span> in <span class="ansi-cyan-fg">_prepare_train_params</span><span class="ansi-blue-fg">(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)</span>
<span class="ansi-green-intense-fg ansi-bold">   1908</span>         _check_param_types<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1909</span>         params <span class="ansi-blue-fg">=</span> _params_type_cast<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">-&gt; 1910</span><span class="ansi-red-fg">         </span>_check_train_params<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1911</span> 
<span class="ansi-green-intense-fg ansi-bold">   1912</span>         eval_set_list <span class="ansi-blue-fg">=</span> eval_set <span class="ansi-green-fg">if</span> isinstance<span class="ansi-blue-fg">(</span>eval_set<span class="ansi-blue-fg">,</span> list<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">else</span> <span class="ansi-blue-fg">[</span>eval_set<span class="ansi-blue-fg">]</span>

<span class="ansi-green-fg">_catboost.pyx</span> in <span class="ansi-cyan-fg">_catboost._check_train_params</span><span class="ansi-blue-fg">()</span>

<span class="ansi-green-fg">_catboost.pyx</span> in <span class="ansi-cyan-fg">_catboost._check_train_params</span><span class="ansi-blue-fg">()</span>

<span class="ansi-red-fg">CatBoostError</span>: catboost/private/libs/options/plain_options_helper.cpp:501: Unknown option {pinned_memory_bytes} with value &#34;104857600&#34;</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>USing Loss Function Change: This methodology meaures how much the loss function cahnges based on the fetaure changes. In this porcess we are training the model with the feature and then train the modle without the feature (This second precess is approximated by using we atre removing thsi feature from all the tress and avaraging the leaf values ad then saying that this would be the effect of dropping this feature from the prediction) This loss function change works well but is time-consuming. These feature importances is both positiove and negative and I will remove the features that affect the loss function negatively.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_prev</span><span class="o">.</span><span class="n">get_feature_importance</span><span class="p">(</span><span class="n">train_pool</span><span class="p">,</span> <span class="s1">&#39;LossFunctionChange&#39;</span><span class="p">,</span> <span class="n">prettified</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Custom logger is already specified. Specify more than one logger at same time is not thread safe.</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">CatBoostError</span>                             Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-46-140a894ae461&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span>model_prev<span class="ansi-blue-fg">.</span>get_feature_importance<span class="ansi-blue-fg">(</span>train_pool<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;LossFunctionChange&#39;</span><span class="ansi-blue-fg">,</span> prettified<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/catboost/core.py</span> in <span class="ansi-cyan-fg">get_feature_importance</span><span class="ansi-blue-fg">(self, data, type, prettified, thread_count, verbose, fstr_type, shap_mode, model_output, interaction_indices, shap_calc_type, reference_data, log_cout, log_cerr)</span>
<span class="ansi-green-intense-fg ansi-bold">   2772</span>             shap_calc_type <span class="ansi-blue-fg">=</span> enum_from_enum_or_str<span class="ansi-blue-fg">(</span>EShapCalcType<span class="ansi-blue-fg">,</span> shap_calc_type<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>value
<span class="ansi-green-intense-fg ansi-bold">   2773</span>             fstr, feature_names = self._calc_fstr(type, data, reference_data, thread_count, verbose, model_output, shap_mode, interaction_indices,
<span class="ansi-green-fg">-&gt; 2774</span><span class="ansi-red-fg">                                                   shap_calc_type)
</span><span class="ansi-green-intense-fg ansi-bold">   2775</span>         <span class="ansi-green-fg">if</span> type <span class="ansi-green-fg">in</span> <span class="ansi-blue-fg">(</span>EFstrType<span class="ansi-blue-fg">.</span>PredictionValuesChange<span class="ansi-blue-fg">,</span> EFstrType<span class="ansi-blue-fg">.</span>LossFunctionChange<span class="ansi-blue-fg">,</span> EFstrType<span class="ansi-blue-fg">.</span>PredictionDiff<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   2776</span>             feature_importances <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span>value<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span> <span class="ansi-green-fg">for</span> value <span class="ansi-green-fg">in</span> fstr<span class="ansi-blue-fg">]</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/catboost/core.py</span> in <span class="ansi-cyan-fg">_calc_fstr</span><span class="ansi-blue-fg">(self, type, pool, reference_data, thread_count, verbose, model_output, shap_mode, interaction_indices, shap_calc_type)</span>
<span class="ansi-green-intense-fg ansi-bold">   1494</span> 
<span class="ansi-green-intense-fg ansi-bold">   1495</span>     <span class="ansi-green-fg">def</span> _calc_fstr<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> type<span class="ansi-blue-fg">,</span> pool<span class="ansi-blue-fg">,</span> reference_data<span class="ansi-blue-fg">,</span> thread_count<span class="ansi-blue-fg">,</span> verbose<span class="ansi-blue-fg">,</span> model_output<span class="ansi-blue-fg">,</span> shap_mode<span class="ansi-blue-fg">,</span> interaction_indices<span class="ansi-blue-fg">,</span> shap_calc_type<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1496</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_object<span class="ansi-blue-fg">.</span>_calc_fstr<span class="ansi-blue-fg">(</span>type<span class="ansi-blue-fg">.</span>name<span class="ansi-blue-fg">,</span> pool<span class="ansi-blue-fg">,</span> reference_data<span class="ansi-blue-fg">,</span> thread_count<span class="ansi-blue-fg">,</span> verbose<span class="ansi-blue-fg">,</span> model_output<span class="ansi-blue-fg">,</span> shap_mode<span class="ansi-blue-fg">,</span> interaction_indices<span class="ansi-blue-fg">,</span> shap_calc_type<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1497</span> 
<span class="ansi-green-intense-fg ansi-bold">   1498</span>     <span class="ansi-green-fg">def</span> _calc_ostr<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> train_pool<span class="ansi-blue-fg">,</span> test_pool<span class="ansi-blue-fg">,</span> top_size<span class="ansi-blue-fg">,</span> ostr_type<span class="ansi-blue-fg">,</span> update_method<span class="ansi-blue-fg">,</span> importance_values_sign<span class="ansi-blue-fg">,</span> thread_count<span class="ansi-blue-fg">,</span> verbose<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">_catboost.pyx</span> in <span class="ansi-cyan-fg">_catboost._CatBoost._calc_fstr</span><span class="ansi-blue-fg">()</span>

<span class="ansi-green-fg">_catboost.pyx</span> in <span class="ansi-cyan-fg">_catboost._CatBoost._calc_fstr</span><span class="ansi-blue-fg">()</span>

<span class="ansi-red-fg">CatBoostError</span>: catboost/libs/data/model_dataset_compatibility.cpp:93: Feature feature_0 from pool must be Float.</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Using-TensorFlow-to-develop-a-NN-model">Using TensorFlow to develop a NN model<a class="anchor-link" href="#Using-TensorFlow-to-develop-a-NN-model"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">Reshape</span><span class="p">,</span> <span class="n">BatchNormalization</span><span class="p">,</span> <span class="n">Add</span><span class="p">,</span><span class="n">Dropout</span><span class="p">,</span> <span class="n">Conv1D</span><span class="p">,</span><span class="n">AveragePooling1D</span><span class="p">,</span><span class="n">Concatenate</span><span class="p">,</span> <span class="n">Average</span><span class="p">,</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">GlobalAveragePooling1D</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">AlphaDropout</span>

<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">RobustScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">class_weight</span>
<span class="c1">#from category_encoders.cat_boost import CatBoostEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">keras.backend</span> <span class="kn">import</span> <span class="n">int_shape</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;/content/train.csv.zip&#39;</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">train</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">train</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">train</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>
<span class="n">X</span><span class="o">=</span><span class="n">train</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">ClassModel</span><span class="p">(</span><span class="n">input_shape</span><span class="p">):</span>

    
    <span class="n">X_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Embedding</span> <span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">354</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">8</span><span class="p">)(</span><span class="n">X_input</span><span class="p">)</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">Conv1D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Conv1D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1">#X = GlobalAveragePooling1D()(X)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1">#X = Dropout(0.2)(X)</span>
    <span class="n">X2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">75</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">GlorotNormal</span><span class="p">(),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;lay1_a&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1">#X2 = BatchNormalization()(X2)</span>
    <span class="c1">#X2 = Dropout(0.2)(X2)</span>
    <span class="n">X2</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">X2</span><span class="p">)</span>
    <span class="n">X3</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">GlorotNormal</span><span class="p">(),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;lay1_b&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1">#X3 = BatchNormalization()(X3)</span>
    <span class="c1">#X3 = Dropout(0.2)(X3)</span>
    <span class="n">X3</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">X3</span><span class="p">)</span>
    <span class="n">X4</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">GlorotNormal</span><span class="p">(),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;lay1_c&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1">#X4 = BatchNormalization()(X4)</span>
    <span class="c1">#X4 = Dropout(0.2)(X4)</span>
    <span class="n">X4</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">X4</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Concatenate</span><span class="p">()([</span><span class="n">X2</span><span class="p">,</span><span class="n">X3</span><span class="p">,</span><span class="n">X4</span><span class="p">])</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;lay1&#39;</span><span class="p">,</span><span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1">#X = BatchNormalization(axis = -1, name = &#39;bn1&#39;)(X)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
<span class="c1">#     X = Dense(300, name=&#39;lay2&#39;,kernel_initializer=&#39;glorot_uniform&#39;)(X)</span>
<span class="c1">#     X = BatchNormalization(axis = -1, name = &#39;bn2&#39;)(X)</span>
<span class="c1">#     X = Dropout(0.4)(X)</span>
<span class="c1">#     X = Activation(&#39;relu&#39;)(X)</span>
<span class="c1">#     X = Dense(100, name=&#39;lay3&#39;,kernel_initializer=&#39;glorot_uniform&#39;)(X)</span>
<span class="c1">#     X = BatchNormalization(axis = -1, name = &#39;bn3&#39;)(X)</span>
<span class="c1">#     X = Dropout(0.4)(X)</span>
<span class="c1">#     X = Activation(&#39;relu&#39;)(X)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;lay4&#39;</span><span class="p">,</span><span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
<span class="c1">#     X = BatchNormalization(axis = -1, name = &#39;bn4&#39;)(X)</span>
<span class="c1">#     X = Dropout(0.4)(X)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>


    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">X_input</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;ClassModel&#39;</span><span class="p">)</span>

    
    <span class="k">return</span> <span class="n">model</span>

<span class="k">def</span> <span class="nf">ResModel</span><span class="p">(</span><span class="n">input_shape</span><span class="p">):</span>

    
    <span class="n">X_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Embedding</span> <span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">354</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">9</span><span class="p">)(</span><span class="n">X_input</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">75</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">GlorotNormal</span><span class="p">(),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;lay1_a&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1">#X2 = BatchNormalization()(X2)</span>
    <span class="c1">#X2 = Dropout(0.2)(X2)</span>
    <span class="n">X2</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">X2</span><span class="p">)</span>
    <span class="n">X3</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">GlorotNormal</span><span class="p">(),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;lay1_b&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1">#X3 = BatchNormalization()(X3)</span>
    <span class="c1">#X3 = Dropout(0.2)(X3)</span>
    <span class="n">X3</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">X3</span><span class="p">)</span>
    <span class="n">X4</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">GlorotNormal</span><span class="p">(),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;lay1_c&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1">#X4 = BatchNormalization()(X4)</span>
    <span class="c1">#X4 = Dropout(0.2)(X4)</span>
    <span class="n">X4</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">X4</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Concatenate</span><span class="p">()([</span><span class="n">X2</span><span class="p">,</span><span class="n">X3</span><span class="p">,</span><span class="n">X4</span><span class="p">])</span>
<span class="c1">#     X = Dropout(0.3)(X)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">GlorotNormal</span><span class="p">(),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;lay1&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
<span class="c1">#     X = BatchNormalization()(X)</span>
<span class="c1">#     X = Dropout(0.3)(X)</span>
    <span class="n">X1</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">GlorotNormal</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;lay2&#39;</span><span class="p">)(</span><span class="n">X1</span><span class="p">)</span>
    
<span class="c1">#     X = BatchNormalization()(X)</span>
<span class="c1">#     X = Dropout(0.3)(X)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">GlorotNormal</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;lay3&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
<span class="c1">#     X = BatchNormalization()(X)</span>
<span class="c1">#     X = Dropout(0.3)(X)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Add</span><span class="p">()([</span><span class="n">X1</span><span class="p">,</span><span class="n">X</span><span class="p">])</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">GlorotNormal</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;lay1a&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
<span class="c1">#     X = BatchNormalization()(X)</span>
<span class="c1">#     X = Dropout(0.3)(X)</span>

    <span class="n">X2</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">GlorotNormal</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;lay2a&#39;</span><span class="p">)(</span><span class="n">X1</span><span class="p">)</span>
<span class="c1">#     X = BatchNormalization()(X)</span>
<span class="c1">#     X = Dropout(0.3)(X)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">GlorotNormal</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;lay3a&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
<span class="c1">#     X = BatchNormalization()(X)</span>
<span class="c1">#     X = Dropout(0.3)(X)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Concatenate</span><span class="p">()([</span><span class="n">X2</span><span class="p">,</span><span class="n">X</span><span class="p">])</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Add</span><span class="p">()([</span><span class="n">X</span><span class="p">,</span><span class="n">X1</span><span class="p">])</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">GlorotNormal</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;lay1b&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
<span class="c1">#     X = BatchNormalization()(X)</span>
<span class="c1">#     X = Dropout(0.3)(X)</span>
    <span class="n">X3</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">GlorotNormal</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;lay2b&#39;</span><span class="p">)(</span><span class="n">X1</span><span class="p">)</span>
<span class="c1">#     X = BatchNormalization()(X)</span>
<span class="c1">#     X = Dropout(0.3)(X)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">GlorotNormal</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;lay3b&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
<span class="c1">#     X = BatchNormalization()(X)</span>
<span class="c1">#     X = Dropout(0.3)(X)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Concatenate</span><span class="p">()([</span><span class="n">X3</span><span class="p">,</span><span class="n">X2</span><span class="p">,</span><span class="n">X</span><span class="p">])</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Add</span><span class="p">()([</span><span class="n">X</span><span class="p">,</span><span class="n">X1</span><span class="p">])</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">GlorotNormal</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;final&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
    
    <span class="n">X</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output&#39;</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>


    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">X_input</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;ResModel&#39;</span><span class="p">)</span>

    
    <span class="k">return</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">prediction</span> <span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">):</span>
    
    <span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>

    <span class="n">kfold</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">100000</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
    <span class="n">train_oof</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">200000</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">kfold</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">):</span>
        <span class="n">train_idx</span><span class="p">,</span> <span class="n">val_idx</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">idx</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">xtrain</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
        <span class="n">ytrain</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
        <span class="n">xval</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">val_idx</span><span class="p">]</span>
        <span class="n">yval</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">val_idx</span><span class="p">]</span>
        <span class="n">ytrain</span> <span class="o">=</span> <span class="n">ytrain</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>
        <span class="n">yval</span> <span class="o">=</span> <span class="n">yval</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>
        <span class="n">ytrain</span><span class="o">-=</span><span class="mi">1</span>
        <span class="n">yval</span><span class="o">-=</span><span class="mi">1</span>
        <span class="n">ytrain</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">ytrain</span><span class="p">)</span>
        <span class="n">yval</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">yval</span><span class="p">)</span>


        
        <span class="c1">#checkpoint_filepath = &#39;/kaggle/working/ckpt1&#39;</span>
        
        <span class="c1">#model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(</span>
        <span class="c1">#            filepath=checkpoint_filepath,</span>
        <span class="c1">#            save_weights_only=True,</span>
        <span class="c1">#            monitor=&#39;val_loss&#39;,</span>
        <span class="c1">#            mode=&#39;min&#39;,</span>
        <span class="c1">#            save_best_only=True)</span>
        
        <span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>
        <span class="c1"># fit model for current fold</span>
        <span class="n">classmodel</span> <span class="o">=</span> <span class="n">ResModel</span><span class="p">(</span><span class="n">xtrain</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="n">classmodel</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
        
        <span class="n">classmodel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">xval</span><span class="p">,</span> <span class="n">yval</span><span class="p">)</span>
        <span class="c1">#callbacks=[model_checkpoint_callback]</span>
        <span class="p">)</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>
        <span class="c1">#classmodel.load_weights(checkpoint_filepath)</span>
        <span class="c1">#create predictions</span>
        <span class="n">y_pred</span> <span class="o">+=</span> <span class="n">classmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span><span class="o">/</span><span class="n">kfold</span><span class="o">.</span><span class="n">n_splits</span>
        <span class="c1">#print(y_pred)</span>
               
        <span class="n">val_pred</span> <span class="o">=</span> <span class="n">classmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xval</span><span class="p">)</span>
        <span class="c1"># getting out-of-fold predictions on training set</span>
        <span class="n">train_oof</span><span class="p">[</span><span class="n">val_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">val_pred</span>
        
        <span class="c1"># calculate and append logloss</span>
        <span class="n">fold_logloss</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">log_loss</span><span class="p">(</span><span class="n">yval</span><span class="p">,</span><span class="n">val_pred</span><span class="p">)</span>
        <span class="c1">#print(classmodel.evaluate(xval,yval))</span>
        <span class="c1">#classmodel.evaluate(xval,yval)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Logloss: </span><span class="si">{0:0.5f}</span><span class="s2">&quot;</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">fold_logloss</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">train_oof</span><span class="p">,</span> <span class="n">classmodel</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">X_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;/content/test.csv.zip&#39;</span><span class="p">)</span>
<span class="n">X_test</span><span class="o">=</span><span class="n">X_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">main_pred</span><span class="p">,</span> <span class="n">train_oof</span><span class="p">,</span> <span class="n">classmodel</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>
<span class="n">sub</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;/content/sample_submission.csv.zip&#39;</span><span class="p">)</span>
<span class="n">sub</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span><span class="o">=</span><span class="n">main_pred</span>
<span class="n">sub</span><span class="o">=</span><span class="n">sub</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">)</span>
<span class="n">sub</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;embmodel.csv&#39;</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">plot_model</span><span class="p">(</span><span class="n">classmodel</span><span class="p">,</span><span class="n">show_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/100
1407/1407 [==============================] - 10s 6ms/step - loss: 1.8119 - accuracy: 0.3328 - val_loss: 1.7867 - val_accuracy: 0.3453
Epoch 2/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7939 - accuracy: 0.3428 - val_loss: 1.7794 - val_accuracy: 0.3504
Epoch 3/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7730 - accuracy: 0.3519 - val_loss: 1.7491 - val_accuracy: 0.3620
Epoch 4/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7570 - accuracy: 0.3596 - val_loss: 1.7472 - val_accuracy: 0.3609
Epoch 5/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7558 - accuracy: 0.3594 - val_loss: 1.7490 - val_accuracy: 0.3513
Epoch 6/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7545 - accuracy: 0.3589 - val_loss: 1.7472 - val_accuracy: 0.3528
Epoch 7/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7537 - accuracy: 0.3598 - val_loss: 1.7520 - val_accuracy: 0.3560
Epoch 8/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7542 - accuracy: 0.3604 - val_loss: 1.7427 - val_accuracy: 0.3634
Epoch 9/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7533 - accuracy: 0.3607 - val_loss: 1.7466 - val_accuracy: 0.3632
Epoch 10/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7529 - accuracy: 0.3608 - val_loss: 1.7546 - val_accuracy: 0.3614
Epoch 11/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7511 - accuracy: 0.3613 - val_loss: 1.7470 - val_accuracy: 0.3644
Epoch 12/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7532 - accuracy: 0.3611 - val_loss: 1.7574 - val_accuracy: 0.3589
Epoch 13/100
1407/1407 [==============================] - 8s 5ms/step - loss: 1.7505 - accuracy: 0.3611 - val_loss: 1.7530 - val_accuracy: 0.3614
Epoch 14/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7491 - accuracy: 0.3621 - val_loss: 1.7482 - val_accuracy: 0.3593
Epoch 15/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7474 - accuracy: 0.3637 - val_loss: 1.7488 - val_accuracy: 0.3618
Epoch 16/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7484 - accuracy: 0.3623 - val_loss: 1.7516 - val_accuracy: 0.3640
Epoch 17/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7463 - accuracy: 0.3636 - val_loss: 1.7535 - val_accuracy: 0.3616
Epoch 18/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7458 - accuracy: 0.3633 - val_loss: 1.7742 - val_accuracy: 0.3553
Epoch 19/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7524 - accuracy: 0.3594 - val_loss: 1.7555 - val_accuracy: 0.3602
Epoch 20/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7441 - accuracy: 0.3635 - val_loss: 1.7621 - val_accuracy: 0.3593
Epoch 21/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7432 - accuracy: 0.3644 - val_loss: 1.7762 - val_accuracy: 0.3584
Epoch 22/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7426 - accuracy: 0.3652 - val_loss: 1.7618 - val_accuracy: 0.3602
Epoch 23/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7434 - accuracy: 0.3641 - val_loss: 1.7620 - val_accuracy: 0.3601
Epoch 24/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7408 - accuracy: 0.3652 - val_loss: 1.7675 - val_accuracy: 0.3595
Epoch 25/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7399 - accuracy: 0.3659 - val_loss: 1.7613 - val_accuracy: 0.3576
Epoch 26/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7398 - accuracy: 0.3654 - val_loss: 1.7615 - val_accuracy: 0.3575
Epoch 27/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7399 - accuracy: 0.3661 - val_loss: 1.7580 - val_accuracy: 0.3603
Epoch 28/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7379 - accuracy: 0.3671 - val_loss: 1.7609 - val_accuracy: 0.3611
Epoch 29/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7369 - accuracy: 0.3672 - val_loss: 1.7621 - val_accuracy: 0.3609
Epoch 30/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7399 - accuracy: 0.3670 - val_loss: 1.7670 - val_accuracy: 0.3584
Epoch 31/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7348 - accuracy: 0.3677 - val_loss: 1.7603 - val_accuracy: 0.3583
Epoch 32/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7356 - accuracy: 0.3688 - val_loss: 1.7653 - val_accuracy: 0.3593
Epoch 33/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7340 - accuracy: 0.3686 - val_loss: 1.7761 - val_accuracy: 0.3559
Epoch 34/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7331 - accuracy: 0.3686 - val_loss: 1.7569 - val_accuracy: 0.3614
Epoch 35/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7329 - accuracy: 0.3684 - val_loss: 1.8834 - val_accuracy: 0.3478
Epoch 36/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7342 - accuracy: 0.3677 - val_loss: 1.7696 - val_accuracy: 0.3604
Epoch 37/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7315 - accuracy: 0.3703 - val_loss: 1.7713 - val_accuracy: 0.3564
Epoch 38/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7331 - accuracy: 0.3690 - val_loss: 1.7691 - val_accuracy: 0.3576
Epoch 39/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7306 - accuracy: 0.3693 - val_loss: 1.7691 - val_accuracy: 0.3579
Epoch 40/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7313 - accuracy: 0.3692 - val_loss: 1.7754 - val_accuracy: 0.3538
Epoch 41/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7317 - accuracy: 0.3690 - val_loss: 1.7773 - val_accuracy: 0.3555
Epoch 42/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7292 - accuracy: 0.3703 - val_loss: 1.7684 - val_accuracy: 0.3607
Epoch 43/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7334 - accuracy: 0.3698 - val_loss: 1.7721 - val_accuracy: 0.3564
Epoch 44/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7312 - accuracy: 0.3690 - val_loss: 1.7765 - val_accuracy: 0.3501
Epoch 45/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7287 - accuracy: 0.3706 - val_loss: 1.7750 - val_accuracy: 0.3587
Epoch 46/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7272 - accuracy: 0.3719 - val_loss: 1.7906 - val_accuracy: 0.3528
Epoch 47/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7274 - accuracy: 0.3710 - val_loss: 1.7915 - val_accuracy: 0.3456
Epoch 48/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7261 - accuracy: 0.3720 - val_loss: 1.7853 - val_accuracy: 0.3576
Epoch 49/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7281 - accuracy: 0.3715 - val_loss: 1.7844 - val_accuracy: 0.3554
Epoch 50/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7255 - accuracy: 0.3726 - val_loss: 1.7985 - val_accuracy: 0.3541
Epoch 51/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7261 - accuracy: 0.3718 - val_loss: 1.7867 - val_accuracy: 0.3552
Epoch 52/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7276 - accuracy: 0.3720 - val_loss: 1.8046 - val_accuracy: 0.3564
Epoch 53/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7242 - accuracy: 0.3728 - val_loss: 1.7814 - val_accuracy: 0.3543
Epoch 54/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7278 - accuracy: 0.3715 - val_loss: 1.7797 - val_accuracy: 0.3562
Epoch 55/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7230 - accuracy: 0.3721 - val_loss: 1.7871 - val_accuracy: 0.3558
Epoch 56/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7244 - accuracy: 0.3722 - val_loss: 1.8158 - val_accuracy: 0.3525
Epoch 57/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7258 - accuracy: 0.3723 - val_loss: 1.8018 - val_accuracy: 0.3456
Epoch 58/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7225 - accuracy: 0.3733 - val_loss: 1.7970 - val_accuracy: 0.3537
Epoch 59/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7245 - accuracy: 0.3724 - val_loss: 1.7730 - val_accuracy: 0.3580
Epoch 60/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7214 - accuracy: 0.3731 - val_loss: 1.7817 - val_accuracy: 0.3550
Epoch 61/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7211 - accuracy: 0.3731 - val_loss: 1.7908 - val_accuracy: 0.3559
Epoch 62/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7209 - accuracy: 0.3735 - val_loss: 1.7898 - val_accuracy: 0.3577
Epoch 63/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7220 - accuracy: 0.3729 - val_loss: 1.8026 - val_accuracy: 0.3525
Epoch 64/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7215 - accuracy: 0.3725 - val_loss: 1.7850 - val_accuracy: 0.3569
Epoch 65/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7192 - accuracy: 0.3735 - val_loss: 1.7912 - val_accuracy: 0.3548
Epoch 66/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7189 - accuracy: 0.3738 - val_loss: 1.7926 - val_accuracy: 0.3508
Epoch 67/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7189 - accuracy: 0.3739 - val_loss: 1.8214 - val_accuracy: 0.3556
Epoch 68/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7192 - accuracy: 0.3746 - val_loss: 1.8049 - val_accuracy: 0.3539
Epoch 69/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7177 - accuracy: 0.3751 - val_loss: 1.7732 - val_accuracy: 0.3586
Epoch 70/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7176 - accuracy: 0.3749 - val_loss: 1.7920 - val_accuracy: 0.3518
Epoch 71/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7163 - accuracy: 0.3757 - val_loss: 1.7954 - val_accuracy: 0.3560
Epoch 72/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7179 - accuracy: 0.3742 - val_loss: 1.8405 - val_accuracy: 0.3525
Epoch 73/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7159 - accuracy: 0.3750 - val_loss: 1.8232 - val_accuracy: 0.3525
Epoch 74/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7152 - accuracy: 0.3743 - val_loss: 1.7864 - val_accuracy: 0.3577
Epoch 75/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7177 - accuracy: 0.3742 - val_loss: 1.8018 - val_accuracy: 0.3590
Epoch 76/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7173 - accuracy: 0.3748 - val_loss: 1.8259 - val_accuracy: 0.3519
Epoch 77/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7146 - accuracy: 0.3751 - val_loss: 1.8029 - val_accuracy: 0.3516
Epoch 78/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7159 - accuracy: 0.3747 - val_loss: 1.8008 - val_accuracy: 0.3582
Epoch 79/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7164 - accuracy: 0.3755 - val_loss: 1.7991 - val_accuracy: 0.3517
Epoch 80/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7244 - accuracy: 0.3728 - val_loss: 1.8075 - val_accuracy: 0.3500
Epoch 81/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7164 - accuracy: 0.3746 - val_loss: 1.8180 - val_accuracy: 0.3516
Epoch 82/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7143 - accuracy: 0.3757 - val_loss: 1.8191 - val_accuracy: 0.3530
Epoch 83/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7143 - accuracy: 0.3760 - val_loss: 1.8143 - val_accuracy: 0.3539
Epoch 84/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7136 - accuracy: 0.3754 - val_loss: 1.7971 - val_accuracy: 0.3550
Epoch 85/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7149 - accuracy: 0.3762 - val_loss: 1.8126 - val_accuracy: 0.3537
Epoch 86/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7124 - accuracy: 0.3765 - val_loss: 1.8053 - val_accuracy: 0.3566
Epoch 87/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7170 - accuracy: 0.3747 - val_loss: 1.8132 - val_accuracy: 0.3559
Epoch 88/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7114 - accuracy: 0.3758 - val_loss: 1.8188 - val_accuracy: 0.3547
Epoch 89/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7130 - accuracy: 0.3760 - val_loss: 1.8057 - val_accuracy: 0.3544
Epoch 90/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7127 - accuracy: 0.3768 - val_loss: 1.8257 - val_accuracy: 0.3531
Epoch 91/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7117 - accuracy: 0.3761 - val_loss: 1.8142 - val_accuracy: 0.3558
Epoch 92/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7181 - accuracy: 0.3748 - val_loss: 1.8673 - val_accuracy: 0.3418
Epoch 93/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7149 - accuracy: 0.3763 - val_loss: 1.8313 - val_accuracy: 0.3546
Epoch 94/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7120 - accuracy: 0.3756 - val_loss: 1.8237 - val_accuracy: 0.3554
Epoch 95/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.7283 - accuracy: 0.3701 - val_loss: 1.8336 - val_accuracy: 0.3232
Epoch 96/100
1407/1407 [==============================] - 8s 6ms/step - loss: 1.8054 - accuracy: 0.3367 - val_loss: 1.8036 - val_accuracy: 0.3481
Epoch 97/100
 100/1407 [=&gt;............................] - ETA: 6s - loss: 1.7206 - accuracy: 0.3765</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-10-c3f546bbe6d8&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> X_test <span class="ansi-blue-fg">=</span> pd<span class="ansi-blue-fg">.</span>read_csv<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;/content/test.csv.zip&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> X_test<span class="ansi-blue-fg">=</span>X_test<span class="ansi-blue-fg">.</span>iloc<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg"> </span>main_pred<span class="ansi-blue-fg">,</span> train_oof<span class="ansi-blue-fg">,</span> classmodel <span class="ansi-blue-fg">=</span> prediction<span class="ansi-blue-fg">(</span>X<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">,</span> X_test<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> sub <span class="ansi-blue-fg">=</span> pd<span class="ansi-blue-fg">.</span>read_csv<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;/content/sample_submission.csv.zip&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span> sub<span class="ansi-blue-fg">.</span>iloc<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">=</span>main_pred

<span class="ansi-green-fg">&lt;ipython-input-9-53507cb58a3d&gt;</span> in <span class="ansi-cyan-fg">prediction</span><span class="ansi-blue-fg">(X_train, y_train, X_test)</span>
<span class="ansi-green-intense-fg ansi-bold">     40</span>         classmodel.fit(xtrain, ytrain,
<span class="ansi-green-intense-fg ansi-bold">     41</span>         batch_size <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">128</span><span class="ansi-blue-fg">,</span> epochs <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">100</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">---&gt; 42</span><span class="ansi-red-fg">         </span>validation_data<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">(</span>xval<span class="ansi-blue-fg">,</span> yval<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     43</span>         <span class="ansi-red-fg">#callbacks=[model_checkpoint_callback]</span>
<span class="ansi-green-intense-fg ansi-bold">     44</span>         )

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py</span> in <span class="ansi-cyan-fg">fit</span><span class="ansi-blue-fg">(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)</span>
<span class="ansi-green-intense-fg ansi-bold">   1181</span>                 _r=1):
<span class="ansi-green-intense-fg ansi-bold">   1182</span>               callbacks<span class="ansi-blue-fg">.</span>on_train_batch_begin<span class="ansi-blue-fg">(</span>step<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">-&gt; 1183</span><span class="ansi-red-fg">               </span>tmp_logs <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>train_function<span class="ansi-blue-fg">(</span>iterator<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1184</span>               <span class="ansi-green-fg">if</span> data_handler<span class="ansi-blue-fg">.</span>should_sync<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1185</span>                 context<span class="ansi-blue-fg">.</span>async_wait<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, *args, **kwds)</span>
<span class="ansi-green-intense-fg ansi-bold">    887</span> 
<span class="ansi-green-intense-fg ansi-bold">    888</span>       <span class="ansi-green-fg">with</span> OptionalXlaContext<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_jit_compile<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 889</span><span class="ansi-red-fg">         </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_call<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwds<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    890</span> 
<span class="ansi-green-intense-fg ansi-bold">    891</span>       new_tracing_count <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>experimental_get_tracing_count<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py</span> in <span class="ansi-cyan-fg">_call</span><span class="ansi-blue-fg">(self, *args, **kwds)</span>
<span class="ansi-green-intense-fg ansi-bold">    915</span>       <span class="ansi-red-fg"># In this case we have created variables on the first call, so we run the</span>
<span class="ansi-green-intense-fg ansi-bold">    916</span>       <span class="ansi-red-fg"># defunned version which is guaranteed to never create variables.</span>
<span class="ansi-green-fg">--&gt; 917</span><span class="ansi-red-fg">       </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_stateless_fn<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwds<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># pylint: disable=not-callable</span>
<span class="ansi-green-intense-fg ansi-bold">    918</span>     <span class="ansi-green-fg">elif</span> self<span class="ansi-blue-fg">.</span>_stateful_fn <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    919</span>       <span class="ansi-red-fg"># Release the lock early so that multiple threads can perform the call</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   3022</span>        filtered_flat_args) = self._maybe_define_function(args, kwargs)
<span class="ansi-green-intense-fg ansi-bold">   3023</span>     return graph_function._call_flat(
<span class="ansi-green-fg">-&gt; 3024</span><span class="ansi-red-fg">         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
</span><span class="ansi-green-intense-fg ansi-bold">   3025</span> 
<span class="ansi-green-intense-fg ansi-bold">   3026</span>   <span class="ansi-blue-fg">@</span>property

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py</span> in <span class="ansi-cyan-fg">_call_flat</span><span class="ansi-blue-fg">(self, args, captured_inputs, cancellation_manager)</span>
<span class="ansi-green-intense-fg ansi-bold">   1959</span>       <span class="ansi-red-fg"># No tape is watching; skip to running the function.</span>
<span class="ansi-green-intense-fg ansi-bold">   1960</span>       return self._build_call_outputs(self._inference_function.call(
<span class="ansi-green-fg">-&gt; 1961</span><span class="ansi-red-fg">           ctx, args, cancellation_manager=cancellation_manager))
</span><span class="ansi-green-intense-fg ansi-bold">   1962</span>     forward_backward = self._select_forward_and_backward_functions(
<span class="ansi-green-intense-fg ansi-bold">   1963</span>         args<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py</span> in <span class="ansi-cyan-fg">call</span><span class="ansi-blue-fg">(self, ctx, args, cancellation_manager)</span>
<span class="ansi-green-intense-fg ansi-bold">    594</span>               inputs<span class="ansi-blue-fg">=</span>args<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    595</span>               attrs<span class="ansi-blue-fg">=</span>attrs<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 596</span><span class="ansi-red-fg">               ctx=ctx)
</span><span class="ansi-green-intense-fg ansi-bold">    597</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    598</span>           outputs = execute.execute_with_cancellation(

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py</span> in <span class="ansi-cyan-fg">quick_execute</span><span class="ansi-blue-fg">(op_name, num_outputs, inputs, attrs, ctx, name)</span>
<span class="ansi-green-intense-fg ansi-bold">     58</span>     ctx<span class="ansi-blue-fg">.</span>ensure_initialized<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     59</span>     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
<span class="ansi-green-fg">---&gt; 60</span><span class="ansi-red-fg">                                         inputs, attrs, num_outputs)
</span><span class="ansi-green-intense-fg ansi-bold">     61</span>   <span class="ansi-green-fg">except</span> core<span class="ansi-blue-fg">.</span>_NotOkStatusException <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     62</span>     <span class="ansi-green-fg">if</span> name <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">kaggle</span> <span class="n">competitions</span> <span class="n">submit</span> <span class="o">-</span><span class="n">c</span> <span class="n">tabular</span><span class="o">-</span><span class="n">playground</span><span class="o">-</span><span class="n">series</span><span class="o">-</span><span class="n">jun</span><span class="o">-</span><span class="mi">2021</span> <span class="o">-</span><span class="n">f</span> <span class="n">embmodel</span><span class="o">.</span><span class="n">csv</span> <span class="o">-</span><span class="n">m</span> <span class="s2">&quot;Embedding Model TensorFlow&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">classmodel</span><span class="o">.</span><span class="n">layers</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&lt;tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f51fddea490&gt;,
 &lt;tensorflow.python.keras.layers.embeddings.Embedding at 0x7f51fdded650&gt;,
 &lt;tensorflow.python.keras.layers.convolutional.Conv1D at 0x7f51fb16fa50&gt;,
 &lt;tensorflow.python.keras.layers.core.Flatten at 0x7f51f7a1ced0&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f51fddeb4d0&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f51fddee1d0&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f51fddf8250&gt;,
 &lt;tensorflow.python.keras.layers.core.Activation at 0x7f51fddee350&gt;,
 &lt;tensorflow.python.keras.layers.core.Activation at 0x7f51f7a1c410&gt;,
 &lt;tensorflow.python.keras.layers.core.Activation at 0x7f51fde1d4d0&gt;,
 &lt;tensorflow.python.keras.layers.merge.Concatenate at 0x7f51fddece90&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f51fde0b410&gt;,
 &lt;tensorflow.python.keras.layers.core.Activation at 0x7f51fddf8390&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f51fde06510&gt;,
 &lt;tensorflow.python.keras.layers.core.Activation at 0x7f51fe863b10&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f51fe863a90&gt;,
 &lt;tensorflow.python.keras.layers.core.Activation at 0x7f51fe863a10&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f51fe845fd0&gt;,
 &lt;tensorflow.python.keras.layers.merge.Add at 0x7f51fddec210&gt;,
 &lt;tensorflow.python.keras.layers.core.Activation at 0x7f51fe867050&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f51fde06150&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f51fddec490&gt;,
 &lt;tensorflow.python.keras.layers.core.Activation at 0x7f51fe845bd0&gt;,
 &lt;tensorflow.python.keras.layers.core.Activation at 0x7f51fb1d2310&gt;,
 &lt;tensorflow.python.keras.layers.merge.Concatenate at 0x7f51fb195a90&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f51fdded550&gt;,
 &lt;tensorflow.python.keras.layers.merge.Add at 0x7f51fde10110&gt;,
 &lt;tensorflow.python.keras.layers.core.Activation at 0x7f51fde06790&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f51fb12d7d0&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f51f7a0cc50&gt;,
 &lt;tensorflow.python.keras.layers.core.Activation at 0x7f51fe8522d0&gt;,
 &lt;tensorflow.python.keras.layers.core.Activation at 0x7f51f7a1cf90&gt;,
 &lt;tensorflow.python.keras.layers.merge.Concatenate at 0x7f51fde10a10&gt;,
 &lt;tensorflow.python.keras.layers.merge.Add at 0x7f51f7a1ae10&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f51fe849d10&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f51fddec450&gt;]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Using-Wandb-and-TensorFlow-to-build-and-improve-an-Embedding-NN-model">Using Wandb and TensorFlow to build and improve an Embedding NN model<a class="anchor-link" href="#Using-Wandb-and-TensorFlow-to-build-and-improve-an-Embedding-NN-model"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">wandb</span>
<span class="err">!</span><span class="n">wandb</span> <span class="n">login</span>

<span class="c1">#APi KEy: b5e2b28dc352c4319dbbf0a0c8555d3f8056a259</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting wandb
  Downloading https://files.pythonhosted.org/packages/e0/b4/9d92953d8cddc8450c859be12e3dbdd4c7754fb8def94c28b3b351c6ee4e/wandb-0.10.32-py2.py3-none-any.whl (1.8MB)
     |████████████████████████████████| 1.8MB 8.3MB/s 
Collecting configparser&gt;=3.8.1
  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl
Requirement already satisfied: Click!=8.0.0,&gt;=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)
Requirement already satisfied: protobuf&gt;=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)
Requirement already satisfied: six&gt;=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)
Requirement already satisfied: python-dateutil&gt;=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)
Collecting GitPython&gt;=1.0.0
  Downloading https://files.pythonhosted.org/packages/bc/91/b38c4fabb6e5092ab23492ded4f318ab7299b19263272b703478038c0fbc/GitPython-3.1.18-py3-none-any.whl (170kB)
     |████████████████████████████████| 174kB 40.2MB/s 
Collecting pathtools
  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz
Collecting subprocess32&gt;=3.5.3
  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)
     |████████████████████████████████| 102kB 13.5MB/s 
Collecting docker-pycreds&gt;=0.4.0
  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl
Requirement already satisfied: requests&lt;3,&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)
Collecting sentry-sdk&gt;=0.4.0
  Downloading https://files.pythonhosted.org/packages/1c/4a/a54b254f67d8f4052338d54ebe90126f200693440a93ef76d254d581e3ec/sentry_sdk-1.1.0-py2.py3-none-any.whl (131kB)
     |████████████████████████████████| 133kB 52.8MB/s 
Requirement already satisfied: psutil&gt;=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)
Requirement already satisfied: promise&lt;3,&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)
Collecting shortuuid&gt;=0.5.0
  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl
Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)
Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf&gt;=3.12.0-&gt;wandb) (57.0.0)
Collecting gitdb&lt;5,&gt;=4.0.1
  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)
     |████████████████████████████████| 71kB 11.9MB/s 
Requirement already satisfied: typing-extensions&gt;=3.7.4.0; python_version &lt; &#34;3.8&#34; in /usr/local/lib/python3.7/dist-packages (from GitPython&gt;=1.0.0-&gt;wandb) (3.7.4.3)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (3.0.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (2021.5.30)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (2.10)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (1.24.3)
Collecting smmap&lt;5,&gt;=3.0.1
  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl
Building wheels for collected packages: pathtools, subprocess32
  Building wheel for pathtools (setup.py) ... done
  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8807 sha256=5a5312db301ddc6081f58bf758bc6892fa54552553c49b3057bc72204510ac9e
  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843
  Building wheel for subprocess32 (setup.py) ... done
  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6502 sha256=e6b4cbd93c00090c0b36cb853a529048b0e0c996d65405c9c8bb0e8907202177
  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1
Successfully built pathtools subprocess32
Installing collected packages: configparser, smmap, gitdb, GitPython, pathtools, subprocess32, docker-pycreds, sentry-sdk, shortuuid, wandb
Successfully installed GitPython-3.1.18 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.1.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.32
<span class="ansi-blue-intense-fg ansi-bold">wandb</span>: You can find your API key in your browser here: https://wandb.ai/authorize
<span class="ansi-blue-intense-fg ansi-bold">wandb</span>: Paste an API key from your profile and hit enter: 
<span class="ansi-blue-intense-fg ansi-bold">wandb</span>: Appending key for api.wandb.ai to your netrc file: /root/.netrc
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="c1">#from tensorflow.keras.layers import Input, Dense, Activation, Reshape, BatchNormalization, Add,Dropout, Conv1D,AveragePooling1D,Concatenate, Average, Embedding, GlobalAveragePooling1D, Flatten, AlphaDropout</span>

<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">wandb</span>
<span class="kn">from</span> <span class="nn">wandb.keras</span> <span class="kn">import</span> <span class="n">WandbCallback</span>

<span class="n">wandb</span><span class="o">.</span><span class="n">login</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre><span class="ansi-blue-intense-fg ansi-bold">wandb</span>: Currently logged in as: <span class="ansi-yellow-fg">nitinkash</span> (use `wandb login --relogin` to force relogin)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>True</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;train.csv.zip&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;test.csv.zip&#39;</span><span class="p">)</span> 
<span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;sample_submission.csv.zip&#39;</span><span class="p">)</span>
<span class="n">submission</span> <span class="o">=</span> <span class="n">submission</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">)</span>

<span class="n">train</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">codes</span>

<span class="n">indep_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;feature_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">75</span><span class="p">)]</span>
<span class="n">dep_var</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">shape</span>
<span class="n">train</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">y</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0         5
1         5
2         1
3         7
4         1
         ..
199995    5
199996    5
199997    7
199998    6
199999    7
Name: target, Length: 200000, dtype: int8</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">emb_sizes</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Building-the-NEural-Network:">Building the NEural Network:<a class="anchor-link" href="#Building-the-NEural-Network:"> </a></h4>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">tensorflow_addons</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting tensorflow_addons
  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)
     |████████████████████████████████| 686kB 28.1MB/s 
Requirement already satisfied: typeguard&gt;=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)
Installing collected packages: tensorflow-addons
Successfully installed tensorflow-addons-0.13.0
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">log_loss</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">mutual_info_classif</span>

<span class="kn">import</span> <span class="nn">gc</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_addons</span> <span class="k">as</span> <span class="nn">tfa</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras.backend</span> <span class="k">as</span> <span class="nn">K</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">activations</span><span class="p">,</span><span class="n">callbacks</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.metrics</span> <span class="kn">import</span> <span class="n">categorical_crossentropy</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">initializers</span>

<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">custom_metric</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="mf">1e-15</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="mf">1e-15</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cce</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">loss</span>

<span class="n">cce</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">CategoricalCrossentropy</span><span class="p">()</span>

<span class="n">es</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span>
    <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_custom_metric&#39;</span><span class="p">,</span> <span class="n">min_delta</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="n">baseline</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plateau</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span>
    <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_custom_metric&#39;</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">conv_model1</span><span class="p">():</span>

    <span class="n">conv_inputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">75</span><span class="p">))</span>
    <span class="n">embed</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span> <span class="p">(</span><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">354</span><span class="p">,</span> 
                              <span class="n">output_dim</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span>
                              <span class="n">embeddings_regularizer</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">)(</span><span class="n">conv_inputs</span><span class="p">)</span>
    <span class="n">embed</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">embed</span><span class="p">)</span>        
    <span class="n">embed</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">embed</span><span class="p">)</span>
    <span class="n">hidden</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)(</span><span class="n">embed</span><span class="p">)</span>
    
    <span class="n">hidden</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">WeightNormalization</span><span class="p">(</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
                <span class="n">units</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                <span class="n">activation</span> <span class="o">=</span><span class="s1">&#39;selu&#39;</span><span class="p">,</span>
                <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s2">&quot;lecun_normal&quot;</span><span class="p">))(</span><span class="n">hidden</span><span class="p">)</span>
    
    <span class="n">output</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)(</span><span class="n">layers</span><span class="o">.</span><span class="n">Concatenate</span><span class="p">()([</span><span class="n">embed</span><span class="p">,</span> <span class="n">hidden</span><span class="p">]))</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">WeightNormalization</span><span class="p">(</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
                <span class="n">units</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
                <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
                <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s2">&quot;lecun_normal&quot;</span><span class="p">))(</span><span class="n">output</span><span class="p">)</span> 
    <span class="n">output</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)(</span><span class="n">layers</span><span class="o">.</span><span class="n">Concatenate</span><span class="p">()([</span><span class="n">embed</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">output</span><span class="p">]))</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">WeightNormalization</span><span class="p">(</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
                <span class="n">units</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> 
                <span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;relu&#39;</span><span class="p">,</span>
                <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s2">&quot;lecun_normal&quot;</span><span class="p">))(</span><span class="n">output</span><span class="p">)</span>
    
    <span class="n">conv_outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
                <span class="n">units</span> <span class="o">=</span> <span class="mi">9</span><span class="p">,</span> 
                <span class="n">activation</span> <span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span>
                <span class="n">kernel_initializer</span> <span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">)(</span><span class="n">output</span><span class="p">)</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">conv_inputs</span><span class="p">,</span><span class="n">conv_outputs</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;train.csv.zip&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;test.csv.zip&#39;</span><span class="p">)</span> 
<span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;sample_submission.csv.zip&#39;</span><span class="p">)</span>
<span class="n">submission</span> <span class="o">=</span> <span class="n">submission</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">)</span>

<span class="n">targets</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>
<span class="n">dic</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Class_1&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;Class_2&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="s1">&#39;Class_3&#39;</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span><span class="s1">&#39;Class_4&#39;</span><span class="p">:</span><span class="mi">4</span><span class="p">,</span><span class="s1">&#39;Class_5&#39;</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span><span class="s1">&#39;Class_6&#39;</span><span class="p">:</span><span class="mi">6</span><span class="p">,</span><span class="s1">&#39;Class_7&#39;</span><span class="p">:</span><span class="mi">7</span><span class="p">,</span><span class="s1">&#39;Class_8&#39;</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span><span class="s1">&#39;Class_9&#39;</span><span class="p">:</span><span class="mi">9</span><span class="p">}</span>
<span class="n">target_num</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">dic</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">y_valids</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">oof_NN_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">9</span><span class="p">))</span>
<span class="n">pred_NN_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">9</span><span class="p">))</span>
<span class="n">pred_NN_class_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">9</span><span class="p">))</span>

<span class="n">oof_NN_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">9</span><span class="p">))</span>
<span class="n">pred_NN_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">9</span><span class="p">))</span>
<span class="n">pred_NN_a_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">9</span><span class="p">))</span>

<span class="n">oof_NN_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">9</span><span class="p">))</span>
<span class="n">pred_NN_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">9</span><span class="p">))</span>
<span class="n">pred_NN_h_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">9</span><span class="p">))</span>

<span class="n">oof_NN_v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">9</span><span class="p">))</span>
<span class="n">pred_NN_v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">9</span><span class="p">))</span>
<span class="n">pred_NN_v_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">9</span><span class="p">))</span>

<span class="n">NN_c_train_preds</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">NN_c_test_preds</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">NN_h_train_preds</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">NN_h_test_preds</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">NN_v_train_preds</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">NN_v_test_preds</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">NN_a_train_preds</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">NN_a_test_preds</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">N_FOLDS</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">SEED</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">EPOCH</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">N_round</span> <span class="o">=</span> <span class="mi">2</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_round</span> <span class="p">):</span>
    
    
    <span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">N_FOLDS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span> <span class="n">SEED</span> <span class="o">*</span> <span class="n">i</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> =========== ROUND </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> ===============</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">fold</span><span class="p">,</span> <span class="p">(</span><span class="n">tr_idx</span><span class="p">,</span> <span class="n">ts_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">])):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--------TRAINING FOLD </span><span class="si">{</span><span class="n">fold</span><span class="si">}</span><span class="s2"> ---------</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">X_train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">tr_idx</span><span class="p">]</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">tr_idx</span><span class="p">]</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">ts_idx</span><span class="p">]</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">ts_idx</span><span class="p">]</span>

        <span class="n">K</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>

        <span class="c1">#================= NN CONV MODEL training =========</span>

        <span class="n">model_conv</span> <span class="o">=</span> <span class="n">conv_model1</span><span class="p">()</span>

        <span class="n">model_conv</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> 
                                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">),</span> 
                                <span class="n">metrics</span><span class="o">=</span><span class="n">custom_metric</span><span class="p">)</span>
        <span class="n">model_conv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
                  <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="n">EPOCH</span><span class="p">,</span>
                  <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
                  <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">es</span><span class="p">,</span> <span class="n">plateau</span><span class="p">],</span>
                  <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1">#============== Convolution Model prediction ==========</span>

        <span class="n">pred_a</span> <span class="o">=</span> <span class="n">model_conv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="n">pred_a1</span> <span class="o">=</span> <span class="n">model_conv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
        <span class="n">oof_NN_a</span><span class="p">[</span><span class="n">ts_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">pred_a</span> 
        <span class="n">score_NN_a</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_a</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Score Model 1: </span><span class="si">{</span><span class="n">score_NN_a</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">pred_NN_a</span> <span class="o">+=</span> <span class="n">model_conv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:])</span> <span class="o">/</span> <span class="n">N_FOLDS</span>
        <span class="n">pred_NN_a_all</span> <span class="o">+=</span> <span class="n">model_conv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:])</span> <span class="o">/</span> <span class="n">N_FOLDS</span> <span class="o">/</span> <span class="n">N_round</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
 =========== ROUND 1 ===============


--------TRAINING FOLD 0 ---------

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Exception ignored in: &lt;function IteratorResourceDeleter.__del__ at 0x7f30390b17a0&gt;
Traceback (most recent call last):
  File &#34;/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py&#34;, line 546, in __del__
    handle=self._handle, deleter=self._deleter)
  File &#34;/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py&#34;, line 1264, in delete_iterator
    _ctx, &#34;DeleteIterator&#34;, name, handle, deleter)
KeyboardInterrupt: 
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Score Model 1: 1.7373326778588816

--------TRAINING FOLD 1 ---------

Score Model 1: 1.7429528020713478

--------TRAINING FOLD 2 ---------

Score Model 1: 1.756215072916355

--------TRAINING FOLD 3 ---------

Score Model 1: 1.761630692366045

--------TRAINING FOLD 4 ---------

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-18-7b162c497acc&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     62</span>                   validation_data<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">(</span>X_test<span class="ansi-blue-fg">,</span> y_test<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     63</span>                   callbacks<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">[</span>es<span class="ansi-blue-fg">,</span> plateau<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">---&gt; 64</span><span class="ansi-red-fg">                   verbose = 0)
</span><span class="ansi-green-intense-fg ansi-bold">     65</span> 
<span class="ansi-green-intense-fg ansi-bold">     66</span>         <span class="ansi-red-fg">#============== Convolution Model prediction ==========</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/keras/engine/training.py</span> in <span class="ansi-cyan-fg">fit</span><span class="ansi-blue-fg">(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)</span>
<span class="ansi-green-intense-fg ansi-bold">   1156</span>                 _r=1):
<span class="ansi-green-intense-fg ansi-bold">   1157</span>               callbacks<span class="ansi-blue-fg">.</span>on_train_batch_begin<span class="ansi-blue-fg">(</span>step<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">-&gt; 1158</span><span class="ansi-red-fg">               </span>tmp_logs <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>train_function<span class="ansi-blue-fg">(</span>iterator<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1159</span>               <span class="ansi-green-fg">if</span> data_handler<span class="ansi-blue-fg">.</span>should_sync<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1160</span>                 context<span class="ansi-blue-fg">.</span>async_wait<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, *args, **kwds)</span>
<span class="ansi-green-intense-fg ansi-bold">    887</span> 
<span class="ansi-green-intense-fg ansi-bold">    888</span>       <span class="ansi-green-fg">with</span> OptionalXlaContext<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_jit_compile<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 889</span><span class="ansi-red-fg">         </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_call<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwds<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    890</span> 
<span class="ansi-green-intense-fg ansi-bold">    891</span>       new_tracing_count <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>experimental_get_tracing_count<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py</span> in <span class="ansi-cyan-fg">_call</span><span class="ansi-blue-fg">(self, *args, **kwds)</span>
<span class="ansi-green-intense-fg ansi-bold">    915</span>       <span class="ansi-red-fg"># In this case we have created variables on the first call, so we run the</span>
<span class="ansi-green-intense-fg ansi-bold">    916</span>       <span class="ansi-red-fg"># defunned version which is guaranteed to never create variables.</span>
<span class="ansi-green-fg">--&gt; 917</span><span class="ansi-red-fg">       </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_stateless_fn<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwds<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># pylint: disable=not-callable</span>
<span class="ansi-green-intense-fg ansi-bold">    918</span>     <span class="ansi-green-fg">elif</span> self<span class="ansi-blue-fg">.</span>_stateful_fn <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    919</span>       <span class="ansi-red-fg"># Release the lock early so that multiple threads can perform the call</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   3022</span>        filtered_flat_args) = self._maybe_define_function(args, kwargs)
<span class="ansi-green-intense-fg ansi-bold">   3023</span>     return graph_function._call_flat(
<span class="ansi-green-fg">-&gt; 3024</span><span class="ansi-red-fg">         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
</span><span class="ansi-green-intense-fg ansi-bold">   3025</span> 
<span class="ansi-green-intense-fg ansi-bold">   3026</span>   <span class="ansi-blue-fg">@</span>property

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py</span> in <span class="ansi-cyan-fg">_call_flat</span><span class="ansi-blue-fg">(self, args, captured_inputs, cancellation_manager)</span>
<span class="ansi-green-intense-fg ansi-bold">   1959</span>       <span class="ansi-red-fg"># No tape is watching; skip to running the function.</span>
<span class="ansi-green-intense-fg ansi-bold">   1960</span>       return self._build_call_outputs(self._inference_function.call(
<span class="ansi-green-fg">-&gt; 1961</span><span class="ansi-red-fg">           ctx, args, cancellation_manager=cancellation_manager))
</span><span class="ansi-green-intense-fg ansi-bold">   1962</span>     forward_backward = self._select_forward_and_backward_functions(
<span class="ansi-green-intense-fg ansi-bold">   1963</span>         args<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py</span> in <span class="ansi-cyan-fg">call</span><span class="ansi-blue-fg">(self, ctx, args, cancellation_manager)</span>
<span class="ansi-green-intense-fg ansi-bold">    594</span>               inputs<span class="ansi-blue-fg">=</span>args<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    595</span>               attrs<span class="ansi-blue-fg">=</span>attrs<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 596</span><span class="ansi-red-fg">               ctx=ctx)
</span><span class="ansi-green-intense-fg ansi-bold">    597</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    598</span>           outputs = execute.execute_with_cancellation(

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py</span> in <span class="ansi-cyan-fg">quick_execute</span><span class="ansi-blue-fg">(op_name, num_outputs, inputs, attrs, ctx, name)</span>
<span class="ansi-green-intense-fg ansi-bold">     58</span>     ctx<span class="ansi-blue-fg">.</span>ensure_initialized<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     59</span>     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
<span class="ansi-green-fg">---&gt; 60</span><span class="ansi-red-fg">                                         inputs, attrs, num_outputs)
</span><span class="ansi-green-intense-fg ansi-bold">     61</span>   <span class="ansi-green-fg">except</span> core<span class="ansi-blue-fg">.</span>_NotOkStatusException <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     62</span>     <span class="ansi-green-fg">if</span> name <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">submission</span><span class="p">[[</span><span class="s1">&#39;Class_1&#39;</span><span class="p">,</span> <span class="s1">&#39;Class_2&#39;</span><span class="p">,</span> <span class="s1">&#39;Class_3&#39;</span><span class="p">,</span> <span class="s1">&#39;Class_4&#39;</span><span class="p">,</span><span class="s1">&#39;Class_5&#39;</span><span class="p">,</span><span class="s1">&#39;Class_6&#39;</span><span class="p">,</span><span class="s1">&#39;Class_7&#39;</span><span class="p">,</span><span class="s1">&#39;Class_8&#39;</span><span class="p">,</span><span class="s1">&#39;Class_9&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">pred_NN_class_all</span>
<span class="n">submission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;classifier1.csv&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">kaggle</span> <span class="n">competitions</span> <span class="n">submit</span> <span class="o">-</span><span class="n">c</span> <span class="n">tabular</span><span class="o">-</span><span class="n">playground</span><span class="o">-</span><span class="n">series</span><span class="o">-</span><span class="n">jun</span><span class="o">-</span><span class="mi">2021</span> <span class="o">-</span><span class="n">f</span> <span class="n">classifier1</span><span class="o">.</span><span class="n">csv</span> <span class="o">-</span><span class="n">m</span> <span class="s2">&quot;Base simple conv tf Model&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="sd">&#39;&#39;&#39;def EmbeddingBlock(X, emb_size):</span>
<span class="sd">    embed_dim = int(min(np.ceil(emb_size / 2), 50))</span>
<span class="sd">    X=layers.Embedding(emb_size+1, embed_dim, embeddings_regularizer=&#39;l2&#39;)(X)</span>
<span class="sd">    X = layers.Reshape(target_shape=(embed_dim, ))(X)</span>
<span class="sd">    X=layers.Flatten()(X)</span>
<span class="sd">    X=layers.Dense(500, kernel_initializer=tf.keras.initializers.GlorotNormal())(X)</span>
<span class="sd">    X=layers.BatchNormalization(axis=-1)(X)</span>
<span class="sd">    X=layers.Dropout(0.4)(X)</span>
<span class="sd">    X=layers.Activation(&#39;relu&#39;)(X)</span>
<span class="sd">    return X</span>


<span class="sd">def get_model(df):</span>
<span class="sd">    inputs= []</span>
<span class="sd">    embeddings = []</span>
<span class="sd">    &#39;&#39;</span>
<span class="sd">    for c in cat_cols:</span>
<span class="sd">        #num_unique_vals = int(df[c].nunique())</span>
<span class="sd">        emb_size = X.train.max(axis=0)</span>
<span class="sd">        embed_dim = int(min(np.ceil(num_unique_vals / 2), 50))</span>
<span class="sd">        inp = layers.Input(shape=(1,))</span>
<span class="sd">        out = layers.Embedding(num_unique_vals + 1, embed_dim, name=c)(inp)</span>
<span class="sd">        #Apply Dropout here</span>
<span class="sd">        out = layers.Reshape(target_shape=(embed_dim, ))(out)</span>
<span class="sd">        inputs.append(inp)</span>
<span class="sd">        outputs.append(out)</span>
<span class="sd">    &#39;&#39;</span>
<span class="sd">    for i in range(75):</span>
<span class="sd">        inputs.append(layers.Input(1,))</span>
<span class="sd">    for i, emb_size in enumerate(emb_sizes):</span>
<span class="sd">        embeddings.append(EmbeddingBlock(inputs[i], int(emb_size)))</span>
<span class="sd">    x = layers.Concatenate()(embeddings)</span>
<span class="sd">    x = layers.Dense(200, name=&#39;lay2&#39;,  activation = &#39;relu&#39;, kernel_initializer=tf.keras.initializers.GlorotNormal())(x)</span>
<span class="sd">    x = layers.BatchNormalization(axis = -1, name = &#39;bn2&#39;)(x)</span>
<span class="sd">    x = layers.Dropout(0.5)(x)</span>
<span class="sd">#    x = layers.Activation(&#39;relu&#39;)(x)</span>
<span class="sd">    x = layers.Dense(100, name=&#39;lay3&#39;,  activation = &#39;relu&#39;, kernel_initializer=tf.keras.initializers.GlorotNormal())(x)</span>
<span class="sd">#    x = layers.BatchNormalization(axis = -1, name = &#39;bn3&#39;)(x)</span>
<span class="sd">#    x = layers.Dropout(0.5)(x)</span>
<span class="sd">#    x = layers.Activation(&#39;relu&#39;)(x)</span>
<span class="sd">    x = layers.Dense(9, activation=&#39;softmax&#39;, name=&#39;output&#39;)(x)</span>
<span class="sd">    model = Model(inputs=inputs, outputs=x, name=&#39;Embedding_Model&#39;)</span>
<span class="sd">    </span>
<span class="sd">    return model</span>
<span class="sd">    &#39;&#39;&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">get_model</span><span class="p">(</span><span class="n">train</span><span class="p">)</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">y</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0         5
1         5
2         1
3         7
4         1
         ..
199995    5
199996    5
199997    7
199998    6
199999    7
Name: target, Length: 200000, dtype: int8</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">f</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">indep_vars</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/14
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-59-bb1227044615&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span>model<span class="ansi-blue-fg">.</span>fit<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">[</span>train<span class="ansi-blue-fg">.</span>loc<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">,</span>f<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>values <span class="ansi-green-fg">for</span> f <span class="ansi-green-fg">in</span> indep_vars<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">,</span> batch_size <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">128</span><span class="ansi-blue-fg">,</span> epochs <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">14</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/wandb/integration/keras/keras.py</span> in <span class="ansi-cyan-fg">new_v2</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    122</span>             <span class="ansi-green-fg">for</span> cbk <span class="ansi-green-fg">in</span> cbks<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    123</span>                 set_wandb_attrs<span class="ansi-blue-fg">(</span>cbk<span class="ansi-blue-fg">,</span> val_data<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 124</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> old_v2<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    125</span> 
<span class="ansi-green-intense-fg ansi-bold">    126</span>     training_arrays<span class="ansi-blue-fg">.</span>orig_fit_loop <span class="ansi-blue-fg">=</span> old_arrays

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py</span> in <span class="ansi-cyan-fg">fit</span><span class="ansi-blue-fg">(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)</span>
<span class="ansi-green-intense-fg ansi-bold">   1181</span>                 _r=1):
<span class="ansi-green-intense-fg ansi-bold">   1182</span>               callbacks<span class="ansi-blue-fg">.</span>on_train_batch_begin<span class="ansi-blue-fg">(</span>step<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">-&gt; 1183</span><span class="ansi-red-fg">               </span>tmp_logs <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>train_function<span class="ansi-blue-fg">(</span>iterator<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1184</span>               <span class="ansi-green-fg">if</span> data_handler<span class="ansi-blue-fg">.</span>should_sync<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1185</span>                 context<span class="ansi-blue-fg">.</span>async_wait<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, *args, **kwds)</span>
<span class="ansi-green-intense-fg ansi-bold">    887</span> 
<span class="ansi-green-intense-fg ansi-bold">    888</span>       <span class="ansi-green-fg">with</span> OptionalXlaContext<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_jit_compile<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 889</span><span class="ansi-red-fg">         </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_call<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwds<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    890</span> 
<span class="ansi-green-intense-fg ansi-bold">    891</span>       new_tracing_count <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>experimental_get_tracing_count<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py</span> in <span class="ansi-cyan-fg">_call</span><span class="ansi-blue-fg">(self, *args, **kwds)</span>
<span class="ansi-green-intense-fg ansi-bold">    922</span>       <span class="ansi-red-fg"># In this case we have not created variables on the first call. So we can</span>
<span class="ansi-green-intense-fg ansi-bold">    923</span>       <span class="ansi-red-fg"># run the first trace but we should fail if variables are created.</span>
<span class="ansi-green-fg">--&gt; 924</span><span class="ansi-red-fg">       </span>results <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_stateful_fn<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwds<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    925</span>       <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>_created_variables<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    926</span>         raise ValueError(&#34;Creating variables on a non-first call to a function&#34;

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   3020</span>     <span class="ansi-green-fg">with</span> self<span class="ansi-blue-fg">.</span>_lock<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   3021</span>       (graph_function,
<span class="ansi-green-fg">-&gt; 3022</span><span class="ansi-red-fg">        filtered_flat_args) = self._maybe_define_function(args, kwargs)
</span><span class="ansi-green-intense-fg ansi-bold">   3023</span>     return graph_function._call_flat(
<span class="ansi-green-intense-fg ansi-bold">   3024</span>         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py</span> in <span class="ansi-cyan-fg">_maybe_define_function</span><span class="ansi-blue-fg">(self, args, kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   3439</span>               call_context_key in self._function_cache.missed):
<span class="ansi-green-intense-fg ansi-bold">   3440</span>             return self._define_function_with_shape_relaxation(
<span class="ansi-green-fg">-&gt; 3441</span><span class="ansi-red-fg">                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)
</span><span class="ansi-green-intense-fg ansi-bold">   3442</span> 
<span class="ansi-green-intense-fg ansi-bold">   3443</span>           self<span class="ansi-blue-fg">.</span>_function_cache<span class="ansi-blue-fg">.</span>missed<span class="ansi-blue-fg">.</span>add<span class="ansi-blue-fg">(</span>call_context_key<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py</span> in <span class="ansi-cyan-fg">_define_function_with_shape_relaxation</span><span class="ansi-blue-fg">(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)</span>
<span class="ansi-green-intense-fg ansi-bold">   3361</span> 
<span class="ansi-green-intense-fg ansi-bold">   3362</span>     graph_function = self._create_graph_function(
<span class="ansi-green-fg">-&gt; 3363</span><span class="ansi-red-fg">         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)
</span><span class="ansi-green-intense-fg ansi-bold">   3364</span>     self<span class="ansi-blue-fg">.</span>_function_cache<span class="ansi-blue-fg">.</span>arg_relaxed<span class="ansi-blue-fg">[</span>rank_only_cache_key<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> graph_function
<span class="ansi-green-intense-fg ansi-bold">   3365</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py</span> in <span class="ansi-cyan-fg">_create_graph_function</span><span class="ansi-blue-fg">(self, args, kwargs, override_flat_arg_shapes)</span>
<span class="ansi-green-intense-fg ansi-bold">   3287</span>             arg_names<span class="ansi-blue-fg">=</span>arg_names<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   3288</span>             override_flat_arg_shapes<span class="ansi-blue-fg">=</span>override_flat_arg_shapes<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">-&gt; 3289</span><span class="ansi-red-fg">             capture_by_value=self._capture_by_value),
</span><span class="ansi-green-intense-fg ansi-bold">   3290</span>         self<span class="ansi-blue-fg">.</span>_function_attributes<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   3291</span>         function_spec<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>function_spec<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py</span> in <span class="ansi-cyan-fg">func_graph_from_py_func</span><span class="ansi-blue-fg">(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)</span>
<span class="ansi-green-intense-fg ansi-bold">    997</span>         _<span class="ansi-blue-fg">,</span> original_func <span class="ansi-blue-fg">=</span> tf_decorator<span class="ansi-blue-fg">.</span>unwrap<span class="ansi-blue-fg">(</span>python_func<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    998</span> 
<span class="ansi-green-fg">--&gt; 999</span><span class="ansi-red-fg">       </span>func_outputs <span class="ansi-blue-fg">=</span> python_func<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>func_args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>func_kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1000</span> 
<span class="ansi-green-intense-fg ansi-bold">   1001</span>       <span class="ansi-red-fg"># invariant: `func_outputs` contains only Tensors, CompositeTensors,</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py</span> in <span class="ansi-cyan-fg">wrapped_fn</span><span class="ansi-blue-fg">(*args, **kwds)</span>
<span class="ansi-green-intense-fg ansi-bold">    670</span>         <span class="ansi-red-fg"># the function a weak reference to itself to avoid a reference cycle.</span>
<span class="ansi-green-intense-fg ansi-bold">    671</span>         <span class="ansi-green-fg">with</span> OptionalXlaContext<span class="ansi-blue-fg">(</span>compile_with_xla<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 672</span><span class="ansi-red-fg">           </span>out <span class="ansi-blue-fg">=</span> weak_wrapped_fn<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>__wrapped__<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwds<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    673</span>         <span class="ansi-green-fg">return</span> out
<span class="ansi-green-intense-fg ansi-bold">    674</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py</span> in <span class="ansi-cyan-fg">wrapper</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    984</span>           <span class="ansi-green-fg">except</span> Exception <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>  <span class="ansi-red-fg"># pylint:disable=broad-except</span>
<span class="ansi-green-intense-fg ansi-bold">    985</span>             <span class="ansi-green-fg">if</span> hasattr<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#34;ag_error_metadata&#34;</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 986</span><span class="ansi-red-fg">               </span><span class="ansi-green-fg">raise</span> e<span class="ansi-blue-fg">.</span>ag_error_metadata<span class="ansi-blue-fg">.</span>to_exception<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    987</span>             <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    988</span>               <span class="ansi-green-fg">raise</span>

<span class="ansi-red-fg">ValueError</span>: in user code:

    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:855 train_function  *
        return step_function(self, iterator)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:845 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:838 run_step  **
        outputs = model.train_step(data)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:797 train_step
        y, y_pred, sample_weight, regularization_losses=self.losses)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__
        loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:155 __call__
        losses = call_fn(y_true, y_pred)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:259 call  **
        return ag_fn(y_true, y_pred, **self._fn_kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper
        return target(*args, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:1644 categorical_crossentropy
        y_true, y_pred, from_logits=from_logits)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper
        return target(*args, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4862 categorical_crossentropy
        target.shape.assert_is_compatible_with(output.shape)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with
        raise ValueError(&#34;Shapes %s and %s are incompatible&#34; % (self, other))

    ValueError: Shapes (None, 1) and (None, 9) are incompatible
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">kfold</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">100000</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="n">train_oof</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">200000</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">kfold</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">):</span>
    <span class="n">train_idx</span><span class="p">,</span> <span class="n">val_idx</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">idx</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">xtrain</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
    <span class="n">ytrain</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
    <span class="n">xval</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">val_idx</span><span class="p">]</span>
    <span class="n">yval</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">val_idx</span><span class="p">]</span>
    <span class="n">ytrain</span> <span class="o">=</span> <span class="n">ytrain</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>
    <span class="n">yval</span> <span class="o">=</span> <span class="n">yval</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>
    <span class="n">ytrain</span><span class="o">-=</span><span class="mi">1</span>
    <span class="n">yval</span><span class="o">-=</span><span class="mi">1</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="n">xtrain</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">f</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">indep_vars</span><span class="p">],</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">ytrain</span><span class="p">),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">+=</span> <span class="n">classmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span><span class="o">/</span><span class="n">kfold</span><span class="o">.</span><span class="n">n_splits</span>

    <span class="n">val_pred</span> <span class="o">=</span> <span class="n">classmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xval</span><span class="p">)</span>
    <span class="c1"># getting out-of-fold predictions on training set</span>
    <span class="n">train_oof</span><span class="p">[</span><span class="n">val_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">val_pred</span>
    
    <span class="c1"># calculate and append logloss</span>
    <span class="n">fold_logloss</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">log_loss</span><span class="p">(</span><span class="n">yval</span><span class="p">,</span><span class="n">val_pred</span><span class="p">)</span>
    <span class="c1">#print(classmodel.evaluate(xval,yval))</span>
    <span class="c1">#classmodel.evaluate(xval,yval)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Logloss: </span><span class="si">{0:0.5f}</span><span class="s2">&quot;</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">fold_logloss</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/14
1547/1547 [==============================] - 150s 81ms/step - loss: nan - accuracy: 0.1221
Epoch 2/14
1547/1547 [==============================] - 122s 79ms/step - loss: nan - accuracy: 0.1222
Epoch 3/14
1547/1547 [==============================] - 120s 78ms/step - loss: nan - accuracy: 0.1222
Epoch 4/14
1547/1547 [==============================] - 118s 77ms/step - loss: nan - accuracy: 0.1222
Epoch 5/14
1506/1547 [============================&gt;.] - ETA: 3s - loss: nan - accuracy: 0.1223</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-92-9364e7524556&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     17</span>     model<span class="ansi-blue-fg">.</span>compile<span class="ansi-blue-fg">(</span>loss<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">&#39;sparse_categorical_crossentropy&#39;</span><span class="ansi-blue-fg">,</span> optimizer <span class="ansi-blue-fg">=</span> keras<span class="ansi-blue-fg">.</span>optimizers<span class="ansi-blue-fg">.</span>Adam<span class="ansi-blue-fg">(</span>learning_rate<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0.01</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> metrics<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;accuracy&#39;</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     18</span> 
<span class="ansi-green-fg">---&gt; 19</span><span class="ansi-red-fg">     </span>model<span class="ansi-blue-fg">.</span>fit<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">[</span>xtrain<span class="ansi-blue-fg">.</span>loc<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">,</span>f<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>values <span class="ansi-green-fg">for</span> f <span class="ansi-green-fg">in</span> indep_vars<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> pd<span class="ansi-blue-fg">.</span>to_numeric<span class="ansi-blue-fg">(</span>ytrain<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> batch_size <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">128</span><span class="ansi-blue-fg">,</span> epochs <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">14</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     20</span>     y_pred <span class="ansi-blue-fg">+=</span> classmodel<span class="ansi-blue-fg">.</span>predict<span class="ansi-blue-fg">(</span>X_test<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">/</span>kfold<span class="ansi-blue-fg">.</span>n_splits
<span class="ansi-green-intense-fg ansi-bold">     21</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/wandb/integration/keras/keras.py</span> in <span class="ansi-cyan-fg">new_v2</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    122</span>             <span class="ansi-green-fg">for</span> cbk <span class="ansi-green-fg">in</span> cbks<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    123</span>                 set_wandb_attrs<span class="ansi-blue-fg">(</span>cbk<span class="ansi-blue-fg">,</span> val_data<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 124</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> old_v2<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    125</span> 
<span class="ansi-green-intense-fg ansi-bold">    126</span>     training_arrays<span class="ansi-blue-fg">.</span>orig_fit_loop <span class="ansi-blue-fg">=</span> old_arrays

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py</span> in <span class="ansi-cyan-fg">fit</span><span class="ansi-blue-fg">(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)</span>
<span class="ansi-green-intense-fg ansi-bold">   1181</span>                 _r=1):
<span class="ansi-green-intense-fg ansi-bold">   1182</span>               callbacks<span class="ansi-blue-fg">.</span>on_train_batch_begin<span class="ansi-blue-fg">(</span>step<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">-&gt; 1183</span><span class="ansi-red-fg">               </span>tmp_logs <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>train_function<span class="ansi-blue-fg">(</span>iterator<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1184</span>               <span class="ansi-green-fg">if</span> data_handler<span class="ansi-blue-fg">.</span>should_sync<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1185</span>                 context<span class="ansi-blue-fg">.</span>async_wait<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, *args, **kwds)</span>
<span class="ansi-green-intense-fg ansi-bold">    887</span> 
<span class="ansi-green-intense-fg ansi-bold">    888</span>       <span class="ansi-green-fg">with</span> OptionalXlaContext<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_jit_compile<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 889</span><span class="ansi-red-fg">         </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_call<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwds<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    890</span> 
<span class="ansi-green-intense-fg ansi-bold">    891</span>       new_tracing_count <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>experimental_get_tracing_count<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py</span> in <span class="ansi-cyan-fg">_call</span><span class="ansi-blue-fg">(self, *args, **kwds)</span>
<span class="ansi-green-intense-fg ansi-bold">    915</span>       <span class="ansi-red-fg"># In this case we have created variables on the first call, so we run the</span>
<span class="ansi-green-intense-fg ansi-bold">    916</span>       <span class="ansi-red-fg"># defunned version which is guaranteed to never create variables.</span>
<span class="ansi-green-fg">--&gt; 917</span><span class="ansi-red-fg">       </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_stateless_fn<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwds<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># pylint: disable=not-callable</span>
<span class="ansi-green-intense-fg ansi-bold">    918</span>     <span class="ansi-green-fg">elif</span> self<span class="ansi-blue-fg">.</span>_stateful_fn <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    919</span>       <span class="ansi-red-fg"># Release the lock early so that multiple threads can perform the call</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   3022</span>        filtered_flat_args) = self._maybe_define_function(args, kwargs)
<span class="ansi-green-intense-fg ansi-bold">   3023</span>     return graph_function._call_flat(
<span class="ansi-green-fg">-&gt; 3024</span><span class="ansi-red-fg">         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
</span><span class="ansi-green-intense-fg ansi-bold">   3025</span> 
<span class="ansi-green-intense-fg ansi-bold">   3026</span>   <span class="ansi-blue-fg">@</span>property

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py</span> in <span class="ansi-cyan-fg">_call_flat</span><span class="ansi-blue-fg">(self, args, captured_inputs, cancellation_manager)</span>
<span class="ansi-green-intense-fg ansi-bold">   1959</span>       <span class="ansi-red-fg"># No tape is watching; skip to running the function.</span>
<span class="ansi-green-intense-fg ansi-bold">   1960</span>       return self._build_call_outputs(self._inference_function.call(
<span class="ansi-green-fg">-&gt; 1961</span><span class="ansi-red-fg">           ctx, args, cancellation_manager=cancellation_manager))
</span><span class="ansi-green-intense-fg ansi-bold">   1962</span>     forward_backward = self._select_forward_and_backward_functions(
<span class="ansi-green-intense-fg ansi-bold">   1963</span>         args<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py</span> in <span class="ansi-cyan-fg">call</span><span class="ansi-blue-fg">(self, ctx, args, cancellation_manager)</span>
<span class="ansi-green-intense-fg ansi-bold">    594</span>               inputs<span class="ansi-blue-fg">=</span>args<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    595</span>               attrs<span class="ansi-blue-fg">=</span>attrs<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 596</span><span class="ansi-red-fg">               ctx=ctx)
</span><span class="ansi-green-intense-fg ansi-bold">    597</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    598</span>           outputs = execute.execute_with_cancellation(

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py</span> in <span class="ansi-cyan-fg">quick_execute</span><span class="ansi-blue-fg">(op_name, num_outputs, inputs, attrs, ctx, name)</span>
<span class="ansi-green-intense-fg ansi-bold">     58</span>     ctx<span class="ansi-blue-fg">.</span>ensure_initialized<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     59</span>     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
<span class="ansi-green-fg">---&gt; 60</span><span class="ansi-red-fg">                                         inputs, attrs, num_outputs)
</span><span class="ansi-green-intense-fg ansi-bold">     61</span>   <span class="ansi-green-fg">except</span> core<span class="ansi-blue-fg">.</span>_NotOkStatusException <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     62</span>     <span class="ansi-green-fg">if</span> name <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">main_pred</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(100000, 200)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">sub</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(100000, 10)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">sub</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;sample_submission.csv.zip&#39;</span><span class="p">)</span>
<span class="n">sub</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span><span class="o">=</span><span class="n">main_pred</span>
<span class="n">sub</span><span class="o">=</span><span class="n">sub</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">)</span>
<span class="n">sub</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;my_tfModel.csv&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-86-d18d1eeece38&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> sub <span class="ansi-blue-fg">=</span> pd<span class="ansi-blue-fg">.</span>read_csv<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;sample_submission.csv.zip&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span>sub<span class="ansi-blue-fg">.</span>iloc<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">=</span>main_pred
<span class="ansi-green-intense-fg ansi-bold">      3</span> sub<span class="ansi-blue-fg">=</span>sub<span class="ansi-blue-fg">.</span>set_index<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;id&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> sub<span class="ansi-blue-fg">.</span>to_csv<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;my_tfModel.csv&#39;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py</span> in <span class="ansi-cyan-fg">__setitem__</span><span class="ansi-blue-fg">(self, key, value)</span>
<span class="ansi-green-intense-fg ansi-bold">    668</span> 
<span class="ansi-green-intense-fg ansi-bold">    669</span>         iloc <span class="ansi-blue-fg">=</span> self <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>name <span class="ansi-blue-fg">==</span> <span class="ansi-blue-fg">&#34;iloc&#34;</span> <span class="ansi-green-fg">else</span> self<span class="ansi-blue-fg">.</span>obj<span class="ansi-blue-fg">.</span>iloc
<span class="ansi-green-fg">--&gt; 670</span><span class="ansi-red-fg">         </span>iloc<span class="ansi-blue-fg">.</span>_setitem_with_indexer<span class="ansi-blue-fg">(</span>indexer<span class="ansi-blue-fg">,</span> value<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    671</span> 
<span class="ansi-green-intense-fg ansi-bold">    672</span>     <span class="ansi-green-fg">def</span> _validate_key<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> key<span class="ansi-blue-fg">,</span> axis<span class="ansi-blue-fg">:</span> int<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py</span> in <span class="ansi-cyan-fg">_setitem_with_indexer</span><span class="ansi-blue-fg">(self, indexer, value)</span>
<span class="ansi-green-intense-fg ansi-bold">   1726</span>                     <span class="ansi-green-fg">if</span> len<span class="ansi-blue-fg">(</span>ilocs<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">!=</span> value<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1727</span>                         raise ValueError(
<span class="ansi-green-fg">-&gt; 1728</span><span class="ansi-red-fg">                             </span><span class="ansi-blue-fg">&#34;Must have equal len keys and value &#34;</span>
<span class="ansi-green-intense-fg ansi-bold">   1729</span>                             <span class="ansi-blue-fg">&#34;when setting with an ndarray&#34;</span>
<span class="ansi-green-intense-fg ansi-bold">   1730</span>                         )

<span class="ansi-red-fg">ValueError</span>: Must have equal len keys and value when setting with an ndarray</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">kaggle</span> <span class="n">competitions</span> <span class="n">submit</span> <span class="o">-</span><span class="n">c</span> <span class="n">tabular</span><span class="o">-</span><span class="n">playground</span><span class="o">-</span><span class="n">series</span><span class="o">-</span><span class="n">jun</span><span class="o">-</span><span class="mi">2021</span> <span class="o">-</span><span class="n">f</span> <span class="n">my_tfModel</span><span class="o">.</span><span class="n">csv</span> <span class="o">-</span><span class="n">m</span> <span class="s2">&quot;Base simple TF Model&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Using-Fast-ai">Using Fast ai<a class="anchor-link" href="#Using-Fast-ai"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">upgrade</span> <span class="n">fastai</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Requirement already up-to-date: fastai in /usr/local/lib/python3.7/dist-packages (2.4)
Requirement already satisfied, skipping upgrade: pillow&gt;6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)
Requirement already satisfied, skipping upgrade: torchvision&gt;=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.10.0+cu102)
Requirement already satisfied, skipping upgrade: fastprogress&gt;=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)
Requirement already satisfied, skipping upgrade: torch&lt;1.10,&gt;=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.9.0+cu102)
Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai) (0.22.2.post1)
Requirement already satisfied, skipping upgrade: fastcore&lt;1.4,&gt;=1.3.8 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.3.20)
Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)
Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)
Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)
Requirement already satisfied, skipping upgrade: spacy&lt;4 in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)
Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.4.1)
Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (20.9)
Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)
Requirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (19.3.1)
Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision&gt;=0.8.2-&gt;fastai) (1.19.5)
Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch&lt;1.10,&gt;=1.7.0-&gt;fastai) (3.7.4.3)
Requirement already satisfied, skipping upgrade: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;fastai) (1.0.1)
Requirement already satisfied, skipping upgrade: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai) (3.0.4)
Requirement already satisfied, skipping upgrade: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai) (2.10)
Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai) (1.24.3)
Requirement already satisfied, skipping upgrade: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai) (2021.5.30)
Requirement already satisfied, skipping upgrade: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;fastai) (2.8.1)
Requirement already satisfied, skipping upgrade: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;fastai) (2018.9)
Requirement already satisfied, skipping upgrade: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (1.0.5)
Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (57.0.0)
Requirement already satisfied, skipping upgrade: wasabi&lt;1.1.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (0.8.2)
Requirement already satisfied, skipping upgrade: plac&lt;1.2.0,&gt;=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (1.1.3)
Requirement already satisfied, skipping upgrade: catalogue&lt;1.1.0,&gt;=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (1.0.0)
Requirement already satisfied, skipping upgrade: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (3.0.5)
Requirement already satisfied, skipping upgrade: blis&lt;0.5.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (0.4.1)
Requirement already satisfied, skipping upgrade: srsly&lt;1.1.0,&gt;=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (1.0.5)
Requirement already satisfied, skipping upgrade: tqdm&lt;5.0.0,&gt;=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (4.41.1)
Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (7.4.0)
Requirement already satisfied, skipping upgrade: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (2.0.5)
Requirement already satisfied, skipping upgrade: pyparsing&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;fastai) (2.4.7)
Requirement already satisfied, skipping upgrade: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai) (1.3.1)
Requirement already satisfied, skipping upgrade: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai) (0.10.0)
Requirement already satisfied, skipping upgrade: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;fastai) (1.15.0)
Requirement already satisfied, skipping upgrade: importlib-metadata&gt;=0.20; python_version &lt; &#34;3.8&#34; in /usr/local/lib/python3.7/dist-packages (from catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;4-&gt;fastai) (4.5.0)
Requirement already satisfied, skipping upgrade: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=0.20; python_version &lt; &#34;3.8&#34;-&gt;catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;4-&gt;fastai) (3.4.1)
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> 
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> 
<span class="kn">import</span> <span class="nn">fastai</span>
<span class="kn">from</span> <span class="nn">fastai.tabular.all</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;train.csv.zip&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;test.csv.zip&#39;</span><span class="p">)</span> 
<span class="n">sample_submission</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;sample_submission.csv.zip&#39;</span><span class="p">)</span>

<span class="n">train</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">codes</span>

<span class="n">indep_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;feature_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">75</span><span class="p">)]</span>
<span class="n">dep_var</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">wandb</span>
<span class="kn">from</span> <span class="nn">fastai.callback.wandb</span> <span class="kn">import</span> <span class="n">WandbCallback</span>

<span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">project</span><span class="o">=</span><span class="s1">&#39;tpcJun&#39;</span><span class="p">,</span> <span class="n">entity</span><span class="o">=</span><span class="s1">&#39;nitinkash&#39;</span><span class="p">)</span>  

<span class="n">n</span><span class="o">=</span><span class="mi">10</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">sample_submission</span><span class="p">[</span><span class="n">sample_submission</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span><span class="o">*</span><span class="mi">0</span>
<span class="n">log</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Loss Train&#39;</span><span class="p">,</span><span class="s1">&#39;Loss Validation&#39;</span><span class="p">,</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">splits</span> <span class="o">=</span> <span class="n">RandomSplitter</span><span class="p">(</span><span class="n">valid_pct</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)(</span><span class="n">range_of</span><span class="p">(</span><span class="n">train</span><span class="p">))</span>
    
    <span class="n">to</span> <span class="o">=</span> <span class="n">TabularPandas</span><span class="p">(</span>
        <span class="n">train</span><span class="p">,</span>
        <span class="n">y_names</span><span class="o">=</span><span class="s2">&quot;target&quot;</span><span class="p">,</span>
        <span class="n">y_block</span> <span class="o">=</span> <span class="n">CategoryBlock</span><span class="p">,</span>
        <span class="n">cat_names</span> <span class="o">=</span> <span class="n">indep_vars</span><span class="p">,</span>
        <span class="n">procs</span> <span class="o">=</span> <span class="p">[</span><span class="n">Categorify</span><span class="p">],</span>
        <span class="n">splits</span><span class="o">=</span><span class="n">splits</span><span class="p">)</span>
    
    <span class="n">loaders</span> <span class="o">=</span> <span class="n">to</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">bs</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
    <span class="n">learn</span> <span class="o">=</span> <span class="n">tabular_learner</span><span class="p">(</span><span class="n">loaders</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">,</span><span class="n">layers</span><span class="o">=</span><span class="p">[</span><span class="mi">400</span><span class="p">,</span><span class="mi">200</span><span class="p">,</span><span class="mi">100</span><span class="p">])</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">WandbCallback</span><span class="p">())</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">log</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span>
    <span class="n">log</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">log</span><span class="p">)]</span> <span class="o">=</span> <span class="n">loss</span>
    <span class="n">dl</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">dls</span><span class="o">.</span><span class="n">test_dl</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">indep_vars</span><span class="p">])</span>
    <span class="n">pred</span><span class="o">+=</span> <span class="n">learn</span><span class="o">.</span><span class="n">get_preds</span><span class="p">(</span><span class="n">dl</span><span class="o">=</span><span class="n">dl</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">/</span><span class="n">n</span>

<span class="n">log</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Finishing last run (ID:ts02mfjf) before initializing another...
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<br />Waiting for W&amp;B process to finish, PID 2938<br />Program ended successfully.
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Find user logs for this run at: <code>/content/wandb/run-20210620_085707-ts02mfjf/logs/debug.log</code>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Find internal logs for this run at: <code>/content/wandb/run-20210620_085707-ts02mfjf/logs/debug-internal.log</code>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Synced 4 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

                    <br />Synced <strong style="color:#cdcd00">rose-elevator-4</strong>: <a href="https://wandb.ai/nitinkash/tpcJun/runs/ts02mfjf" target="_blank">https://wandb.ai/nitinkash/tpcJun/runs/ts02mfjf</a><br />
                
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
...Successfully finished last run (ID:ts02mfjf). Initializing new run:<br /><br />
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

                Tracking run with wandb version 0.10.32<br />
                Syncing run <strong style="color:#cdcd00">wandering-silence-5</strong> to <a href="https://wandb.ai" target="_blank">Weights &amp; Biases</a> <a href="https://docs.wandb.com/integrations/jupyter.html" target="_blank">(Documentation)</a>.<br />
                Project page: <a href="https://wandb.ai/nitinkash/tpcJun" target="_blank">https://wandb.ai/nitinkash/tpcJun</a><br />
                Run page: <a href="https://wandb.ai/nitinkash/tpcJun/runs/lga2wpme" target="_blank">https://wandb.ai/nitinkash/tpcJun/runs/lga2wpme</a><br />
                Run data is saved locally in <code>/content/wandb/run-20210620_085727-lga2wpme</code><br /><br />
            
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WandbCallback requires use of &#34;SaveModelCallback&#34; to log best model
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.760212</td>
      <td>1.763360</td>
      <td>0.358483</td>
      <td>00:14</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.751347</td>
      <td>1.761349</td>
      <td>0.357117</td>
      <td>00:14</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.751319</td>
      <td>1.754586</td>
      <td>0.360867</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.732643</td>
      <td>1.758830</td>
      <td>0.360000</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.694515</td>
      <td>1.786344</td>
      <td>0.354183</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.632646</td>
      <td>1.826944</td>
      <td>0.347283</td>
      <td>00:15</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WandbCallback requires use of &#34;SaveModelCallback&#34; to log best model
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.767195</td>
      <td>1.770747</td>
      <td>0.351250</td>
      <td>00:14</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.746005</td>
      <td>1.760289</td>
      <td>0.357833</td>
      <td>00:14</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.740296</td>
      <td>1.759351</td>
      <td>0.357367</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.733669</td>
      <td>1.760480</td>
      <td>0.359217</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.691971</td>
      <td>1.792537</td>
      <td>0.351633</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.627157</td>
      <td>1.830427</td>
      <td>0.344667</td>
      <td>00:15</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WandbCallback requires use of &#34;SaveModelCallback&#34; to log best model
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.757772</td>
      <td>1.767650</td>
      <td>0.357517</td>
      <td>00:14</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.746079</td>
      <td>1.754012</td>
      <td>0.359433</td>
      <td>00:14</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.756429</td>
      <td>1.757512</td>
      <td>0.357617</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.730067</td>
      <td>1.760968</td>
      <td>0.357800</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.676232</td>
      <td>1.795751</td>
      <td>0.349383</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.613920</td>
      <td>1.844784</td>
      <td>0.340417</td>
      <td>00:16</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WandbCallback requires use of &#34;SaveModelCallback&#34; to log best model
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.769339</td>
      <td>1.755938</td>
      <td>0.359383</td>
      <td>00:14</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.747505</td>
      <td>1.755559</td>
      <td>0.359250</td>
      <td>00:14</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.741776</td>
      <td>1.751421</td>
      <td>0.360250</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.738125</td>
      <td>1.757160</td>
      <td>0.359367</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.683477</td>
      <td>1.788251</td>
      <td>0.353333</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.626947</td>
      <td>1.823900</td>
      <td>0.345967</td>
      <td>00:15</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WandbCallback requires use of &#34;SaveModelCallback&#34; to log best model
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.766214</td>
      <td>1.757098</td>
      <td>0.360483</td>
      <td>00:14</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.740282</td>
      <td>1.754356</td>
      <td>0.360617</td>
      <td>00:14</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.746247</td>
      <td>1.752255</td>
      <td>0.359300</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.736547</td>
      <td>1.754223</td>
      <td>0.358200</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.686455</td>
      <td>1.789755</td>
      <td>0.351750</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.614124</td>
      <td>1.845294</td>
      <td>0.342300</td>
      <td>00:15</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WandbCallback requires use of &#34;SaveModelCallback&#34; to log best model
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.768590</td>
      <td>1.761582</td>
      <td>0.353517</td>
      <td>00:14</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.751888</td>
      <td>1.757103</td>
      <td>0.360533</td>
      <td>00:14</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.742130</td>
      <td>1.756774</td>
      <td>0.358917</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.730845</td>
      <td>1.757504</td>
      <td>0.359267</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.690707</td>
      <td>1.786458</td>
      <td>0.350267</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.639708</td>
      <td>1.824516</td>
      <td>0.341183</td>
      <td>00:17</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WandbCallback requires use of &#34;SaveModelCallback&#34; to log best model
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.763231</td>
      <td>1.760707</td>
      <td>0.358200</td>
      <td>00:14</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.751050</td>
      <td>1.756307</td>
      <td>0.357717</td>
      <td>00:14</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.749340</td>
      <td>1.752529</td>
      <td>0.360467</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.734925</td>
      <td>1.755805</td>
      <td>0.356433</td>
      <td>00:14</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.692954</td>
      <td>1.784191</td>
      <td>0.352450</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.641886</td>
      <td>1.820158</td>
      <td>0.344900</td>
      <td>00:15</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WandbCallback requires use of &#34;SaveModelCallback&#34; to log best model
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.755902</td>
      <td>1.769750</td>
      <td>0.347917</td>
      <td>00:14</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.750517</td>
      <td>1.753261</td>
      <td>0.355550</td>
      <td>00:14</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.739976</td>
      <td>1.756716</td>
      <td>0.356567</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.724806</td>
      <td>1.761603</td>
      <td>0.355033</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.687991</td>
      <td>1.794379</td>
      <td>0.349167</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.616076</td>
      <td>1.835337</td>
      <td>0.341417</td>
      <td>00:15</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WandbCallback requires use of &#34;SaveModelCallback&#34; to log best model
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.774278</td>
      <td>1.761793</td>
      <td>0.354733</td>
      <td>00:14</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.746634</td>
      <td>1.754074</td>
      <td>0.358083</td>
      <td>00:14</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.748075</td>
      <td>1.754374</td>
      <td>0.355183</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.739434</td>
      <td>1.756819</td>
      <td>0.359917</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.687033</td>
      <td>1.785866</td>
      <td>0.351767</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.627529</td>
      <td>1.829849</td>
      <td>0.343417</td>
      <td>00:15</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WandbCallback requires use of &#34;SaveModelCallback&#34; to log best model
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.761038</td>
      <td>1.762059</td>
      <td>0.358317</td>
      <td>00:14</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.755838</td>
      <td>1.753854</td>
      <td>0.354683</td>
      <td>00:14</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.758328</td>
      <td>1.754847</td>
      <td>0.360933</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.737863</td>
      <td>1.754674</td>
      <td>0.359883</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.703351</td>
      <td>1.777514</td>
      <td>0.353233</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.645787</td>
      <td>1.819137</td>
      <td>0.344767</td>
      <td>00:15</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Loss Train</th>
      <th>Loss Validation</th>
      <th>Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>10.000000</td>
      <td>10.000000</td>
      <td>10.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1.628578</td>
      <td>1.830035</td>
      <td>0.343632</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.011545</td>
      <td>0.009265</td>
      <td>0.002256</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.613920</td>
      <td>1.819137</td>
      <td>0.340417</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.618794</td>
      <td>1.824054</td>
      <td>0.341637</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.627343</td>
      <td>1.828396</td>
      <td>0.344042</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.637943</td>
      <td>1.834109</td>
      <td>0.344867</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.645787</td>
      <td>1.845294</td>
      <td>0.347283</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">sample_submission</span><span class="p">[</span><span class="n">sample_submission</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span> <span class="o">=</span> <span class="n">pred</span>
<span class="n">sample_submission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;submission.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">kaggle</span> <span class="n">competitions</span> <span class="n">submit</span> <span class="o">-</span><span class="n">c</span> <span class="n">tabular</span><span class="o">-</span><span class="n">playground</span><span class="o">-</span><span class="n">series</span><span class="o">-</span><span class="n">jun</span><span class="o">-</span><span class="mi">2021</span> <span class="o">-</span><span class="n">f</span> <span class="n">submission</span><span class="o">.</span><span class="n">csv</span> <span class="o">-</span><span class="n">m</span> <span class="s2">&quot;Base fastai Model2&quot;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Warning: Looks like you&#39;re using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)
100% 17.9M/17.9M [00:00&lt;00:00, 36.4MB/s]
Successfully submitted to Tabular Playground Series - Jun 2021</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>

<script type="application/vnd.jupyter.widget-state+json">
{"4bae5b46de924e5083f92478577e69de": {"model_module": "@jupyter-widgets/controls", "model_name": "VBoxModel", "state": {"_view_name": "VBoxView", "_dom_classes": [], "_model_name": "VBoxModel", "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.5.0", "box_style": "", "layout": "IPY_MODEL_e7408e3b09d04ffa95d9a2cc7505bac4", "_model_module": "@jupyter-widgets/controls", "children": ["IPY_MODEL_cd53787fe07b4294bf23d469e1b193fe", "IPY_MODEL_e64cfa6946b34e9ca1dc2daf46671986"]}}, "e7408e3b09d04ffa95d9a2cc7505bac4": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_view_name": "LayoutView", "grid_template_rows": null, "right": null, "justify_content": null, "_view_module": "@jupyter-widgets/base", "overflow": null, "_model_module_version": "1.2.0", "_view_count": null, "flex_flow": null, "width": null, "min_width": null, "border": null, "align_items": null, "bottom": null, "_model_module": "@jupyter-widgets/base", "top": null, "grid_column": null, "overflow_y": null, "overflow_x": null, "grid_auto_flow": null, "grid_area": null, "grid_template_columns": null, "flex": null, "_model_name": "LayoutModel", "justify_items": null, "grid_row": null, "max_height": null, "align_content": null, "visibility": null, "align_self": null, "height": null, "min_height": null, "padding": null, "grid_auto_rows": null, "grid_gap": null, "max_width": null, "order": null, "_view_module_version": "1.2.0", "grid_template_areas": null, "object_position": null, "object_fit": null, "grid_auto_columns": null, "margin": null, "display": null, "left": null}}, "cd53787fe07b4294bf23d469e1b193fe": {"model_module": "@jupyter-widgets/controls", "model_name": "LabelModel", "state": {"_view_name": "LabelView", "style": "IPY_MODEL_f82cb8b3fbb84a7e843f98b4892df0d8", "_dom_classes": [], "description": "", "_model_name": "LabelModel", "placeholder": "\u200b", "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r", "_view_count": null, "_view_module_version": "1.5.0", "description_tooltip": null, "_model_module": "@jupyter-widgets/controls", "layout": "IPY_MODEL_bc84b3cb13444a058b1e0e149ba3b75d"}}, "e64cfa6946b34e9ca1dc2daf46671986": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "state": {"_view_name": "ProgressView", "style": "IPY_MODEL_d3d8bfe2d35242ffa484a805b978dafc", "_dom_classes": [], "description": "", "_model_name": "FloatProgressModel", "bar_style": "", "max": 1, "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "value": 1, "_view_count": null, "_view_module_version": "1.5.0", "orientation": "horizontal", "min": 0, "description_tooltip": null, "_model_module": "@jupyter-widgets/controls", "layout": "IPY_MODEL_1adaf66b1dee4d62bee541da8f6cfff1"}}, "f82cb8b3fbb84a7e843f98b4892df0d8": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "state": {"_view_name": "StyleView", "_model_name": "DescriptionStyleModel", "description_width": "", "_view_module": "@jupyter-widgets/base", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.2.0", "_model_module": "@jupyter-widgets/controls"}}, "bc84b3cb13444a058b1e0e149ba3b75d": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_view_name": "LayoutView", "grid_template_rows": null, "right": null, "justify_content": null, "_view_module": "@jupyter-widgets/base", "overflow": null, "_model_module_version": "1.2.0", "_view_count": null, "flex_flow": null, "width": null, "min_width": null, "border": null, "align_items": null, "bottom": null, "_model_module": "@jupyter-widgets/base", "top": null, "grid_column": null, "overflow_y": null, "overflow_x": null, "grid_auto_flow": null, "grid_area": null, "grid_template_columns": null, "flex": null, "_model_name": "LayoutModel", "justify_items": null, "grid_row": null, "max_height": null, "align_content": null, "visibility": null, "align_self": null, "height": null, "min_height": null, "padding": null, "grid_auto_rows": null, "grid_gap": null, "max_width": null, "order": null, "_view_module_version": "1.2.0", "grid_template_areas": null, "object_position": null, "object_fit": null, "grid_auto_columns": null, "margin": null, "display": null, "left": null}}, "d3d8bfe2d35242ffa484a805b978dafc": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "state": {"_view_name": "StyleView", "_model_name": "ProgressStyleModel", "description_width": "", "_view_module": "@jupyter-widgets/base", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.2.0", "bar_color": null, "_model_module": "@jupyter-widgets/controls"}}, "1adaf66b1dee4d62bee541da8f6cfff1": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_view_name": "LayoutView", "grid_template_rows": null, "right": null, "justify_content": null, "_view_module": "@jupyter-widgets/base", "overflow": null, "_model_module_version": "1.2.0", "_view_count": null, "flex_flow": null, "width": null, "min_width": null, "border": null, "align_items": null, "bottom": null, "_model_module": "@jupyter-widgets/base", "top": null, "grid_column": null, "overflow_y": null, "overflow_x": null, "grid_auto_flow": null, "grid_area": null, "grid_template_columns": null, "flex": null, "_model_name": "LayoutModel", "justify_items": null, "grid_row": null, "max_height": null, "align_content": null, "visibility": null, "align_self": null, "height": null, "min_height": null, "padding": null, "grid_auto_rows": null, "grid_gap": null, "max_width": null, "order": null, "_view_module_version": "1.2.0", "grid_template_areas": null, "object_position": null, "object_fit": null, "grid_auto_columns": null, "margin": null, "display": null, "left": null}}}
</script>



  </div><a class="u-url" href="/blog/2021/11/17/_06_01_KaggleTabular_June21.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>My Data Science Blog</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/nitinkash" title="nitinkash"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/1nitinkashyap" title="1nitinkashyap"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/nikashyap" title="nikashyap"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
