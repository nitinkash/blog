{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-14T07:17:43.575838Z","iopub.execute_input":"2021-06-14T07:17:43.576262Z","iopub.status.idle":"2021-06-14T07:17:43.590724Z","shell.execute_reply.started":"2021-06-14T07:17:43.576137Z","shell.execute_reply":"2021-06-14T07:17:43.589781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/train.csv')\ntrain['target'].unique()\ntrain['target']=train['target'].str[-1]\ntrain.pop('id')\n\ny = train['target']\ntrain.pop('target')\nX=train\n# idx=X[X.duplicated()==True].index\n# X.describe()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:17:43.592677Z","iopub.execute_input":"2021-06-14T07:17:43.593172Z","iopub.status.idle":"2021-06-14T07:17:44.941764Z","shell.execute_reply.started":"2021-06-14T07:17:43.593135Z","shell.execute_reply":"2021-06-14T07:17:44.940347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X.drop(X.index[idx], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:17:44.943861Z","iopub.execute_input":"2021-06-14T07:17:44.944162Z","iopub.status.idle":"2021-06-14T07:17:44.956023Z","shell.execute_reply.started":"2021-06-14T07:17:44.944137Z","shell.execute_reply":"2021-06-14T07:17:44.953972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y.drop(y.index[idx], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:17:44.957622Z","iopub.execute_input":"2021-06-14T07:17:44.957964Z","iopub.status.idle":"2021-06-14T07:17:44.969637Z","shell.execute_reply.started":"2021-06-14T07:17:44.957927Z","shell.execute_reply":"2021-06-14T07:17:44.965006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Dense, Activation, Reshape, BatchNormalization, Add,Dropout, Conv1D,AveragePooling1D,Concatenate, Average, Embedding, GlobalAveragePooling1D, Flatten, AlphaDropout\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.over_sampling import SMOTE\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.utils import class_weight\nfrom category_encoders.cat_boost import CatBoostEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom tensorflow import keras\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn import metrics\nfrom keras.backend import int_shape","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:17:44.971042Z","iopub.execute_input":"2021-06-14T07:17:44.971394Z","iopub.status.idle":"2021-06-14T07:17:52.195811Z","shell.execute_reply.started":"2021-06-14T07:17:44.971351Z","shell.execute_reply":"2021-06-14T07:17:52.194996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X = X.astype('category')\n#X_train, X_test, y_train, y_test  = train_test_split(X,y,test_size=0.05,random_state=151,stratify=y)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:17:52.197084Z","iopub.execute_input":"2021-06-14T07:17:52.197422Z","iopub.status.idle":"2021-06-14T07:17:52.203321Z","shell.execute_reply.started":"2021-06-14T07:17:52.197387Z","shell.execute_reply":"2021-06-14T07:17:52.202517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# emb = X_train.max(axis=0)\n# emb = emb.cumsum(axis=0)\n# emb = emb.shift(1)\n# emb = emb.fillna(0)\n# emb = np.array(emb)\n#np.array(X_train).max()\n#X[:10]","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:17:52.204725Z","iopub.execute_input":"2021-06-14T07:17:52.205079Z","iopub.status.idle":"2021-06-14T07:17:52.210654Z","shell.execute_reply.started":"2021-06-14T07:17:52.205043Z","shell.execute_reply":"2021-06-14T07:17:52.209944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #scaler = RobustScaler()\n# #X_train=scaler.fit_transform(X_train)\n\n# y_train=np.array(y_train)\n# X_train=np.array(X_train)+1\n# X = np.array(X)+1\n# #X_train=np.clip(X_train,1,100)\n# #X_test = scaler.transform(X_test)\n\n# y_test=np.array(y_test)\n# X_test=np.array(X_test)+1\n# #X_test=np.clip(X_test,1,100)\n# X_train=np.float32(X_train)\n# X=np.float32(X)\n# y=np.float32(y)\n# y_train=np.float32(y_train)\n# X_test=np.float32(X_test)\n# y_test=np.float32(y_test)\n# y_train=y_train-1\n# y_test=y_test-1\n# y=y-1","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:17:52.211924Z","iopub.execute_input":"2021-06-14T07:17:52.212353Z","iopub.status.idle":"2021-06-14T07:17:52.220294Z","shell.execute_reply.started":"2021-06-14T07:17:52.212319Z","shell.execute_reply":"2021-06-14T07:17:52.219412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X_train.min()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:17:52.222658Z","iopub.execute_input":"2021-06-14T07:17:52.223119Z","iopub.status.idle":"2021-06-14T07:17:52.230154Z","shell.execute_reply.started":"2021-06-14T07:17:52.223083Z","shell.execute_reply":"2021-06-14T07:17:52.229297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#smote = SMOTE(random_state=12)\n#X_train, y_train = smote.fit_resample(X_train, y_train)\n#oversample = RandomOverSampler(sampling_strategy='minority')\n#X_train, y_train = oversample.fit_resample(X_train, y_train)\n#emb_sizes = X_train.max(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:17:52.231612Z","iopub.execute_input":"2021-06-14T07:17:52.232033Z","iopub.status.idle":"2021-06-14T07:17:52.240436Z","shell.execute_reply.started":"2021-06-14T07:17:52.232Z","shell.execute_reply":"2021-06-14T07:17:52.239704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#np.unique(y_train, return_counts=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:17:52.243127Z","iopub.execute_input":"2021-06-14T07:17:52.243418Z","iopub.status.idle":"2021-06-14T07:17:52.250423Z","shell.execute_reply.started":"2021-06-14T07:17:52.243389Z","shell.execute_reply":"2021-06-14T07:17:52.249533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ClassModel(input_shape):\n\n    \n    X_input = Input(input_shape)\n    X = Embedding (input_dim=354, output_dim=8)(X_input)\n\n    X = Conv1D(64,1,padding='same',activation='relu')(X)\n    X = Conv1D(128,1,padding='same',activation='relu')(X)\n    #X = GlobalAveragePooling1D()(X)\n    X = Flatten()(X)\n    #X = Dropout(0.2)(X)\n    X2 = Dense(75, kernel_initializer=tf.keras.initializers.GlorotNormal(),name='lay1_a')(X)\n    #X2 = BatchNormalization()(X2)\n    #X2 = Dropout(0.2)(X2)\n    X2 = Activation('relu')(X2)\n    X3 = Dense(150, kernel_initializer=tf.keras.initializers.GlorotNormal(),name='lay1_b')(X)\n    #X3 = BatchNormalization()(X3)\n    #X3 = Dropout(0.2)(X3)\n    X3 = Activation('relu')(X3)\n    X4 = Dense(50, kernel_initializer=tf.keras.initializers.GlorotNormal(),name='lay1_c')(X)\n    #X4 = BatchNormalization()(X4)\n    #X4 = Dropout(0.2)(X4)\n    X4 = Activation('relu')(X4)\n    X = Concatenate()([X2,X3,X4])\n    X = Dense(100, name='lay1',kernel_initializer='glorot_uniform')(X)\n    #X = BatchNormalization(axis = -1, name = 'bn1')(X)\n    #X = Dropout(0.2)(X)\n    X = Activation('relu')(X)\n#     X = Dense(300, name='lay2',kernel_initializer='glorot_uniform')(X)\n#     X = BatchNormalization(axis = -1, name = 'bn2')(X)\n#     X = Dropout(0.4)(X)\n#     X = Activation('relu')(X)\n#     X = Dense(100, name='lay3',kernel_initializer='glorot_uniform')(X)\n#     X = BatchNormalization(axis = -1, name = 'bn3')(X)\n#     X = Dropout(0.4)(X)\n#     X = Activation('relu')(X)\n    X = Dense(50, name='lay4',kernel_initializer='glorot_uniform')(X)\n#     X = BatchNormalization(axis = -1, name = 'bn4')(X)\n#     X = Dropout(0.4)(X)\n    X = Activation('relu')(X)\n\n    X = Dense(9, activation='softmax', name='output')(X)\n\n\n    model = Model(inputs = X_input, outputs = X, name='ClassModel')\n\n    \n    return model\n\ndef ResModel(input_shape):\n\n    \n    X_input = Input(input_shape)\n    X = Embedding (input_dim=354, output_dim=2)(X_input)\n    X = Conv1D(16,1,activation='relu')(X)\n    X = Flatten()(X)\n    X2 = Dense(75, kernel_initializer=tf.keras.initializers.GlorotNormal(),name='lay1_a')(X)\n    #X2 = BatchNormalization()(X2)\n    #X2 = Dropout(0.2)(X2)\n    X2 = Activation(\"relu\")(X2)\n    X3 = Dense(150, kernel_initializer=tf.keras.initializers.GlorotNormal(),name='lay1_b')(X)\n    #X3 = BatchNormalization()(X3)\n    #X3 = Dropout(0.2)(X3)\n    X3 = Activation(\"relu\")(X3)\n    X4 = Dense(50, kernel_initializer=tf.keras.initializers.GlorotNormal(),name='lay1_c')(X)\n    #X4 = BatchNormalization()(X4)\n    #X4 = Dropout(0.2)(X4)\n    X4 = Activation(\"relu\")(X4)\n    X = Concatenate()([X2,X3,X4])\n#     X = Dropout(0.3)(X)\n    X = Dense(120, kernel_initializer=tf.keras.initializers.GlorotNormal(),name='lay1')(X)\n#     X = BatchNormalization()(X)\n#     X = Dropout(0.3)(X)\n    X1 = Activation(\"relu\")(X)\n    X = Dense(120, kernel_initializer=tf.keras.initializers.GlorotNormal(), name='lay2')(X1)\n    \n#     X = BatchNormalization()(X)\n#     X = Dropout(0.3)(X)\n    X = Activation(\"relu\")(X)\n    X = Dense(120, kernel_initializer=tf.keras.initializers.GlorotNormal(), name='lay3')(X)\n#     X = BatchNormalization()(X)\n#     X = Dropout(0.3)(X)\n    X = Activation(\"relu\")(X)\n    X = Add()([X1,X])\n    X = Dense(60, kernel_initializer=tf.keras.initializers.GlorotNormal(), name='lay1a')(X)\n#     X = BatchNormalization()(X)\n#     X = Dropout(0.3)(X)\n\n    X2 = Activation(\"relu\")(X)\n    X = Dense(60, kernel_initializer=tf.keras.initializers.GlorotNormal(), name='lay2a')(X1)\n#     X = BatchNormalization()(X)\n#     X = Dropout(0.3)(X)\n    X = Activation(\"relu\")(X)\n    X = Dense(60, kernel_initializer=tf.keras.initializers.GlorotNormal(), name='lay3a')(X)\n#     X = BatchNormalization()(X)\n#     X = Dropout(0.3)(X)\n    X = Activation(\"relu\")(X)\n    X = Concatenate()([X2,X])\n    X = Add()([X,X1])\n    X = Dense(30, kernel_initializer=tf.keras.initializers.GlorotNormal(), name='lay1b')(X)\n#     X = BatchNormalization()(X)\n#     X = Dropout(0.3)(X)\n    X3 = Activation(\"relu\")(X)\n    X = Dense(30, kernel_initializer=tf.keras.initializers.GlorotNormal(), name='lay2b')(X1)\n#     X = BatchNormalization()(X)\n#     X = Dropout(0.3)(X)\n    X = Activation(\"relu\")(X)\n    X = Dense(30, kernel_initializer=tf.keras.initializers.GlorotNormal(), name='lay3b')(X)\n#     X = BatchNormalization()(X)\n#     X = Dropout(0.3)(X)\n    X = Activation(\"relu\")(X)\n    X = Concatenate()([X3,X2,X])\n    X = Add()([X,X1])\n    X = Dense(20, kernel_initializer=tf.keras.initializers.GlorotNormal(), name='final')(X)\n    \n    X = Dense(9, activation='softmax', name='output')(X)\n\n\n    model = Model(inputs = X_input, outputs = X, name='ResModel')\n\n    \n    return model\ndef EmbeddingBlock(X, emb_size):\n    X=Embedding(input_dim=emb_size+1, output_dim=15, embeddings_regularizer='l2')(X)\n    X=Flatten()(X)\n    X=Dense(1000, kernel_initializer=tf.keras.initializers.GlorotNormal())(X)\n    X=BatchNormalization(axis=-1)(X)\n    X=Dropout(0.4)(X)\n    X=Activation('relu')(X)\n    return X\n    \ndef MultiEmbModel():\n    inputs = []\n    embeddings = []\n    for i in range(75):\n        inputs.append(Input(1,))\n    for i,emb_size in enumerate(emb_sizes):\n        embeddings.append(EmbeddingBlock(inputs[i],int(emb_size)))\n    X = Concatenate()(embeddings)\n    #X = Dense(800, name='lay1',kernel_initializer=tf.keras.initializers.GlorotNormal())(X)\n    #X = BatchNormalization(axis = -1, name = 'bn1')(X)\n    #X = Dropout(0.5)(X)\n    #X = Activation('relu')(X)\n    X = Dense(400, name='lay2',kernel_initializer=tf.keras.initializers.GlorotNormal())(X)\n    X = BatchNormalization(axis = -1, name = 'bn2')(X)\n    X = Dropout(0.5)(X)\n    X = Activation('relu')(X)\n    X = Dense(200, name='lay3',kernel_initializer=tf.keras.initializers.GlorotNormal())(X)\n    X = BatchNormalization(axis = -1, name = 'bn3')(X)\n    X = Dropout(0.5)(X)\n    X = Activation('relu')(X)\n    #X = Dense(100, name='lay4',kernel_initializer=tf.keras.initializers.GlorotNormal())(X)\n    #X = BatchNormalization(axis = -1, name = 'bn4')(X)\n    #X = Dropout(0.5)(X)\n    #X = Activation('relu')(X)\n\n    X = Dense(9, activation='softmax', name='output')(X)\n\n\n    model = Model(inputs = inputs, outputs = X, name='EmbModel')\n\n    \n    return model","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-14T07:17:56.844875Z","iopub.execute_input":"2021-06-14T07:17:56.845197Z","iopub.status.idle":"2021-06-14T07:17:56.873832Z","shell.execute_reply.started":"2021-06-14T07:17:56.845165Z","shell.execute_reply":"2021-06-14T07:17:56.872606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.4,\n#                             patience=3, min_lr=0.00001, verbose=1)\ncheckpoint_filepath = '/kaggle/working/ckpt'\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_loss',\n    mode='min',\n    save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:17:59.929099Z","iopub.execute_input":"2021-06-14T07:17:59.929454Z","iopub.status.idle":"2021-06-14T07:17:59.933675Z","shell.execute_reply.started":"2021-06-14T07:17:59.92942Z","shell.execute_reply":"2021-06-14T07:17:59.932765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef prediction (X_train, y_train, X_test):\n    \n    keras.backend.clear_session()\n\n    kfold = StratifiedKFold(n_splits = 10, shuffle=True)\n\n    y_pred = np.zeros((100000,9))\n    train_oof = np.zeros((200000,9))\n\n    for idx in kfold.split(X=X_train, y=y_train):\n        train_idx, val_idx = idx[0], idx[1]\n        xtrain = X_train.iloc[train_idx]\n        ytrain = y_train.iloc[train_idx]\n        xval = X_train.iloc[val_idx]\n        yval = y_train.iloc[val_idx]\n        ytrain = ytrain.astype('int')\n        yval = yval.astype('int')\n        ytrain-=1\n        yval-=1\n        ytrain = to_categorical(ytrain)\n        yval = to_categorical(yval)\n\n\n        \n        checkpoint_filepath = '/kaggle/working/ckpt1'\n        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_loss',\n    mode='min',\n    save_best_only=True)\n        keras.backend.clear_session()\n        # fit model for current fold\n        classmodel = ResModel(xtrain.shape[1:])\n        classmodel.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.Adam(learning_rate=0.00015), metrics=['accuracy'])\n        \n        classmodel.fit(xtrain, ytrain,\n        batch_size = 128, epochs = 14,\n        validation_data=(xval, yval),\n        callbacks=[model_checkpoint_callback])\n        keras.backend.clear_session()\n        classmodel.load_weights(checkpoint_filepath)\n        #create predictions\n        y_pred += classmodel.predict(X_test)/kfold.n_splits\n        #print(y_pred)\n               \n        val_pred = classmodel.predict(xval)\n        # getting out-of-fold predictions on training set\n        train_oof[val_idx] = val_pred\n        \n        # calculate and append logloss\n        fold_logloss = metrics.log_loss(yval,val_pred)\n        #print(classmodel.evaluate(xval,yval))\n        #classmodel.evaluate(xval,yval)\n        print(\"Logloss: {0:0.5f}\". format(fold_logloss))\n    \n    return y_pred, train_oof, classmodel","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:18:01.440379Z","iopub.execute_input":"2021-06-14T07:18:01.440702Z","iopub.status.idle":"2021-06-14T07:18:01.450958Z","shell.execute_reply.started":"2021-06-14T07:18:01.440673Z","shell.execute_reply":"2021-06-14T07:18:01.449992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/test.csv')\nX_test=X_test.iloc[:,1:]\nmain_pred, train_oof, classmodel = prediction(X, y, X_test)\nsub = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/sample_submission.csv')\nsub.iloc[:,1:]=main_pred\nsub=sub.set_index('id')\nsub.to_csv('embmodel.csv')\ntf.keras.utils.plot_model(classmodel,show_shapes=True) \n# classModel = ClassModel(X.shape[1:])\n# classModel.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003))\n# classModel.summary()\n\n# resModel = ResModel(X.shape[1:])\n# resModel.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=tf.keras.optimizers.Adadelta(learning_rate=1))\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:18:03.701075Z","iopub.execute_input":"2021-06-14T07:18:03.701416Z","iopub.status.idle":"2021-06-14T07:22:12.981232Z","shell.execute_reply.started":"2021-06-14T07:18:03.701388Z","shell.execute_reply":"2021-06-14T07:22:12.978809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tf.keras.utils.plot_model(classmodel,show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T12:31:36.781136Z","iopub.execute_input":"2021-06-13T12:31:36.781447Z","iopub.status.idle":"2021-06-13T12:31:36.805053Z","shell.execute_reply.started":"2021-06-13T12:31:36.781419Z","shell.execute_reply":"2021-06-13T12:31:36.803679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history=classModel.fit(X_train,y_train, validation_data=(X_test,y_test),epochs = 15, batch_size=64, shuffle=True, callbacks=[model_checkpoint_callback])","metadata":{"execution":{"iopub.status.busy":"2021-06-08T06:12:53.946533Z","iopub.execute_input":"2021-06-08T06:12:53.946866Z","iopub.status.idle":"2021-06-08T06:17:03.963965Z","shell.execute_reply.started":"2021-06-08T06:12:53.946814Z","shell.execute_reply":"2021-06-08T06:17:03.962966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# classModel.load_weights('/kaggle/working/cp-0013.ckpt')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T06:18:38.505379Z","iopub.execute_input":"2021-06-08T06:18:38.505733Z","iopub.status.idle":"2021-06-08T06:18:38.604742Z","shell.execute_reply.started":"2021-06-08T06:18:38.5057Z","shell.execute_reply":"2021-06-08T06:18:38.603984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# classModel.evaluate(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T06:18:40.417697Z","iopub.execute_input":"2021-06-08T06:18:40.418037Z","iopub.status.idle":"2021-06-08T06:18:41.197462Z","shell.execute_reply.started":"2021-06-08T06:18:40.418009Z","shell.execute_reply":"2021-06-08T06:18:41.196682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_test = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T06:18:45.963253Z","iopub.execute_input":"2021-06-08T06:18:45.9636Z","iopub.status.idle":"2021-06-08T06:18:46.304625Z","shell.execute_reply.started":"2021-06-08T06:18:45.963566Z","shell.execute_reply":"2021-06-08T06:18:46.303768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X=test.iloc[:,1:]\n# #X=scaler.transform(X)\n# X=X+1\n# #X=np.array(X)\n# #X=np.clip(X,1,100)\n# #X_pred = []\n\n# #for x in range(75):\n#     #X_pred.append(X[:,x])\n# y=classModel.predict(X)\n# sub = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/sample_submission.csv')\n# sub.iloc[:,1:]=y\n# sub=sub.set_index('id')\n# sub.to_csv('embmodel.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T06:18:47.648831Z","iopub.execute_input":"2021-06-08T06:18:47.649207Z","iopub.status.idle":"2021-06-08T06:18:54.366761Z","shell.execute_reply.started":"2021-06-08T06:18:47.649174Z","shell.execute_reply":"2021-06-08T06:18:54.365685Z"},"trusted":true},"execution_count":null,"outputs":[]}]}